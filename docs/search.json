[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Section 03: M/W/F 02:20-03:20pm, THTR 213\nWelcome to STAT 253! This class is an introduction to the exciting world of statistical machine learning. Broadly, statistical machine learning consists of tools and algorithms to learn from data. Insights from machine learning help us take action by enabling us to make predictions and understand uncertainty. Applications of machine learning algorithms are used everywhere from finance to biology, medicine, social sciences, language, and the humanities.\nIn this course, you will build on the linear and logistic regression modeling techniques covered in STAT 155 to understand tools of regression (Weeks 2‚Äì6) and classification (Weeks 7‚Äì11) more broadly. You will also learn about unsupervised learning methods (Weeks 12‚Äì15) that can help you find underlying structure in data. Along the way, you‚Äôll also improve your skills in computational thinking/programming, communication, collaboration, ethical thinking, and reflection, all of which are vital in any profession.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#about-your-professor",
    "href": "syllabus.html#about-your-professor",
    "title": "Syllabus",
    "section": "About your professor",
    "text": "About your professor\n\nMd Mutasim Billah, PhD\nPronunciation: listen here\nOffice: Olin-Rice 234\nEmail: mbillah@macalester.edu\n\n\n\n\n\n\nNotes from ‚Äúyour professor‚Äù\n\n\n\nGreetings! You can call me Bill or Professor Billah & I use he/him pronouns. Back when I was an undergrad student, I didn‚Äôt have the best experience in Intro Stat‚Äîthose courses often emphasized formulas over real understanding. That experience has shaped my teaching‚ÄîI concentrate on illustrating how statistical theories connect and can be applied in the real world. I‚Äôm excited to teach STAT 253 and to create a more meaningful experience‚Äîone that helps all students feel confident applying it beyond the classroom. My methodological research lies at the intersection of statistical genetics, biostatistics, and genomics. My current research interests include developing novel statistical methods and computationally efficient bioinfor matics tools, leveraging modern machine- and deep-learning approaches analyze high-dimensional next-generation sequencing and multi-omics data to identify genes and regulatory mechanisms underlying complex diseases. Outside of my academic work, I enjoy spending time outdoors with family and friends or cooking variety of foods. If you can‚Äôt find me anywhere, I might be busy playing soccer or exploring new worlds on my PS5 Pro!\n\n\nOffice hours:\n\nLocation: My office (OLRI 234) and over Zoom\nTimes: M/W: 12:00pm - 12:30pm (in-person), T/TR: 2pm - 3pm (Over zoom, password: 123456)\nBy Appointment: I‚Äôm also happy to meet one-on-one if my normal drop-in/virtual hours don‚Äôt work for you. Shoot me an email and we can arrange it over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays. Please note that messages sent after 3:00 pm or on weekends may take longer to receive a response.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#about-your-preceptors",
    "href": "syllabus.html#about-your-preceptors",
    "title": "Syllabus",
    "section": "About your preceptors",
    "text": "About your preceptors\nWe have four awesome preceptors who will be helping out with STAT 253 this semester. See the calendar on Moodle for up-to-date information about their office hour times and locations.\nThe role of an MSCS preceptor is to help students with content questions, assist in the navigation of available resources, advise on studying approaches for classes, and assist with concepts, tools, and skills needed for problem sets. Students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), are not expected to immediately know the right approach, or provide assistance outside of office hours. Additional guidelines and expectations on how to interact with preceptors can be found here.\nData and R Support: In addition to our course preceptors, there is support on campus for working with data and R / RStudio. See https://www.macalester.edu/mscs/data-support for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbook-online-course-manual",
    "href": "syllabus.html#textbook-online-course-manual",
    "title": "Syllabus",
    "section": "Textbook & Online Course Manual",
    "text": "Textbook & Online Course Manual\n\nOur textbook, ISLR, is available free online: An Introduction to Statistical Learning with Applications in R (2nd edition). James et al, 2021.. The ISLR readings are highly encouraged and serve as a nice complement to the videos and in-class activities.\nThroughout the course, readings will be assigned from these notes, or other sources.\nThe online course websitel includes all in-class activities (with solutions).\nSee the rough schedule of the course, which is subject to change as needed.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#moodle",
    "href": "syllabus.html#moodle",
    "title": "Syllabus",
    "section": "Moodle",
    "text": "Moodle\nMoodle includes important announcements, general resources, a broad course calendar, submission links, feedback, and a forum for student questions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#statistical-software",
    "href": "syllabus.html#statistical-software",
    "title": "Syllabus",
    "section": "Statistical software",
    "text": "Statistical software\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, and RStudio are available on the R Resources tab.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#office-hours-oh-and-r-support",
    "href": "syllabus.html#office-hours-oh-and-r-support",
    "title": "Syllabus",
    "section": "Office hours (OH) and R Support",
    "text": "Office hours (OH) and R Support\nOH: Across the instructor and preceptors, there are several office hours each week. Names, times, and locations are on the Moodle course calendar. IMPORTANT: Always check the calendar before attending OH.\nData & R Support: In addition to the course preceptors, there is support on campus for working with data and R / RStudio. This is a great resource for R setup and troubleshooting throughout the semester. See https://www.macalester.edu/mscs/data-support for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#before-class",
    "href": "syllabus.html#before-class",
    "title": "Syllabus",
    "section": "Before Class",
    "text": "Before Class\nIn order to dedicate our class time to hands-on learning, you will prepare for class by watching short videos, reading from our textbook, and completing short quizzes (checkpoints) to assess your initial understanding of concepts. You can reattempt each checkpoint question multiple times, with a small penalty for incorrect responses.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#during-class",
    "href": "syllabus.html#during-class",
    "title": "Syllabus",
    "section": "During Class",
    "text": "During Class\nDuring class time, you will engage with each other in exercises and discussions that build upon the pre-class work. Please bring your laptop to class every day. Consistent attendance and active participation in these activities is expected of all students and, most importantly, will be crucial for your learning!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#after-class",
    "href": "syllabus.html#after-class",
    "title": "Syllabus",
    "section": "After Class",
    "text": "After Class\nAfter class, you will be expected to finish any remaining exercises from the class activity and review/organize your notes. For each unit, you will also complete homework assignments designed to help you practice and synthesize material and provide an opportunity to receive feedback to further guide your learning.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#group-assignments",
    "href": "syllabus.html#group-assignments",
    "title": "Syllabus",
    "section": "Group Assignments",
    "text": "Group Assignments\nhese assignments will give you an opportunity to practice collaboration, communication, and application of core statistical machine learning concepts in a more open-ended setting. They will also provide an opportunity to review and synthesize key concepts prior to each quiz. We will reserve class time at the end of each module‚ÄîRegression (Units 1‚Äì3), Classification (Units 4‚Äì5), and Unsupervised Learning (Units 6‚Äì7)‚Äîto work on these assignments. Deadlines are posted in the Stat 253 Google Calendar on Moodle.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Syllabus",
    "section": "Quizzes",
    "text": "Quizzes\nThe primary assessment of your understanding of core statistical machine learning concepts and R code will come in the form of three in-class quizzes:\n\nQuiz 1: TBD\nQuiz 2: TBD\nQuiz 3: Thurs. 5/7, 1:30pm-3:30pm in class\n\n\n\n\n\n\n\nüìú Quiz Policies\n\n\n\n\nAll quizzes will have the following format:\n\nTaken individually, using pen/pencil & paper\nClosed notes, but you may use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards. Making your own card is important to the review process- as you are required to submit the index card along with the answer paper.\n\nQuiz corrections:\nAfter Quizzes 1 and 2, you will have the opportunity modify your quiz grade by reviewing feedback, completing a short reflection, and revising your answers. Note: Quiz 3 corrections are not allowed due to time constraints at the end of the semester (I‚Äôll take this into consideration when grading!)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#learning-reflections",
    "href": "syllabus.html#learning-reflections",
    "title": "Syllabus",
    "section": "Learning Reflections",
    "text": "Learning Reflections\nThroughout the semester, I want you to practice reflecting on your progress and learning. I will provide a structured set of reflection questions for you to complete roughly once a month. More details (prompts, deadlines, grading, etc.) will be provided in class!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#flexibility",
    "href": "syllabus.html#flexibility",
    "title": "Syllabus",
    "section": "Flexibility",
    "text": "Flexibility\nI provide transparent accommodations to all students. It helps reduce stress and the ‚Äúhidden curriculum‚Äù (not everybody feels comfortable asking for flexibility).\n\nMissed Class: You are warmly invited, encouraged, and expected to attend and participate in all class meetings. Participation means coming to class prepared, actively discussing material, engaging in the activities, and asking questions. This will be important not only for your own learning, but also for our ability to build a community and maintain a sense of connection and commitment to one another during the semester. That being said, it‚Äôs okay to miss class in the case of an emergency.\n\n\n\n\n\n\n\nWhat to Do If You Miss Class\n\n\n\n\nüìß Send me a quick email. You do not need to share a reason for your absence, especially if it‚Äôs personal. It‚Äôs just a simple courtesy & keeps communication lines open.\nüìÖ Check the Course Schedule in the online manual for what is happening in class that day.\nüìù Complete the in-class activity on your own & check the solutions posted in the online manual.\nüí¨ Ask any follow-up questions on the Moodle forum or in office hours (OH).\n\n\n\n\nHomework: There will be a one hour grace period implemented for each assignment. If you need more time than that, email me to request an extension. Each student will automatically (no reason necessary!) be granted the use of three 3-day homework extensions. Except in rare circumstances, I will not grant more than three (or longer than 3-day) extensions.\nCheckpoints: Except in exceptional circumstances, I will NOT grant extensions or accept late submissions for checkpoints. These are important preparation for class.\nMajor learning activities: I cannot guarantee that I will be able to accommodate late work or extensions for group assignments, quizzes, or reflections, but I will do my best to work with you in exceptional circumstances. Send extension requests for any of these major assignments at least one week in advance for full consideration.\n\n\n\n\n\n\n\nü§ù PLEASE REACH OUT WHEN YOU NEED HELP.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai",
    "href": "syllabus.html#artificial-intelligence-ai",
    "title": "Syllabus",
    "section": "Artificial Intelligence (AI)",
    "text": "Artificial Intelligence (AI)\nUsing AI tools is an emerging skill. You may use AI (ChatGPT, Gemini, Grok, etc), with some caveats & limitations:\n\nAI is often wrong, thus is not a good resource on topics for which you don‚Äôt yet have expertise. Relatedly, though AI can be helpful with parts of a statistical analysis (eg: getting unstuck on code, checking grammar), you have to guide that process (eg: what questions are we trying to answer? what‚Äôs a reasonable approach?).\nWork on an exercise for at least 30 minutes before even thinking about AI. You will learn very little if you overly rely on AI, hence be unprepared for other interactions with the material (eg: in-class discussions, quizzes, future courses that build upon 253, etc). Learning comes from you doing the puzzling, not from you producing a correct answer.\nWhether or not you use AI, you must be able to defend/explain any code/discussion you hand in. You cannot simply use AI to bypass your own learning.\nYou may not use AI to generate entire arguments or discussions. Putting code and discussions into your own words is critical for your own deeper learning, independent thinking, and creativity. (For example, imagine how little you‚Äôd learn in a language course if you simply used AI to translate all text for you!!)\nAny use of AI must be cited, just like any other resource.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#community-academic-integrity",
    "href": "syllabus.html#community-academic-integrity",
    "title": "Syllabus",
    "section": "Community & Academic Integrity",
    "text": "Community & Academic Integrity\nMSCS strives to provide a learning environment that is equitable, inclusive, welcoming, mutually respectful, and free of discrimination. You‚Äôre expected to follow the MSCS Community Guidelines. You‚Äôre also required to be familiar with & follow the college‚Äôs academic integrity & other academic policies. In addition to the examples listed there, academic violations in this course include but are not limited to the following:\n\nUsing any materials from any past STAT 253 course, at Mac or elsewhere. Relatedly, you should not provide any materials to any future 253 students.\nGaining access to, using, or distributing solution sets.\nPassing off others‚Äô work as your own. You must be able to defend / explain all work you hand in.\nUsing AI without citation, to generate entire discussions / code blocks, or without being able to defend the results. Policy violations will result in a score of 0 on the work & be reported to the Asst. Dean of Academic Programs & Advising.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading-system",
    "href": "syllabus.html#grading-system",
    "title": "Syllabus",
    "section": "Grading system",
    "text": "Grading system\nThis course uses a grading system designed to combat some of the (many!) problems with ‚Äútraditional‚Äù grades link. My hope is that this alternative grading system will provide space to make and learn from mistakes, engage in feedback loops link, and encourage self-reflection. You will receive qualitative feedback and marks (e.g., PASS, ATTEMPT), rather than points, on most assignments. I will then translate that feedback into an overall letter grade according to the table to the right. Adjusting to this system may take time. I‚Äôll provide feedback and resources to help you track your progress throughout the semester. If you are ever concerned about your learning (or grade), please set up an appointment with me to discuss!\n\n\n\n\n\n\n\nPassing(C)\n\n\nProgressing(B)\n\n\nExemplary(A)\n\n\n\n\n\n\nCheckpoints\n\n\nATTEMPT ‚â• 10\n\n\n\n\nPASS ‚â• 12\n\n\n\n\nHomework\n\n\nATTEMPT ‚â• 5\n\n\n\n\nPASS ‚â• 7\n\n\n\n\nGroupAssignments\n\n\nATTEMPT ‚â• 2\n\n\nATTEMPT ‚â• 3 and PASS ‚â• 2\n\n\nPASS ‚â• 3\n\n\n\n\nReflections\n\n\nATTEMPT ‚â• 2\n\n\nATTEMPT ‚â• 3 and PASS ‚â• 2\n\n\nPASS ‚â• 3\n\n\n\n\nQuizzes(after revision)\n\n\n‚â• 70%\n\n\n‚â• 80%\n\n\n‚â• 90%\n\n\n\n\n\nIf you meet all criteria in a particular column, you will earn that grade. Intermediate grades (e.g., B+, A-) will be given if most requirements in a given column are achieved but some requirements for lower (-) and/or higher (+) grades are met.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#asking-questionscommunicating",
    "href": "syllabus.html#asking-questionscommunicating",
    "title": "Syllabus",
    "section": "Asking questions/communicating",
    "text": "Asking questions/communicating\n\nOffice Hours\nOH are a great place to chat about the course, career planning, life,‚Ä¶ Please visit us!!\n\nOH times & locations are on the Moodle course calendar.\nOH are oriented around group discussion. They are not first come, first served appointments.\nSince it‚Äôs not an effective way to deepen your learning, OH are not a place to sit and do assignments with me or preceptors. It‚Äôs an opportunity to discuss concepts & specific questions.\n\n\n\nMoodle Forum: STAT 253 Discussion Board\nThis forum is where we‚Äôll communicate outside class. Students can post and answer comments / questions there. This is an informal way to converse, ask questions, share info, & connect. Do not rely on receiving responses outside weekdays between 9am & 5pm.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "href": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "title": "Syllabus",
    "section": "What to do when you have a question for me?",
    "text": "What to do when you have a question for me?\n\nIf it‚Äôs non-private (e.g.¬†about policies, homework (Practice Problems), class activities, etc), you must post it on STAT 253 Discussion Board in Moodle. Remember- collaboration is the KEY!\nIf it‚Äôs personal (e.g.¬†about an absence), email me.\nIt‚Äôs good, professional practice to check whether your question is already answered in the provided resources. For example:\n\nInfo (what to do if you miss class): syllabus\nDue dates: course calendar at the top of Moodle + course schedule in the online manual\nQuiz dates: syllabus + course calendar at the top of Moodle + course schedule in the online manual\nHomework policies & grading: homework policies & grading doc\nFinals week: syllabus + course calendar at the top of Moodle + course schedule in the online manual",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#thriving-in-stat-253",
    "href": "syllabus.html#thriving-in-stat-253",
    "title": "Syllabus",
    "section": "Thriving in STAT 253",
    "text": "Thriving in STAT 253\n\n\n\n\n\n\nüóìÔ∏è Plan Ahead\n\n\n\nYou should plan to spend ~10-12 hours on any 4-credit course, including class time.1 Stay up-to-date on the course calendar and carve out time for studying & doing homework.\n\n\n\n\n\n\n\n\n‚úÖ Do the Things\n\n\n\nAt minimum, thriving in this course requires the completion of some concrete tasks. Complete all assignments, regularly attend & engage in class, complete in-class activities (which might mean completing work outside of class), and check the activity solutions.\n\n\n\n\n\n\n\n\nüèóÔ∏è Build a Foundation\n\n\n\nIf your main focus is on checking off some boxes, you won‚Äôt get much out of this course (or college in general). Deeper, enduring learning requires more. Carve out time to rewrite, reflect upon, & review your notes. Summarize concepts in your own words.\n\n\n\n\n\n\n\n\nüéâ Engage, Ask Questions, Have Fun\n\n\n\nActively participate in the class & take ownership of your learning. PLEASE: Don‚Äôt be afraid to ask for help, make mistakes, and ask questions! These skills are critical to your well-being & learning. Finally, have some fun, be curious, and reflect upon what surprises you about the material and yourself",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#attend-class.",
    "href": "syllabus.html#attend-class.",
    "title": "Syllabus",
    "section": "Attend class.",
    "text": "Attend class.\nWe‚Äôll use class time to ask and answer questions, review material, and practice concepts in a collaborative environment. To ensure the best learning experience for you and your classmates, come prepared, engage in class, and make full use of the entire class period.\n\n\n\n\n\n\nüìå If you miss class‚Ä¶\n\n\n\ncheck the course website to see what you missed, review that material and complete the activity on your own, get notes from your classmates, and then (after doing all of the above) come to office hours with any remaining specific questions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#ask-questions.",
    "href": "syllabus.html#ask-questions.",
    "title": "Syllabus",
    "section": "Ask questions.",
    "text": "Ask questions.\nWhen you have questions, please stop me during class, ask your neighbor, post on Moodle discussion board, and come to office hours. Saying ‚ÄúI don‚Äôt understand‚Äù is an important part of learning and it helps others. Office hours are a great time to talk about course material and assignments, study strategies, selecting courses, declaring a major, grad school and/or career planning, or life. You don‚Äôt need to have a specific question in order to attend office hours: it can also be a great space to review concepts, talk through examples, or just chat!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#make-time.",
    "href": "syllabus.html#make-time.",
    "title": "Syllabus",
    "section": "Make time.",
    "text": "Make time.\nPerforming a thoughtful statistical analysis requires time: to plan, to implement, to interpret, and to revise. Start your assignments early. It is very hard to be creative or to debug R code when you are in a rush. You should expect to spend about 10 hours per week on this class (including the 3 hours we spend together during class). If you‚Äôre spending much more (or less!) time than that, please let me know.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#prioritize-your-well-being.",
    "href": "syllabus.html#prioritize-your-well-being.",
    "title": "Syllabus",
    "section": "Prioritize your well-being.",
    "text": "Prioritize your well-being.\nTaking care of yourself will help you engage more fully in your academic experience. Beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities with you. If you are having difficulties maintaining your well-being, I encourage you to contact me and/or check out these resources.\n\n\n\n\n\n\nüìå Important‚Ä¶\n\n\n\nAs part of prioritizing your well-being (and that of others around you), it is important that you stay home if you are feeling sick. This is particularly meaningful to me as someone with a severely immunocompromised family member. I will happily work with you to get you caught up!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#communicate.",
    "href": "syllabus.html#communicate.",
    "title": "Syllabus",
    "section": "Communicate.",
    "text": "Communicate.\nI will do my best to clearly and promptly communicate any changes to expectations, deadlines, office hours, or class meetings. Please make sure to check your email (and Moodle announcement) so you don‚Äôt miss any important announcements. I know that you may also have issues come up: if so, please get in touch with me to discuss solutions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": "Syllabus",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations.\nIn an effort to respect religious diversity, I request that students who plan to observe a religious holiday during scheduled class meetings/class requirements talk to me about reasonable consideration by the end of the second week of the course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": "Syllabus",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester‚Äôs Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others‚Äô ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you. If you are having difficulties maintaining your well-being, please don‚Äôt hesitate to contact me and/or find support from physical and mental health resources here, here, and here.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMacalester Academic Advising ‚Äì High School Preparation‚Ü©Ô∏é",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "The (tentative) course schedule below will be filled in throughout the semester. For each day, there will be written on what is due ahead of class time OR whats‚Äô the big thing (like quizzes!). Any important announcements will be made over email (moodle)."
  },
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "Learning Goals",
    "section": "",
    "text": "Specific skills and course topics are listed below. Use this list to guide your synthesis of video and reading material for specific topics, and your learning more generally, throughout the semester. It also serves as a study guide for quizzes and other assessments.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#computational-thinking",
    "href": "learning.html#computational-thinking",
    "title": "Learning Goals",
    "section": "Computational Thinking",
    "text": "Computational Thinking\n\nDecomposition: Break a task into smaller tasks to be able to explain the process to another person or computer\nPattern Recognition: Recognize patterns in tasks by noticing similarities and common differences\nAbstraction: Represent an idea or process in general terms so that you can use it to solve other projects that are similar in nature\nAlgorithmic Thinking: Develop a step-by-step strategy for solving a problem",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#ethical-data-thinking",
    "href": "learning.html#ethical-data-thinking",
    "title": "Learning Goals",
    "section": "Ethical Data Thinking",
    "text": "Ethical Data Thinking\n\nIdentify ethical issues associated with applications of statistical machine learning in a variety of settings\nAssess and critique the actions of individuals and organizations as it relates to ethical use of data",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#data-communication",
    "href": "learning.html#data-communication",
    "title": "Learning Goals",
    "section": "Data Communication",
    "text": "Data Communication\n\nIn written and oral formats: Inform and justify data analysis and modeling process and the resulting conclusions with clear, organized, logical, and compelling details that adapt to the background, values, and motivations of the audience and context in which communication occurs.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#collaborative-learning",
    "href": "learning.html#collaborative-learning",
    "title": "Learning Goals",
    "section": "Collaborative Learning",
    "text": "Collaborative Learning\n\nUnderstand and demonstrate characteristics of effective collaboration (team roles, interpersonal communication, self-reflection, awareness of social dynamics, advocating for yourself and others).\nDevelop a common purpose and agreement on goals.\nBe able to contribute questions or concerns in a respectful way.\nShare and contribute to the group‚Äôs learning in an equitable manner.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#reflection",
    "href": "learning.html#reflection",
    "title": "Learning Goals",
    "section": "Reflection",
    "text": "Reflection\n\nRegularly reflect on your learning to make note of and celebrate your progress, identify opportunities for continued growth, and set goals",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-0",
    "href": "learning.html#unit-0",
    "title": "Learning Goals",
    "section": "Unit 0",
    "text": "Unit 0\nIntroduction to Statistical Machine Learning\n\n\n\n\n\n\nTopics\n\n\n\n\nFormulate research questions that align with regression, classification, or unsupervised learning tasks.\nIdentify the appropriate task (regression, classification, unsupervised) for a given research question.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-1",
    "href": "learning.html#unit-1",
    "title": "Learning Goals",
    "section": "Unit 1",
    "text": "Unit 1\nEvaluating Regression Models\n\n\n\n\n\n\nTopics\n\n\n\n\nCreate and interpret residuals vs.¬†fitted, residuals vs.¬†predictor plots to identify improvements in modeling and address ethical concerns.\nCalculate and interpret MSE, RMSE, MAE, and R-squared in a contextually meaningful way.\n\n\n\nOverfitting and Cross-Validation\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain why training/in-sample model evaluation metrics can provide a misleading view of true test/out-of-sample performance\nAccurately describe all steps of cross-validation to estimate the test/out-of-sample version of a model evaluation metric\nExplain what role CV has in a predictive modeling analysis and its connection to overfitting\nExplain the pros/cons of higher vs.¬†lower k in k-fold CV in terms of sample size and computing time",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-2",
    "href": "learning.html#unit-2",
    "title": "Learning Goals",
    "section": "Unit 2",
    "text": "Unit 2\nVariable Selection\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the difference between inferential models and predictive models and how the model building processes differ\nClearly describe the backward stepwise selection algorithm and why they are examples of greedy algorithms\nCompare best subset and stepwise algorithms in terms of optimality of output and computational time\n\n\n\nLASSO (shrinkage/regularization)\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain how ordinary and penalized least squares are similar and different with regard to (1) the form of the objective function (i.e., the function we are trying to minimize) and (2) the goal of variable selection\nExplain how the lambda tuning parameter affects model performance and how this is related to overfitting",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-3",
    "href": "learning.html#unit-3",
    "title": "Learning Goals",
    "section": "Unit 3",
    "text": "Unit 3\nKNN Regression and the Bias-Variance Tradeoff\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the KNN algorithm for making a regression prediction\nExplain how the number of neighbors relates to the bias-variance tradeoff\nExplain the difference between parametric and nonparametric methods\nExplain how the curse of dimensionality relates to the performance of KNN\n\n\n\nLocal Regression and Splines\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe the local regression algorithm for making a prediction\nExplain how bandwidth (span) relate to the bias-variance tradeoff\nExplain the advantages of splines over global transformations (e.g.¬†y ~ poly(x, 2)) and other types of piecewise polynomials\nExplain how splines are constructed by drawing connections to variable transformations and least squares\nExplain how the number of knots relates to the bias-variance tradeoff",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-4",
    "href": "learning.html#unit-4",
    "title": "Learning Goals",
    "section": "Unit 4",
    "text": "Unit 4\nClassification via Logistic regression\n\n\n\n\n\n\nTopics\n\n\n\n\nUse a logistic regression model to make hard (class) and soft (probability) predictions\nInterpret non-intercept coefficients from logistic regression models in the data context\n\n\n\nEvaluating Classification Models\n\n\n\n\n\n\nTopics\n\n\n\n\nCalculate (by hand from confusion matrices) and contextually interpret overall accuracy, sensitivity, and specificity\nConstruct and interpret plots of predicted probabilities across classes\nExplain how a ROC curve is constructed and the rationale behind AUC as an evaluation metric\nAppropriately use and interpret the no-information rate to evaluate accuracy metrics",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-5",
    "href": "learning.html#unit-5",
    "title": "Learning Goals",
    "section": "Unit 5",
    "text": "Unit 5\nKNN Classification\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the KNN algorithm for making a classification prediction\nInterpret a KNN classification region plot\nDiscuss the pros and cons of KNN classification relative to other classification tools (eg logistic regression, decision trees)\n\n\n\nDecision Trees\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe the recursive binary splitting algorithm for tree building for both regression and classification\nCompute the weighted average Gini index to measure the quality of a classification tree split\nCompute the sum of squared residuals to measure the quality of a regression tree split\nExplain how recursive binary splitting is a greedy algorithm\nExplain how different tree parameters relate to the bias-variance tradeoff\n\n\n\nBagging and Random Forests\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the rationale for bagging\nExplain the rationale for selecting a random subset of predictors at each split (random forests)\nExplain how the size of the random subset of predictors at each split relates to the bias-variance tradeoff\nExplain the rationale for and implement out-of-bag error estimation for both regression and classification\nExplain the rationale behind the random forest variable importance measure and why it is biased towards quantitative predictors (in class)",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-6",
    "href": "learning.html#unit-6",
    "title": "Learning Goals",
    "section": "Unit 6",
    "text": "Unit 6\nHierarchical Clustering\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the hierarchical clustering algorithm\nCompare and contrast k-means and hierarchical clustering in their outputs and algorithms\nInterpret cuts of the dendrogram for single and complete linkage\nDescribe the rationale for how clustering algorithms work in terms of within-cluster variation\nDescribe the tradeoff of more vs.¬†less clusters in terms of interpretability\nImplement strategies for interpreting / contextualizing the clusters\n\n\n\nK-Means Clustering\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the k-means algorithm\nDescribe the rationale for how clustering algorithms work in terms of within-cluster variation\nDescribe the tradeoff of more vs.¬†less clusters in terms of interpretability\nImplement strategies for interpreting / contextualizing the clusters",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-7",
    "href": "learning.html#unit-7",
    "title": "Learning Goals",
    "section": "Unit 7",
    "text": "Unit 7\nPrincipal Component Analysis\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the goal of dimension reduction and how this can be useful in a supervised learning setting\nInterpret and use the information provided by principal component loadings and scores\nInterpret and use a scree plot to guide dimension reduction\n\n\n\nPrincipal Component Regression\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement the principal component regression algorithm\nDescribe the tradeoff of choice of principal components (k) in terms of the bias-variance tradeoff\nImplement strategies for choosing k\nDiscuss the pros and cons of principal component regression relative to variable selection and LASSO",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Broadly, statistical machine learning consists of tools and algorithms to learn from data. Insights from machine learning help us take action by enabling us to make predictions and understand uncertainty. Applications of machine learning algorithms are used everywhere from finance to biology, medicine, social sciences, language, and the humanities.\nIn this course, you will build on the linear and logistic regression modeling techniques covered in STAT 155 to understand tools of regression (Units 1‚Äì3) and classification (Units 4‚Äì5) more broadly. You will also learn about unsupervised methods (Units 6‚Äì7) that can help you find underlying structure in data.\n\n\n\nWe‚Äôll return to this diagram frequently throughout the semester!\n\n\n\n\n\n\nAs we build on ideas from STAT 155, familiarity with core concepts from that course is expected.\nCheck out the STAT 155 Review in the Appendix for a list of important topics that we‚Äôll revisit this semester, as well as links to resources if you need a refresher on any of those topics.\n\n\n\n\n\nWe‚Äôll also be building on your introduction to R/RStudio from STAT 155 (and COMP/STAT 112, if applicable).\nTO-DO: During the first week of class, work through the steps on the R and RStudio Setup page in the Appendix to get everything set up for the semester.\nThroughout the semester, if you find yourself needing a refresher or additional resources related to R, check out the R Resources page!\n\n\n\n\n\nYou‚Äôll access most of the materials that you need for this course via this website. Each class period will have its own page on this site. There, you‚Äôll find daily learning goals, lecture notes, discussion questions, and exercises designed to give you hands-on practice with newly introduced concepts.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#stat-155-review",
    "href": "getting-started.html#stat-155-review",
    "title": "Getting Started",
    "section": "",
    "text": "As we build on ideas from STAT 155, familiarity with core concepts from that course is expected.\nCheck out the STAT 155 Review in the Appendix for a list of important topics that we‚Äôll revisit this semester, as well as links to resources if you need a refresher on any of those topics.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#r-setup-and-resources",
    "href": "getting-started.html#r-setup-and-resources",
    "title": "Getting Started",
    "section": "",
    "text": "We‚Äôll also be building on your introduction to R/RStudio from STAT 155 (and COMP/STAT 112, if applicable).\nTO-DO: During the first week of class, work through the steps on the R and RStudio Setup page in the Appendix to get everything set up for the semester.\nThroughout the semester, if you find yourself needing a refresher or additional resources related to R, check out the R Resources page!",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#course-notes",
    "href": "getting-started.html#course-notes",
    "title": "Getting Started",
    "section": "",
    "text": "You‚Äôll access most of the materials that you need for this course via this website. Each class period will have its own page on this site. There, you‚Äôll find daily learning goals, lecture notes, discussion questions, and exercises designed to give you hands-on practice with newly introduced concepts.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html",
    "href": "activities/L05-model-selection.html",
    "title": "Model Selection",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#context",
    "href": "activities/L05-model-selection.html#context",
    "title": "Model Selection",
    "section": "Context",
    "text": "Context\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\ntask = regression\n\\(y\\) is quantitative\nmodel = linear regression\nWe‚Äôll assume that the relationship between \\(y\\) and (\\(x_1, x_2, ..., x_p\\)) can be represented by\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\varepsilon\\]",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#inferential-v.-predictive-models",
    "href": "activities/L05-model-selection.html#inferential-v.-predictive-models",
    "title": "Model Selection",
    "section": "Inferential v. Predictive Models",
    "text": "Inferential v. Predictive Models\nIn model building, the decision of which predictors to use depends upon our goal.\nInferential models\n\nGoal: Explore & test hypotheses about a specific relationship.\nPredictors: Defined by the goal.\nExample: An economist wants to understand how salaries (\\(y\\)) vary by age (\\(x_1\\)) while controlling for education level (\\(x_2\\)).\n\n\n\nPredictive models\n\n\nGoal: Produce the ‚Äúbest‚Äù possible predictions of \\(y\\).\nPredictors: Any combination of predictors that help us meet this goal.\nExample: A mapping app wants to provide users with quality estimates of arrival time (\\(y\\)) utilizing any useful predictors (eg: time of day, distance, route, speed limit, weather, day of week, traffic radar‚Ä¶)",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#model-selection-goals",
    "href": "activities/L05-model-selection.html#model-selection-goals",
    "title": "Model Selection",
    "section": "Model Selection Goals",
    "text": "Model Selection Goals\nModel selection algorithms can help us build a predictive model of \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\nThere are 3 general approaches to this task:\n\n\nVariable selection (today)\nIdentify a subset of predictors to use in our model of \\(y\\).\nShrinkage / regularization (next class)\nShrink / regularize the coefficients of all predictors toward or to 0.\nDimension reduction (later in the semester)\nCombine the predictors into a smaller set of new predictors.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#instructions",
    "href": "activities/L05-model-selection.html#instructions",
    "title": "Model Selection",
    "section": "Instructions",
    "text": "Instructions\nAs a group, you‚Äôll design a variable selection algorithm to pick which predictors to use in a predictive model of height. Specifically, you will:\n\ncome up with one algorithm (5 mins)\n\nNOTE: This will NOT be perfect! Our goals are to:\n\nHave fun and work together!\nTap into your intuition for key questions and challenges in variable selection.\nDeepen your understanding of ‚Äúalgorithms‚Äù and ‚Äútuning parameters‚Äù by designing and communicating your own.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#questions",
    "href": "activities/L05-model-selection.html#questions",
    "title": "Model Selection",
    "section": "Questions",
    "text": "Questions\nLet‚Äôs build a predictive model of height in inches using one or more of 12 possible predictors. Other than age and weight, these are circumferences measured in cm.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Load data\nhumans &lt;- read.csv(\"https://mac-stat.github.io/data/bodyfat1.csv\")\nnames(humans)\n##  [1] \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"     \"thigh\"  \n##  [8] \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"   \"height\"\n\n\n\nA heat map displays correlations for each pair of variables in our dataset. Not only is height correlated with multiple predictors, the predictors are correlated with one another (mulicollinear)! We don‚Äôt need all of them in our model.\n\n\nCode\n# Get the correlation matrix\nlibrary(reshape2)\ncor_matrix &lt;- cor(humans)\ncor_matrix[lower.tri(cor_matrix)] &lt;- NA\ncor_matrix &lt;- cor_matrix %&gt;% \n  melt() %&gt;% \n  na.omit() %&gt;% \n  rename(correlation = value)\n\n# Visualize the correlation for each pair of variables\nggplot(cor_matrix, aes(x = Var1, y = Var2, fill = correlation)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"blue\", high = \"red\", mid = \"white\", \n    midpoint = 0, limit = c(-1,1)) +\n  labs(x = \"\", y = \"\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\nDesign your own algorithm (5 minutes)\n- Do not use any materials from outside this class. - Document your algorithm in words (not code). - Your algorithm must: - be clear to other humans - be clear to a machine (cannot utilize context) - lead to a single model that uses 0-12 of our predictors - define and provide directions for selecting any tuning parameters",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-1-best-subset-selection-.unnumbered-.smaller-tea",
    "href": "activities/L05-model-selection.html#algorithm-1-best-subset-selection-.unnumbered-.smaller-tea",
    "title": "Model Selection",
    "section": "Algorithm 1: Best Subset Selection {.unnumbered .smaller} [Tea]",
    "text": "Algorithm 1: Best Subset Selection {.unnumbered .smaller} [Tea]\n\n\nBuild all \\(2^p\\) possible models that use any combination of the available predictors \\((x_1, x_2,..., x_p)\\).\n\nIdentify the best model with respect to some chosen metric (eg: CV MAE) and context.\n\n\nSuppose we used this algorithm for our height model with 12 possible predictors: what‚Äôs the main drawback?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-2-backward-stepwise-selection",
    "href": "activities/L05-model-selection.html#algorithm-2-backward-stepwise-selection",
    "title": "Model Selection",
    "section": "Algorithm 2: Backward Stepwise Selection",
    "text": "Algorithm 2: Backward Stepwise Selection\n\n\nBuild a model with all \\(p\\) possible predictors, \\((x_1, x_2,..., x_p)\\).\n\nRepeat the following until only 1 predictor remains in the model:\n\nRemove the 1 predictor with the biggest p-value.\nBuild a model with the remaining predictors.\n\n\nYou now have \\(p\\) competing models: one with all \\(p\\) predictors, one with \\(p-1\\) predictors, ‚Ä¶, and one with 1 predictor. Identify the ‚Äúbest‚Äù model with respect to some metric (eg: CV MAE) and context.\n\n\n\nLet‚Äôs try out the first few steps!\n\n# Load packages and data\nlibrary(tidyverse)\nlibrary(tidymodels)\nhumans &lt;- read.csv(\"https://mac-stat.github.io/data/bodyfat1.csv\")\n\n\n# STEP 1: model specifications\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n\n# STEP 2: model estimate (using all 12 predictors to start)\n# Pick apart this code and make it easier to identify the least \"significant\" predictor!!!\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, \n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\n# 11 predictors (tweak the code)\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\n# 10 predictors (tweak the code)\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\nBelow is the complete model sequence along with 10-fold CV MAE for each model (using set.seed(253)).\n\n\n\npred\nCV MAE\npredictor list\n\n\n\n\n12\n5.728\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee, neck, biceps\n\n\n11\n5.523\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee, neck\n\n\n10\n5.413\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee\n\n\n9\n5.368\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist\n\n\n8\n5.047\nweight, hip, forearm, thigh, chest, abdomen, age, ankle\n\n\n7\n5.013\nweight, hip, forearm, thigh, chest, abdomen, age\n\n\n6\n4.684\nweight, hip, forearm, thigh, chest, abdomen\n\n\n5\n4.460\nweight, hip, forearm, thigh, chest\n\n\n4\n4.386\nweight, hip, forearm, thigh\n\n\n3\n4.091\nweight, hip, forearm\n\n\n2\n3.733\nweight, hip\n\n\n1\n3.658\nweight\n\n\n\n\n\nDISCUSS at your tables: In Groups\n\n(Review) Interpret the CV MAE for the model of height by weight alone.\nIs this algorithm more or less computationally expensive than the best subset algorithm?\nThe predictors neck and wrist, in that order, are the most strongly correlated with height. Where do these appear in the backward sequence and what does this mean?\n\n\ncor(humans)[,'height'] %&gt;% \n  sort()\n##       thigh         hip         age     abdomen        knee       chest \n## -0.11301249 -0.10648937 -0.05853538 -0.02173587  0.02345904  0.05838830 \n##      biceps       ankle      weight     forearm       wrist        neck \n##  0.07441696  0.07920867  0.11228791  0.16968040  0.28967468  0.29147610 \n##      height \n##  1.00000000\n\n\nWe deleted predictors one at a time. Why is this better than deleting a collection of multiple predictors at the same time (eg: kicking out all predictors with p-value &gt; 0.1)?\n\n\n\n\n\nWe have to pick just 1 of the 12 models as our final model. That is, we have to pick a value for our tuning parameter, the number of predictors.\nIt helps to plot the CV MAE for each model in the sequence.\nHere‚Äôs what we saw above:\n\n\nCode\ndata.frame(\n    predictors = c(12:1), \n    mae = c(5.728, 5.523, 5.413, 5.368, 5.047, 5.013, 4.684, 4.460, 4.386, 4.091, 3.733, 3.658)) %&gt;% \n  ggplot(aes(x = predictors, y = mae)) + \n    geom_point() + \n    geom_line() + \n    scale_x_continuous(breaks = c(1:12))\n\n\n\n\n\n\n\n\n\nDISCUSS at your tables: In Groups\n\nWhich model do you pick?!?\nIn the odd ‚ÄúGoldilocks‚Äù fairy tale, a kid comes upon a bear den ‚Äì the first bear‚Äôs bed is too hard, the second bear‚Äôs is too soft, and the third bear‚Äôs is just right. The second plot, below, illustrates a goldilocks problem in tuning the number of predictors in our backward stepwise model. Explain.\n\n\n\nWhen the number of predictors is too small, the MAE increases because the model is too‚Ä¶.\nWhen the number of predictors is too large, the MAE increases because the model is too‚Ä¶.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-3-forward-stepwise-selection",
    "href": "activities/L05-model-selection.html#algorithm-3-forward-stepwise-selection",
    "title": "Model Selection",
    "section": "Algorithm 3: Forward Stepwise Selection",
    "text": "Algorithm 3: Forward Stepwise Selection\nDISCUSS at your tables: In Groups\n\nHow do you think this works?\nIs it more or less computationally expensive than backward stepwise?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#machine-learning-vs-human-learning",
    "href": "activities/L05-model-selection.html#machine-learning-vs-human-learning",
    "title": "Model Selection",
    "section": "Machine Learning vs Human Learning",
    "text": "Machine Learning vs Human Learning\nWhen tuning or finalizing a model building algorithm, we (humans!) have our own choices to make. For one, we need to decide what we prefer:\n\na model with the lowest prediction errors; or\na more parsimonious model: one with slightly higher prediction errors but fewer predictors\n\nIn deciding, here are some human considerations:\n\ngoal: How will the model be used? Should it be easy for humans to interpret and apply?\ncost: How many resources (time, money, computer memory, etc) do the model and data needed require?\nimpact: What are the consequences of a bad prediction?\n\n\n\nFor each scenario below, which model would you pick: (1) the model with the lowest prediction errors; or (2) a parsimonious model with slightly worse predictions?\n\nGoogle asks us to re-build their search algorithm.\nA small non-profit hires us to help them build a predictive model of the donation dollars they‚Äôll receive throughout the year.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#warning",
    "href": "activities/L05-model-selection.html#warning",
    "title": "Model Selection",
    "section": "WARNING",
    "text": "WARNING\nVariable selection algorithms are a nice, intuitive place to start our discussion of model selection techniques.\nBUT we will not use them.\nThey are frowned upon in the broader ML community, so much so that tidymodels doesn‚Äôt even implement them! Why?\n\nBest subset selection is computationally expensive.\n\nStepwise selection methods (forward and backward):\n\nAre greedy ‚Äì they make locally optimal decisions, thus often missing the globally optimal model\nOverestimate the significance of included predictors, thus shouldn‚Äôt be used for inference\n\nThis Stack Exchange discussion shows the results of a simulation study that helps illustrate this phenomenon.\n\nCan produce odd combinations of predictors\n\nForward: a new predictor may render previously included predictors non-significant)\nBackward: sensible predictors can be kicked out early (like the neck and wrist issue in our height model in Example 3)",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#instructions-1",
    "href": "activities/L05-model-selection.html#instructions-1",
    "title": "Model Selection",
    "section": "Instructions",
    "text": "Instructions\n\nGoal: become familiar with new code structures (recipes and workflows)\nAsk me questions as I move around the room.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#questions-.unnumbered-.smaller--in-group-finish-after-class-in-you-cannot-finish-all-in-class",
    "href": "activities/L05-model-selection.html#questions-.unnumbered-.smaller--in-group-finish-after-class-in-you-cannot-finish-all-in-class",
    "title": "Model Selection",
    "section": "Questions {.unnumbered .smaller}- In Group [Finish after class in you cannot finish all in-class!]",
    "text": "Questions {.unnumbered .smaller}- In Group [Finish after class in you cannot finish all in-class!]\nThe video for today introduced the concepts of recipes and workflows in the tidymodels framework. These concepts will become important to our new modeling algorithms. Though they aren‚Äôt necessary to linear regression models, let‚Äôs explore them in this familiar setting.\nRun through the following discussion and code one step at a time. Take note of the general process, concepts, and questions you have.\n\n\nSTEP 1: model specification\nThis specifies the structure or general modeling algorithm we plan to use.\nIt does not specify anything about the variables of interest or our data.\n\nlm_spec &lt;- linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# Check it out\nlm_spec\n\n\n\nSTEP 2: recipe specification\nJust as a cooking recipe specifies the ingredients and how to prepare them, a tidymodels recipe specifies:\n\nthe variables in our relationship of interest (the ingredients)\nhow to pre-process or wrangle these variables (how to prepare the ingredients)\nthe data we‚Äôll use to explore these variables (where to find the ingredients)\n\nIt does not specify anything about the model structure we‚Äôll use to explore this relationship.\n\n# A simple recipe with NO pre-processing\ndata_recipe &lt;- recipe(height ~ wrist + ankle, data = humans)\n\n# Check it out\ndata_recipe # Not shpowing output in Bill's RStudio!\nhead(data_recipe) # Check the third output!\n\n\n\nSTEP 3: workflow creation (model + recipe)\nThis specifies the general workflow of our modeling process, including our model structure and our variable recipe.\n\nmodel_workflow &lt;- workflow() %&gt;%\n  add_recipe(data_recipe) %&gt;%\n  add_model(lm_spec)\n\n# Check it out\nmodel_workflow # 0 Recipe Steps- No pre-processing steps\n\n\n\nSTEP 4: Model estimation\nThis step estimates or fits our model of interest using our entire sample data.\nThe model (lm_spec) and variable details (here just height ~ wrist + ankle) are specified in the workflow, so we do not need to give that information again!\n\nmy_model &lt;- model_workflow %&gt;% \n  fit(data = humans)\n\n# Check it out\nmy_model\n\n\n\nSTEPS 5: Model evaluation\nTo get in-sample metrics, use my_model like normal.\n\n# example: calculate in-sample R^2\nmy_model %&gt;% \n  glance()\n\n# example: calculate in-sample MAE\nmy_model %&gt;%\n  augment(new_data = humans) %&gt;% # notice what data we're plugging in here!\n  mae(truth = height, estimate = .pred)\n\nTo get CV metrics, pass the workflow to fit_resamples along with information about how to randomly create folds.\n\n# conduct 10-fold CV, calculate R^2 on each test fold\nset.seed(253) # review: what is this line doing? why do we need it? \nmy_model_cv &lt;- model_workflow %&gt;% \n  fit_resamples(resamples = vfold_cv(humans, v = 10), # \"v\" is our \"k\" \n                metrics = metric_set(rsq)) # replace rsq with the metric of your choice!\n\n# Check it out\nmy_model_cv\n\nThen, proceed as usual‚Ä¶\n\n# get a summary of the CV metrics across all folds\nmy_model_cv %&gt;%\n  collect_metrics()\n## Error: object 'my_model_cv' not found\n\n# get the metrics for each fold\nmy_model_cv %&gt;%\n  unnest(.metrics)\n## Error: object 'my_model_cv' not found",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#collaborative-learning",
    "href": "activities/L05-model-selection.html#collaborative-learning",
    "title": "Model Selection",
    "section": "Collaborative Learning",
    "text": "Collaborative Learning\nTake 5 minutes to free-write in response to the following prompts, reflecting upon your strengths and areas for growth with respect to collaboration.\nIn Unit 1:\n\nHow actively did you contribute to group discussions?\nHow actively did you include ALL other group members in discussion?\nIn what ways did you (or did you not) help create a space where others feel comfortable making mistakes & sharing their ideas?\n\nMore generally:\n\nWhat has/hasn‚Äôt worked well for you when it comes to working on in-class exercises in small groups (in this class or others)?\nWhat would you like to try, or avoid, in this next unit?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#exercises-part-1-1",
    "href": "activities/L05-model-selection.html#exercises-part-1-1",
    "title": "Model Selection",
    "section": "Exercises: Part 1",
    "text": "Exercises: Part 1\nDesign your own algorithm.\n\n\nSolution\n\nThere is no ‚Äúcorrect‚Äù answer to this question ‚Äî we just want to see what you can come up with! With that said, a ‚Äúgood‚Äù algorithm should:\n\nbe clear to other humans\nbe clear to a machine (eg cannot utilize context)\nlead to a single model that uses 0‚Äì12 of our predictors\ndefine and provide directions for selecting any tuning parameters",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#notes-discussion-variable-selection-1",
    "href": "activities/L05-model-selection.html#notes-discussion-variable-selection-1",
    "title": "Model Selection",
    "section": "Notes & Discussion: Variable Selection",
    "text": "Notes & Discussion: Variable Selection\nBest Subset Selection Drawback\n\n\nSolution\n\nIt‚Äôs computationally expensive. For our humans example, we‚Äôd need to build 4096 models:\n\n2^12\n## [1] 4096\n\n\n\nBackward Stepwise Selection Implementation\n\n\nSolution\n\n\n# All 12 predictors\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;%  # use tidy to get p-values for each coefficient\n  filter(term != \"(Intercept)\") %&gt;% # exclude the intercept\n  mutate(p.value = round(p.value, 4)) %&gt;% # round the p-values for easier viewing\n  arrange(desc(p.value)) # added this line to arrange from largest to smallest p-value\n## # A tibble: 12 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 biceps   -0.0808     0.746    -0.108  0.915 \n##  2 neck      0.139      1.17      0.119  0.906 \n##  3 knee      0.151      0.941     0.160  0.874 \n##  4 wrist     0.836      2.32      0.361  0.721 \n##  5 ankle    -0.888      1.28     -0.693  0.494 \n##  6 abdomen   0.283      0.354     0.798  0.432 \n##  7 age      -0.112      0.132    -0.847  0.405 \n##  8 chest    -0.459      0.473    -0.971  0.340 \n##  9 forearm   2.25       1.80      1.25   0.223 \n## 10 weight    0.379      0.213     1.78   0.0864\n## 11 hip      -0.921      0.510    -1.81   0.0822\n## 12 thigh    -1.24       0.646    -1.92   0.066\n\n\n# 11 predictors (got rid of biceps)\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4)) %&gt;% \n  arrange(desc(p.value))\n## # A tibble: 11 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 neck       0.161     1.14      0.142  0.888 \n##  2 knee       0.180     0.886     0.203  0.841 \n##  3 wrist      0.907     2.18      0.416  0.681 \n##  4 ankle     -0.878     1.26     -0.699  0.490 \n##  5 abdomen    0.281     0.348     0.809  0.425 \n##  6 age       -0.111     0.130    -0.858  0.398 \n##  7 chest     -0.453     0.461    -0.982  0.334 \n##  8 forearm    2.17      1.62      1.34   0.192 \n##  9 hip       -0.902     0.470    -1.92   0.0652\n## 10 weight     0.369     0.190     1.94   0.0623\n## 11 thigh     -1.26      0.602    -2.09   0.0454\n\n\n# 10 predictors (got rid of neck)\nlm_spec %&gt;% \n  fit(height ~ age + weight  + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4)) %&gt;% \n  arrange(desc(p.value))\n## # A tibble: 10 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 knee       0.166     0.866     0.191  0.850 \n##  2 wrist      0.985     2.07      0.475  0.639 \n##  3 ankle     -0.884     1.23     -0.716  0.480 \n##  4 age       -0.111     0.127    -0.869  0.392 \n##  5 abdomen    0.298     0.322     0.924  0.363 \n##  6 chest     -0.460     0.451    -1.02   0.316 \n##  7 forearm    2.29      1.37      1.66   0.107 \n##  8 weight     0.377     0.179     2.11   0.0435\n##  9 thigh     -1.26      0.591    -2.14   0.0409\n## 10 hip       -0.931     0.416    -2.24   0.0331\n\nEtc.\n\n\nBackward Stepwise Selection Step-by-Step Results\n\n\nSolution\n\nIf you‚Äôre curious, here‚Äôs some code to implement all steps of the backward stepwise selection algorithm:\n\n\nCode\n# setup\npredictors &lt;- c(\"age\", \"weight\", \"neck\", \"chest\", \"abdomen\", \"hip\", \"thigh\", \"knee\", \"ankle\", \"biceps\", \"forearm\", \"wrist\")\np &lt;- length(predictors)\nkick_out &lt;- rep(0, p)\ncvs &lt;- rep(0, p)\n\n# loop through predictors\nfor(i in 1:12){\n  # fit model\n  my_model &lt;- lm_spec %&gt;% \n    fit(as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))), \n        data = humans) %&gt;% \n    tidy() %&gt;% \n    filter(term != \"(Intercept)\") %&gt;% \n    arrange(desc(p.value))\n  \n  # use 10-fold CV to get MAE for model\n  set.seed(253)\n  cv_process &lt;- lm_spec %&gt;% \n      fit_resamples(\n        as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))),\n        resamples = vfold_cv(humans, v = 10), \n        metrics = metric_set(mae)\n      ) %&gt;% \n      collect_metrics()\n  \n  # get name of worst variable (biggest p-value)\n  worst &lt;- as.data.frame(my_model)[1,1]\n  kick_out[i] &lt;- worst\n  \n  # get rid of worst variable from predictor list\n  predictors &lt;- predictors[predictors != worst]\n  \n  # save CV MAE for this model\n  cvs[i] &lt;- as.data.frame(cv_process)$mean\n}\n\nkick_out\n##  [1] \"biceps\"  \"neck\"    \"knee\"    \"wrist\"   \"ankle\"   \"age\"     \"abdomen\"\n##  [8] \"chest\"   \"thigh\"   \"forearm\" \"hip\"     \"weight\"\ncvs\n##  [1] 5.727898 5.522730 5.413292 5.368143 5.047014 5.013322 4.684182 4.460353\n##  [9] 4.385650 4.090791 3.733412 3.658251\n\n\n\nUsing a linear model with only weight to predict height, our prediction error would be on average 3.58 inches off from the truth on new data. In other words, we estimate that this model can predict a new person‚Äôs height within, on average, 3.58 inches.\nLess. We only have to build 12 models.\nBoth neck and wrist are kicked out early! The 1-predictor model produced by this algorithm isn‚Äôt necessarily the best 1-predictor model (same for any number of predictors). Backward stepwise selection is a greedy algorithm!\nThe value of the coefficient (and thus the p-value) is dependent on the other variables in the model as we are accounting for or conditioning on them.\n\n\n\nBackward Stepwise Selection Final Model\n\n\nSolution\n\n\nBased on our data, I think the model with 1 predictor seems pretty reasonable! It‚Äôs simple and has the smallest CV MAE. If you‚Äôre worried that model is too simple, the model with 2 predictors also has a similarly small MAE.\nIf I were looking at the other MAE plot, though, I might pick a model with 1 (the simplest), 2 (still simple, but better MAE than 1 predictor), or 5 predictors (the model with the best CV MAE).\nToo few predictors: model is too simple. Too many predictors: model is too overfit.\n\n\n\nForward Stepwise Selection\n\n\nSolution\n\n\nStart with 0 predictors. Fit all possible models with 1 predictor. Add the predictor with the smallest p-value. To this model, add a second predictor with the smallest p-value. Continue until all predictors are in the model. (More details in ISLR Section 6.1.2.)\nMore. For 12 predictors, we‚Äôd have to build 12 models in step 1, 11 models in step 2, etc. Thus 12 + 11 + ‚Ä¶ + 1 = 78 models total.\n\n\n\nMachine Learning vs Human Learning\n\n\nSolution\n\n\n1\n2",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#exercises-part-2-1",
    "href": "activities/L05-model-selection.html#exercises-part-2-1",
    "title": "Model Selection",
    "section": "Exercises: Part 2",
    "text": "Exercises: Part 2\nNo solutions for this part.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html",
    "href": "activities/L03-Overfitting.html",
    "title": "Overfitting",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#directions",
    "href": "activities/L03-Overfitting.html#directions",
    "title": "Overfitting",
    "section": "Directions",
    "text": "Directions\nLet‚Äôs build and evaluate a predicted model of an adult‚Äôs height (\\(y\\)) using some predictors \\(x_i\\) (e.g., age, weight, etc.).\n\nIntroduce yourself in whatever way you feel appropriate and check in with each other as human beings\nCome up with a team name\nWork through the steps below as a group\n\nEach group will be given a different sample of 40 adults\nStart by predicting height (in) using hip circumference (cm)\nEvaluate the model on your sample.\n\nBe prepared to share your answers to:\n\nHow good is your simple model?\nWhat would happen if we added more predictors?",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions",
    "href": "activities/L03-Overfitting.html#questions",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\n\nGoal\n\nLet‚Äôs build and evaluate a predictive model of an adult‚Äôs height (\\(y\\)) using some predictors \\(x_i\\) (eg: age, height, etc).\nSince \\(y\\) is quantitative this is a regression task.\nThere are countless possible models of \\(y\\) vs \\(x\\). We‚Äôll utilize a linear regression model:\n\n\\[y = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p + \\varepsilon\\]\n\nAnd after building this model, we‚Äôll evaluate it.\n\n\n\nData: Each group will be given a different sample of 40 adults.\n\n# Load packages needed for this analysis\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nUsing the following starter code, fill in the blank in the URL with the appropriate number depending on your group number.\n\nGroup 1: 50\nGroup 2: 143\n\nREMINDER: Do not edit the starter code directly. Instead, copy-paste the code into an empty code chunk below. Then, make edits (eg fill in blanks) in that second code chunk.\n\n# Load data\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat___.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\nCheck out a density plot of your outcome:\n\n# Plot data\nggplot(humans, aes(x = ___)) + \n  geom____()\n\n\n\nModel building: Build a linear regression model of height (in) by hip circumference (cm).\n\n# STEP 1: model specification\nlm_spec &lt;- ___() %&gt;% \n  set_mode(___) %&gt;% \n  set_engine(___)\n\n\n# STEP 2: model estimation\nmodel_1 &lt;- ___ %&gt;% \n  ___(height ~ hip, data = humans)\n\n\n# Check out the coefficients\n# Do all groups have the same coefficients? Should they?\n\n\n\nModel evaluation: How good is our model?\n\n# Calculate the R^2 for model_1\n\n\n# Use your model to predict height for your subjects\n# Just print the first 6 results\nmodel_1 %&gt;% \n  ___(new_data = ___) %&gt;% \n  head()\n\n\n# Calculate the MAE, i.e. typical prediction error, for your model\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  ___(truth = ___, estimate = ___)\n\n\n\nReflection\nIn addition to hip circumference, suppose we incorporated more predictors into our model of height. What would happen to \\(R^2\\)? To the MAE?",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#directions-1",
    "href": "activities/L03-Overfitting.html#directions-1",
    "title": "Overfitting",
    "section": "Directions",
    "text": "Directions\n\nTake 5 minutes to complete exercises 1 and 2 (choosing one of three models).\nWe‚Äôll pause for a few minutes to discuss each group‚Äôs answers to these exercises.\nThen, and only then, you can finish exercises 3 - 5.\n\nREMINDERS:\n\nBe kind to yourself/each other. You will make mistakes!\nCollaborate:\n\nactively contribute to discussion (don‚Äôt work on your own)\nactively include all group members in discussion\ncreate a space where others feel comfortable making mistakes and sharing their ideas\nstay in sync",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions-1",
    "href": "activities/L03-Overfitting.html#questions-1",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\n\nSelect a model\n\nConsider 3 different models of height, estimated below. As a group, use your data to choose which is the best predictive model of height. Calculate the MAE for this model.\n\n# height vs hip\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_1 %&gt;% \n  tidy()\n## Error: object 'model_1' not found\n\n# height vs hip & weight\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_2 %&gt;% \n  tidy()\n## Error: object 'model_2' not found\n\n# height vs a lot of predictors (AND some interaction terms)\nmodel_3 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat * abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_3 %&gt;% \n  tidy()\n## Error: object 'model_3' not found\n\n\n# Calculate the MAE for your model\n___ %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## Error in parse(text = input): &lt;text&gt;:2:2: unexpected input\n## 1: # Calculate the MAE for your model\n## 2: __\n##     ^\n\n\n\nüõë WAIT. Don‚Äôt keep going.\n\n\n\n\n\n\n\nDon‚Äôt peek\nWhat do you know?! 40 new people just walked into the doctor‚Äôs office and the doctor wants to predict their height:\n\n# Import the new data\nnew_patients &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat182.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\n\n\nIntuition\nConsider using your models to predict height for these 40 new subjects. On average, do you think these predictions will be better or worse than for your original patients? Why?\n\n\n\n\n\nHow well does your models do in the real world?\nUse your model to predict height for the new patients and calculate the typical prediction error (MAE). Record this in the Google sheet. (MAE: NEW PATIENTS)\n\n\n___ %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## Error in parse(text = input): &lt;text&gt;:1:2: unexpected input\n## 1: __\n##      ^\n\n\n\n\n\nReflection\nIn summary, which model seems best? What‚Äôs the central theme here?\n\n\nIn general, models tend to perform worse on new data than on the data on which they were built/trained. In this particular dataset, Model 2 looks best on new data, and Model 3 performs horribly. Model 3 is overfit to the training data. This is more likely to happen with an overly complicated model.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#overfitting",
    "href": "activities/L03-Overfitting.html#overfitting",
    "title": "Overfitting",
    "section": "Overfitting",
    "text": "Overfitting\nWhen we add more and more predictors into a model, it can become overfit to the noise in our sample data:\n\nour model loses the broader trend / big picture\nthus does not generalize to new data\nthus results in bad predictions and a bad understanding of the relationship among the new data points\n\n\n\nPreventing overfitting: training and testing\n\nIn-sample metrics, i.e.¬†measures of how well the model performs on the same sample data that we used to build it, tend to be overly optimistic and lead to overfitting.\nInstead, we should build and evaluate, or train and test, our model using different data.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#r-code",
    "href": "activities/L03-Overfitting.html#r-code",
    "title": "Overfitting",
    "section": "R Code",
    "text": "R Code\n\n\n\n\n\n\nNote\n\n\n\nThis section is for future reference. It is a summary of code you‚Äôll learn below for creating and applying training and testing data. You don‚Äôt need to (and in fact should not) run the code in this section‚Äîjust use this as example code for future reference.\n\n\nSuppose we wish to build and evaluate a linear regression model of y vs x1 and x2 using our sample_data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nSplit the sample data into training and test sets\n\n# Set the random number seed\nset.seed(___)\n\n# Split the sample_data\n# \"prop\" is the proportion of data assigned to the training set\n# it must be some number between 0 and 1\ndata_split &lt;- initial_split(sample_data, strata = y, prop = ___)\n\n# Get the training data from the split\ndata_train &lt;- data_split %&gt;% \n  training()\n\n# Get the testing data from the split\ndata_test &lt;- data_split %&gt;% \n  testing()\n\nBuild a training model\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\nmodel_train &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = data_train)\n\nUse the training model to make predictions for the test data\n\n# Make predictions\nmodel_train %&gt;% \n  augment(new_data = data_test)\n\nEvaluate the training model using the test data\n\n# Calculate the test MAE\nmodel_train %&gt;% \n  augment(new_data = data_test) %&gt;% \n  mae(truth = y, estimate = .pred)",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions-2",
    "href": "activities/L03-Overfitting.html#questions-2",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\nThe following exercises are inspired by Chapter 5.3.1 of ISLR.\n\n# Load packages\n# NOTE: You might first need to install the ISLR package\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ISLR) # install the package ISLR if you haven't already\n\n# Load data\ndata(Auto)\n\n# Select three variables from Auto data\n# Save as a data frame called \"cars\"\ncars &lt;- Auto %&gt;% \n  dplyr::select(mpg, horsepower, year)\nhead(cars)\n##   mpg horsepower year\n## 1  18        130   70\n## 2  15        165   70\n## 3  18        150   70\n## 4  16        150   70\n## 5  17        140   70\n## 6  15        198   70\ndim(cars)\n## [1] 392   3\n\n\n\nLet‚Äôs use the cars data to compare three linear regression models of fuel efficiency in miles per gallon (mpg) by engine power (horsepower):\n\n# Raw data\ncars_plot &lt;- ggplot(cars, aes(x = horsepower, y = mpg)) + \n  geom_point()\ncars_plot\n\n\n\n\n\n\n\n\n\n# model 1: 1 predictor (y = b0 + b1 x)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# model 2: 2 predictors (y = b0 + b1 x + b2 x^2)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 2))\n\n\n\n\n\n\n\n\n\n# model 3: 19 predictors (y = b0 + b1 x + b2 x^2 + ... + b19 x^19)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 19))\n\n\n\n\n\n\n\n\n\n\nGoal\nLet‚Äôs evaluate and compare these models by training and testing them using different data.\n\n\n\n155 review: set.seed()\n\nRun the two chunks below multiple times each. Afterward, summarize what set.seed() does and why it‚Äôs important to being able to reproduce a random sample.\n\nsample_n(cars, 2)\n##      mpg horsepower year\n## 217 31.5         68   77\n## 388 26.0         92   82\n\n\nset.seed(253)\nsample_n(cars, 2)\n##      mpg horsepower year\n## 224 15.5        145   77\n## 61  20.0         90   72\n\n¬†\n\nTraining and test sets\n\nLet‚Äôs randomly split our original 392 sample cars into two separate pieces: select 80% of the cars to train (build) the model and the other 20% to test (evaluate) the model.\n\n# Set the random number seed\nset.seed(8)\n    \n# Split the cars data into 80% / 20%\n# Ensure that the sub-samples are similar with respect to mpg\ncars_split &lt;- initial_split(cars, strata = mpg, prop = 0.8)\n\n\n# Check it out\n# What do these numbers mean?\ncars_split\n## &lt;Training/Testing/Total&gt;\n## &lt;312/80/392&gt;\n\n\n# Get the training data from the split\ncars_train &lt;- cars_split %&gt;% \n  training()\n    \n# Get the testing data from the split\ncars_test &lt;- cars_split %&gt;% \n  testing()\n\n\n# The original data has 392 cars\nnrow(cars)\n## [1] 392\n    \n# How many cars are in cars_train?\nnrow(cars_train)\n## [1] 312\n\n# How many cars are in cars_test?\nnrow(cars_test)\n## [1] 80\n\n\n\n\nReflect on the above code\n\n\nWhy do we want the training and testing data to be similar with respect to mpg (strata = mpg)? What if they weren‚Äôt?\n\n\nSuppose, for example, the training cars all had higher mpg than the test cars. Then the training model likely would not perform well on the test cars, thus we‚Äôd get an overly pessimistic measure of model quality.\n\n\nWhy did we need all this new code instead of just using the first 80% of cars in the sample for training and the last 20% for testing?\n\n\nIf the cars are ordered in some way (eg: from biggest to smallest) then our training and testing samples would have systematically different properties.\n\n\n\n\nBuild the training model\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- ___ %&gt;% \n  ___(mpg ~ poly(horsepower, 19), data = ___)\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- lm_spec %&gt;% \n  fit(mpg ~ poly(horsepower, 19), data = cars_train)\n\n\n\n\nEvaluate the training model\n\n\n# How well does the TRAINING model predict the TRAINING data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = ___) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n\n\n# How well does the training model predict the training data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_train) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        2.99\n\n\n# How well does the TRAINING model predict the TEST data?\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = ___) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n\n\n\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_test) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        6.59\n\n\n\n\nPunchline\n\nThe table below summarizes your results for train_model_19 as well as the other two models of interest. (You should confirm the other two model results outside of class!)\n\n\n\nModel\nTraining MAE\nTesting MAE\n\n\n\n\nmpg ~ horsepower\n3.78\n4.00\n\n\nmpg ~ poly(horsepower, 2)\n3.20\n3.49\n\n\nmpg ~ poly(horsepower, 19)\n2.99\n6.59\n\n\n\nLet us discuss following and reflect on why each answer makes sense:\n\nWithin each model, how do the training errors compare to the testing errors? (This isn‚Äôt always the case, but is common.)\n\n\nthe training errors are smaller\n\n\nWhat about the training and test errors for the third model suggest that it is overfit to our sample data?\n\n\nthe test MAE is much larger than the training MAE\n\n\nWhich model seems the best with respect to the training errors?\n\n\nthe 19th order polynomial\n\n\nWhich model is the best with respect to the testing errors?\n\n\nthe quadratic\n\n\nWhich model would you choose?\n\n\nthe quadratic\n\n\n\n\nFinal reflection\n\n\nThe training / testing procedure provided a more honest evaluation and comparison of our model predictions. How might we improve upon this procedure? What problems can you anticipate in splitting our data into 80% / 20%?\nSummarize the key themes from today in your own words.\n\n\n\n\nSTAT 155 REVIEW: data drill\n\n\nConstruct and interpret a plot of mpg vs horsepower and year.\nCalculate the average mpg.\nCalculate the average mpg for each year. HINT: group_by()\nPlot the average mpg by year.\n\n\n\n\nCode for the curious (optional)\n\nI wrote a function calculate_MAE() to automate the calculations in the table. If you‚Äôre curious, pick through this code!\n\n# Write function to calculate MAEs\ncalculate_MAE &lt;- function(poly_order){\n  # Construct a training model\n  model &lt;- lm_spec %&gt;% \n    fit(mpg ~ poly(horsepower, poly_order), cars_train)\n  \n  # Calculate the training MAE\n  train_it &lt;- model %&gt;% \n    augment(new_data = cars_train) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Calculate the testing MAE\n  test_it &lt;- model %&gt;% \n    augment(new_data = cars_test) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Return the results\n  return(data.frame(train_MAE = train_it$.estimate, test_MAE = test_it$.estimate))\n}\n    \n# Calculate training and testing MSEs\ncalculate_MAE(poly_order = 1)\n##   train_MAE test_MAE\n## 1  3.779331 4.004333\ncalculate_MAE(poly_order = 2)\n##   train_MAE test_MAE\n## 1  3.199882 3.487022\ncalculate_MAE(poly_order = 19)\n##   train_MAE test_MAE\n## 1  2.989305 6.592341\n\n# For those of you interested in trying all orders...\n\nresults &lt;- purrr::map_df(1:19,calculate_MAE) %&gt;% \n  mutate(order = 1:19) %&gt;%\n  pivot_longer(cols=1:2,names_to='Metric',values_to = 'MAE') \n\nresults %&gt;%\n  ggplot(aes(x = order, y = MAE, color = Metric)) + \n  geom_line() + \n  geom_point(data = results %&gt;% filter(Metric == 'test_MAE') %&gt;% slice_min(MAE)) + \n  geom_point(data = results %&gt;% filter(Metric == 'train_MAE') %&gt;% slice_min(MAE))",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#small-group-discussion-1",
    "href": "activities/L03-Overfitting.html#small-group-discussion-1",
    "title": "Overfitting",
    "section": "Small Group Discussion",
    "text": "Small Group Discussion\nData\n\n\nSolution\n\nEach group will have slightly different plots because they have different samples of data.\nThroughout the solutions I‚Äôll use one of the datasets as an example:\n\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat50.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\nggplot(humans, aes(x = height)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\n\nModel building\n\n\nSolution\n\nEach group will have slightly different coefficients because they have different samples of data.\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode('regression') %&gt;% \n  set_engine('lm')\n\n# STEP 2: model estimation\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\n\n# Check out the coefficients\nmodel_1  %&gt;% \n  tidy()\n## # A tibble: 2 √ó 5\n##   term        estimate std.error statistic      p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n## 1 (Intercept)   52.5      7.68        6.84 0.0000000460\n## 2 hip            0.179    0.0778      2.30 0.0272\n\n\n\nModel evaluation\n\n\nSolution\n\nAgain, each group will have slightly different answers here because they have different samples of data.\n\n# Calculate the R^2 for model_1\nmodel_1 %&gt;%\n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.125         0.101  2.26      5.29  0.0272     1  -86.1  178.  183.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# Use your model to predict height for your subjects\n# Just print the first 6 results\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  head()\n## # A tibble: 6 √ó 21\n##   .pred .resid fatBrozek body_fat density   age weight height adiposity\n##   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n## 1  70.3  -1.09      24.7     25.4    1.04    43   177    69.2      26  \n## 2  70.8  -1.52      22       22.5    1.05    38   187.   69.2      27.5\n## 3  70.2  -1.19       9.4      8.8    1.08    29   161.   69        23.8\n## 4  68.9   4.58       7.1      6.3    1.08    49   153.   73.5      19.9\n## 5  69.3   2.91       9.9      9.4    1.08    23   160.   72.2      21.6\n## 6  70.2  -2.48      22.7     23.3    1.05    52   167    67.8      25.6\n## # ‚Ñπ 12 more variables: fatFreeWeight &lt;dbl&gt;, neck &lt;dbl&gt;, chest &lt;dbl&gt;,\n## #   abdomen &lt;dbl&gt;, hip &lt;dbl&gt;, thigh &lt;dbl&gt;, knee &lt;dbl&gt;, ankle &lt;dbl&gt;,\n## #   biceps &lt;dbl&gt;, forearm &lt;dbl&gt;, wrist &lt;dbl&gt;, hipin &lt;dbl&gt;\n\n# Calculate the MAE, i.e. typical prediction error, for your model\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.88\n\n\n\nReflection\n\n\nSolution\n\n\\(R^2\\) would increase and MAE would decrease.\n\n\nBONUS\n\n\nSolution\n\nReview your notes from last class and stop by office hours to discuss!",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#exercises-part-1-1",
    "href": "activities/L03-Overfitting.html#exercises-part-1-1",
    "title": "Overfitting",
    "section": "Exercises (Part 1)",
    "text": "Exercises (Part 1)\n\nSelect a model\n\n\n\nSolution\n\nWill vary by group. MAE is calculated here for each model.\nREMINDER: Throughout the solutions I‚Äôm using one of the datasets as an example: bodyfat50.csv.\n\n# Build the models\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight, data = humans)\nmodel_3 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat * abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\n# Evaluate the models\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.88\nmodel_2 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.67\nmodel_3 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard    1.53e-10\n\n\n\n\nShare your results.\n\n\n\nSolution\n\nDone! (Model 3 had the best MAE for this dataset.)\n\n\n\nIntuition.\n\n\n\nSolution\n\nAnswers will vary.\n\n\n\nHow well does your model do in the real world?\n\n\n\nSolution\n\n\n# Predict height (assume, for example, I choose model_1)\nmodel_1 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  head()\n## # A tibble: 6 √ó 21\n##   .pred .resid fatBrozek body_fat density   age weight height adiposity\n##   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n## 1  71.5 -1.96       27.1     28      1.04    62   201.   69.5      29.3\n## 2  70.4 -0.141      20.9     21.3    1.05    42   163    70.2      23.3\n## 3  69.7 -0.497      26.1     27      1.04    72   168    69.2      24.7\n## 4  69.1 -1.39        4.1      3      1.09    35   152.   67.8      23.4\n## 5  68.5 -2.99        1.9      0.7    1.1     35   126.   65.5      20.6\n## 6  71.9 -1.91       31       32.3    1.03    57   206.   70        29.5\n## # ‚Ñπ 12 more variables: fatFreeWeight &lt;dbl&gt;, neck &lt;dbl&gt;, chest &lt;dbl&gt;,\n## #   abdomen &lt;dbl&gt;, hip &lt;dbl&gt;, thigh &lt;dbl&gt;, knee &lt;dbl&gt;, ankle &lt;dbl&gt;,\n## #   biceps &lt;dbl&gt;, forearm &lt;dbl&gt;, wrist &lt;dbl&gt;, hipin &lt;dbl&gt;\n\n\n# Calculate the MAE for model_1\nmodel_1 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.73\n\n# Calculate the MAE for model_2\nmodel_2 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.68\n\n# Calculate the MAE for model_3\nmodel_3 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        105.\n\n\n\n\nReflection\n\n\n\nSolution\n\nA few takeaways:\n\nIn general, models tend to perform worse on new data than on the data on which they were built/trained.\nIn this particular dataset, Model 2 looks best on new data, and Model 3 performs horribly.\nModel 3 is overfit to the training data. This is more likely to happen with an overly complicated model.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#exercises-part-2-1",
    "href": "activities/L03-Overfitting.html#exercises-part-2-1",
    "title": "Overfitting",
    "section": "Exercises (Part 2)",
    "text": "Exercises (Part 2)\n\n155 review: set.seed()\n\n\n\nSolution\n\nset.seed() is used to create the same ‚Äúrandom numbers‚Äù each time a random function is called.\nNote that is if you want to get exactly the same random result, set.seed() needs to be run right before the call to random function, every time.\nIt is important so that you can reproduce the same random sample every time you knit your work.\nThere might be different results across computers/platforms as they might be using different pseudo-random number generators. The most important thing is for your code to be consistent.\n\n\n\nTraining and test sets\n\n\n\nSolution\n\n\n# Set the random number seed\nset.seed(8)\n\n# Split the cars data into 80% / 20%\n# Ensure that the sub-samples are similar with respect to mpg\ncars_split &lt;- initial_split(cars, strata = mpg, prop = 0.8)\n\n# Check it out\ncars_split\n## &lt;Training/Testing/Total&gt;\n## &lt;312/80/392&gt;\n\n# Get the training data from the split\ncars_train &lt;- cars_split %&gt;% \n  training()\n\n# Get the testing data from the split\ncars_test &lt;- cars_split %&gt;% \n  testing()\n\n# The original data has 392 cars\nnrow(cars)\n## [1] 392\n\n# How many cars are in cars_train?\nnrow(cars_train)\n## [1] 312\n\n# How many cars are in cars_test?\nnrow(cars_test)\n## [1] 80\n\n\n\n\nReflect on the above code\n\n\n\nSolution\n\n\nSuppose, for example, the training cars all had higher mpg than the test cars. Then the training model likely would not perform well on the test cars, thus we‚Äôd get an overly pessimistic measure of model quality.\nIf the cars are ordered in some way (eg: from biggest to smallest) then our training and testing samples would have systematically different properties.\n\n\n\n\nBuild the training model\n\n\n\nSolution\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- lm_spec %&gt;% \n  fit(mpg ~ poly(horsepower, 19), data = cars_train)\n\n\n\n\nEvaluate the training model\n\n\n\nSolution\n\n\n# How well does the training model predict the training data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_train) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        2.99\n\n# How well does the training model predict the test data?\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_test) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        6.59\n\n\n\n\nPunchline\n\n\n\nSolution\n\n\nthe training errors are smaller\n\nthe test MAE is much larger than the training MAE\nthe 19th order polynomial\n\nthe quadratic\n\nthe quadratic\n\nCode for the curious\nI wrote a function calculate_MAE() to automate the calculations in the table. If you‚Äôre curious, pick through this code!\n\n# Write function to calculate MAEs\ncalculate_MAE &lt;- function(poly_order){\n  # Construct a training model\n  model &lt;- lm_spec %&gt;% \n    fit(mpg ~ poly(horsepower, poly_order), cars_train)\n  \n  # Calculate the training MAE\n  train_it &lt;- model %&gt;% \n    augment(new_data = cars_train) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Calculate the testing MAE\n  test_it &lt;- model %&gt;% \n    augment(new_data = cars_test) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Return the results\n  return(data.frame(train_MAE = train_it$.estimate, test_MAE = test_it$.estimate))\n}\n    \n# Calculate training and testing MSEs\ncalculate_MAE(poly_order = 1)\n##   train_MAE test_MAE\n## 1  3.779331 4.004333\ncalculate_MAE(poly_order = 2)\n##   train_MAE test_MAE\n## 1  3.199882 3.487022\ncalculate_MAE(poly_order = 19)\n##   train_MAE test_MAE\n## 1  2.989305 6.592341\n\n\n# For those of you interested in trying all orders...\n\nresults &lt;- purrr::map_df(1:19,calculate_MAE) %&gt;% \n  mutate(order = 1:19) %&gt;%\n  pivot_longer(cols=1:2,names_to='Metric',values_to = 'MAE') \n\nresults %&gt;%\n  ggplot(aes(x = order, y = MAE, color = Metric)) + \n  geom_line() + \n  geom_point(data = results %&gt;% filter(Metric == 'test_MAE') %&gt;% slice_min(MAE)) + \n  geom_point(data = results %&gt;% filter(Metric == 'train_MAE') %&gt;% slice_min(MAE))\n\n\n\n\n\n\n\n\n\n\n\nFinal reflection\n\n\n\nSolution\n\nThis will be discussed in the next video!\n \n\n\n\nSTAT 155 REVIEW: data drill\n\n\n\nSolution\n\n\n# a. One of many options\nggplot(cars, aes(x = horsepower, y = mpg, color = year)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# b\ncars %&gt;% \n  summarize(mean(mpg))\n##   mean(mpg)\n## 1  23.44592\n\n# c\ncars %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_mpg = mean(mpg))\n## # A tibble: 13 √ó 2\n##     year mean_mpg\n##    &lt;dbl&gt;    &lt;dbl&gt;\n##  1    70     17.7\n##  2    71     21.1\n##  3    72     18.7\n##  4    73     17.1\n##  5    74     22.8\n##  6    75     20.3\n##  7    76     21.6\n##  8    77     23.4\n##  9    78     24.1\n## 10    79     25.1\n## 11    80     33.8\n## 12    81     30.2\n## 13    82     32\n\n# d\ncars %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_mpg = mean(mpg)) %&gt;% \n  ggplot(aes(y = mean_mpg, x = year)) + \n  geom_point()",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html",
    "href": "activities/L01-introductions.html",
    "title": "Introduction to Statistical Machine Learning",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#whats-machine-learning",
    "href": "activities/L01-introductions.html#whats-machine-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "What‚Äôs Machine Learning?",
    "text": "What‚Äôs Machine Learning?\n\n\n‚ÄúMachine Learning‚Äù was coined back in 1959 by Arthur Samuel, an early contributor to AI.\nFrom Kohavi & Provost (1998): Machine Learning is the exploration & application of algorithms that can learn from existing patterns and make predictions using data.\n\nIMPORTANT: humans are in charge of the ‚Äúexploration & application‚Äù!\n\nFrom James et al (2021) [link]: Statistical Learning refers to a vast set of tools for understanding data.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#in-stat-253-we-will",
    "href": "activities/L01-introductions.html#in-stat-253-we-will",
    "title": "Introduction to Statistical Machine Learning",
    "section": "In STAT 253 we will‚Ä¶",
    "text": "In STAT 253 we will‚Ä¶\n\n\nPick up where STAT 155 left off, acquiring tools that can be used to learn from data in greater depth and a wider variety of settings. (STAT 155 is a foundational subset of ML!)\nExplore universal ML concepts using tools and software common among statisticians (hence ‚Äústatistical‚Äù machine learning).\nSurvey a breadth of modern ML tools and algorithms that fall into the workflow below. Part of the cognitive load will be:\n\nkeeping all the tools in place (what are they and when to use them)\nunderstanding the connections between the tools\nadapting (not memorizing) code to implement each tool\na new topic almost every day\n\nWe‚Äôll focus on concepts and applications over mathematical theory. (Come chat with me in office hours if you‚Äôre interested in learning more about the theory!)",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#course-structure",
    "href": "activities/L01-introductions.html#course-structure",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Course Structure",
    "text": "Course Structure",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#before-class",
    "href": "activities/L01-introductions.html#before-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Before Class",
    "text": "Before Class\nIn order to dedicate our class time to hands-on learning, you will prepare for class by watching short videos, reading from our textbook, and completing short quizzes (checkpoints) to assess your initial understanding of concepts. You can reattempt each checkpoint question multiple times, with a small penalty for incorrect responses.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#during-class",
    "href": "activities/L01-introductions.html#during-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "During Class",
    "text": "During Class\nDuring class time, you will engage with each other in exercises and discussions that build upon the pre-class work. Please bring your laptop to class every day. Consistent attendance and active participation in these activities is expected of all students and, most importantly, will be crucial for your learning!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#after-class",
    "href": "activities/L01-introductions.html#after-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "After Class",
    "text": "After Class\nAfter class, you will be expected to finish any remaining exercises from the class activity and review/organize your notes. For each unit, you will also complete homework assignments designed to help you practice and synthesize material and provide an opportunity to receive feedback to further guide your learning.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#types-of-ml-tasks",
    "href": "activities/L01-introductions.html#types-of-ml-tasks",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Types of ML Tasks",
    "text": "Types of ML Tasks\n\nStatistical machine learning tools can be classified as follows:\n\nsupervised or unsupervised\nwithin supervised learning: regression vs classification\nwithin unsupervised learning: clustering vs dimension reduction\n\nKnowing which of these scenarios your research question falls into is an important first step in identifying which tool to use!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#supervised-learning",
    "href": "activities/L01-introductions.html#supervised-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nWe want to model the relationship between some output variable1 \\(y\\) and input variables2 \\(x = (x_1, x_2,..., x_p)\\):\n\\[\n\\begin{split}\ny\n& = f(x) + \\varepsilon \\\\\n& = \\text{(trend in the relationship) } + \\text{ (residual deviation from the trend)} \\\\\n\\end{split}\n\\]\nTypes of supervised learning tasks:\n\nregression: \\(y\\) is quantitative\nexample:\n\\(y\\) = number of dental caries (cavities)\n\\(x\\) = (genetic information at millions of markers, sex, age, age\\(^2\\), etc)\nproject details\nclassification: \\(y\\) is categorical\nexample:\n\\(y\\) = whether a patient experienced adverse surgery outcomes after undergoing an upper endoscopy (yes, no)\n\\(x\\) = (administration of sedation [anesthesia professional, nurse], age, medical comorbidities [eg sleep apnea], etc.)\nproject details",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#unsupervised-learning",
    "href": "activities/L01-introductions.html#unsupervised-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nWe have some input variables \\(x = (x_1, x_2,..., x_p)\\) but there‚Äôs no output variable \\(y\\). Thus the goal is to use \\(x\\) to understand and/or modify the structure of our data.\nTypes of unsupervised learning tasks:\n\n\n\n\nclustering: Identify and examine groups or clusters of data points that are similar with respect to their \\(x_i\\) values.\nexample:\n\\(x\\) = (genetic data)\nproject details (led by a Mac alum!)\ndimension reduction: Turn the original set of \\(p\\) input variables, which are potentially correlated, into a smaller set of \\(k &lt; p\\) variables which still preserve the majority of information in the originals.\nexample:\n\\(x\\) = (genetic data)\nproject details\n\n\n\n\n\n\nSupplemental Figure 2A from Barragan et al (2023) [link] uses both clustering and dimension reduction!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#instructions",
    "href": "activities/L01-introductions.html#instructions",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Instructions",
    "text": "Instructions\n\nDiscuss the following scenarios as a group, talking through your ideas, questions, and reasoning as you go.\nWrite down your answers, and any insights or questions that come up while working, in your notebook or simply type in here and render your own work!\nI‚Äôll move around to groups to check in on your progress and see what questions you have.\nYou can check your answers by clicking the drop-down ‚ÄúSolutions‚Äù button.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#questions",
    "href": "activities/L01-introductions.html#questions",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Questions",
    "text": "Questions\nIndicate whether each scenario below represents a regression, classification, or clustering task.\n\nHow is the number of people that rent bikes on a given day in Washington, D.C. (\\(y\\)) explained by the temperature (\\(x_1\\)) and whether or not it‚Äôs a weekend (\\(x_2\\))?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nregression. there‚Äôs a quantitative output variable \\(y\\).\n\n\n\nGiven the observed bill length (\\(x_1\\)) and bill depth (\\(x_2\\)) on a set of penguins, how many different penguin species might there be?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nclustering. there‚Äôs no output variable \\(y\\).\n\n\n\nHow can we determine whether somebody has a certain infection (\\(y\\)) based on two different blood sample measurements, Measure A (\\(x_1\\)) and Measure B (\\(x_2\\))?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nclassification. there‚Äôs a categorical output variable \\(y\\).\n\n\n\nMachine learn about past students! Scenario A.\nThe following data were collected from past STAT 253 students and were analyzed using a machine learning algorithm. The questions were about their major (STAT/DS and Other), Activity (readng, streaming), walk time to MAC, Photo rating, class year, ). In your groups: (1) brainstorm what research question is being investigated; (2) determine whether this is a regression, classification, or clustering task; and (3) summarize what the output tells you about the students.\n\n\n\n\nSolution\n\n\npredict someone‚Äôs major based on ‚Äòother‚Äô survey responses\nclassification (\\(y\\) = major is categorical)\n(will vary by semester ‚Äì what do you learn about the majors represented in this class and the variables that are useful for predicting it?)\n\n\n\n\nMachine learn about past students! Scenario B.\nSame directions as for Scenario A: (1) brainstorm what research question is being investigated; (2) determine whether this is a regression, classification, or clustering task; and (3) summarize what the output tells you about the students.\n\n\n\n\nSolution\n\n\npredict walk time to Mac based on photo rating and class year\nregression (\\(y\\) = time to mac is quantitative)\n(answers will vary by semester ‚Äì what do you learn about the relationships between these variables?)\n\n\n\n\nUse Spotify users‚Äô previous listening behavior to identify groups of similar users.\n\n\n\nSolution\n\nclustering\n\n \n\nPredict workers‚Äô wages by their years of experience.\n\n\n\n\nSolution\n\nregression (\\(y\\) = wages)\n\n\n\nPredict workers‚Äô wages by their college major.\n\n\n\n\nSolution\n\nregression (\\(y\\) = wages)\n\n\n\nUse a customer‚Äôs age to predict whether they‚Äôve seen the Barbie movie.\n\n\n\n\nSolution\n\nclassification (\\(y\\) = whether or not watched the film)\n\n\n\nLook for similarities among genetic samples taken from a group of patients.\n\n\n\n\nSolution\n\nclustering (no outcome \\(y\\))",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#whats-next",
    "href": "activities/L01-introductions.html#whats-next",
    "title": "Introduction to Statistical Machine Learning",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nWhat to work on after class today:\n\ncomplete the pre-class tasks for next class on Friday (videos/reading/checkpoint)- note that no class on Wednesday!\n\nreview the checkpoint instructions & policies on Moodle before you start!\n\nstart HW0 (I will post it soon)\n\ndue Friday (at 11:59 pm)\nreview the Stat 155 Review resources as needed\n\ncomplete the recommended R and RStudio Setup steps\ncarefully review the course logistics (in the course website)",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#footnotes",
    "href": "activities/L01-introductions.html#footnotes",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\notherwise known as outcome, response, dependent variable‚Ü©Ô∏é\notherwise known as predictors, features, independent variables‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "R_Resources.html",
    "href": "R_Resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Tidymodels package documentation\nTidy Modeling with R textbook (Max Kuhn and Julia Silge)\nISLR Labs with Tidymodels (Emil Hvitfeldt)\nIntro to Tidymodels Presentation (Lucy D‚ÄôAgostino McGowan)\n\n\n\n\n\nCOMP/STAT 112 website (with code examples and videos)\nR for Data Science\nExploratory Data Analysis with R\nJohn‚Äôs Hopkins Tidyverse course text\n\n\n\n\n\nggplot2 reference\nColors in R\n\n\n\n\n\nCOMP/STAT 112 website (including an example quarto document)\nQuarto cheatsheet\nQuarto tutorial\nComprehensive Quarto Guide\n\n\n\n\n\nRStudio cheatsheets\nAdvanced R\nR Programming Wikibook\nDebugging in R\n\nArticle\nVideo\n\n\n\n\n\n\nCreating new variables\ncase_when() from the dplyr package is a very versatile function for creating new variables based on existing variables. This can be useful for creating categorical or quantitative variables and for creating indices from multiple variables.\n\n# Turn quant_var into a Low/Med/High version\ndata &lt;- data %&gt;%\n    mutate(cat_var = case_when(\n            quant_var &lt; 10 ~ \"Low\",\n            quant_var &gt;= 10 & quant_var &lt;= 20 ~ \"Med\",\n            quant_var &gt; 20 ~ \"High\"\n        )\n    )\n\n# Turn cat_var (A, B, C categories) into another categorical variable\n# (collapse A and B into one category)\ndata &lt;- data %&gt;%\n    mutate(new_cat_var = case_when(\n            cat_var %in% c(\"A\", \"B\") ~ \"A or B\"\n            cat_var==\"C\" ~ \"C\"\n        )\n    )\n\n# Turn a categorical variable (x1) encoded as a numerical 0/1/2 variable into a different quantitative variable\n# Doing this for multiple variables allows you to create an index\ndata &lt;- data %&gt;%\n    mutate(x1_score = case_when(\n            x1==0 ~ 10,\n            x1==1 ~ 20,\n            x1==2 ~ 50\n        )\n    )\n\n# Add together multiple variables with mutate\ndata &lt;- data %&gt;%\n    mutate(index = x1_score + x2_score + x3_score)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#tidymodels-resources",
    "href": "R_Resources.html#tidymodels-resources",
    "title": "R Resources",
    "section": "",
    "text": "Tidymodels package documentation\nTidy Modeling with R textbook (Max Kuhn and Julia Silge)\nISLR Labs with Tidymodels (Emil Hvitfeldt)\nIntro to Tidymodels Presentation (Lucy D‚ÄôAgostino McGowan)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#tidyverse-resources",
    "href": "R_Resources.html#tidyverse-resources",
    "title": "R Resources",
    "section": "",
    "text": "COMP/STAT 112 website (with code examples and videos)\nR for Data Science\nExploratory Data Analysis with R\nJohn‚Äôs Hopkins Tidyverse course text",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#visualization-resources",
    "href": "R_Resources.html#visualization-resources",
    "title": "R Resources",
    "section": "",
    "text": "ggplot2 reference\nColors in R",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#quarto-resources",
    "href": "R_Resources.html#quarto-resources",
    "title": "R Resources",
    "section": "",
    "text": "COMP/STAT 112 website (including an example quarto document)\nQuarto cheatsheet\nQuarto tutorial\nComprehensive Quarto Guide",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#general-r-resources",
    "href": "R_Resources.html#general-r-resources",
    "title": "R Resources",
    "section": "",
    "text": "RStudio cheatsheets\nAdvanced R\nR Programming Wikibook\nDebugging in R\n\nArticle\nVideo",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#some-example-code",
    "href": "R_Resources.html#some-example-code",
    "title": "R Resources",
    "section": "",
    "text": "Creating new variables\ncase_when() from the dplyr package is a very versatile function for creating new variables based on existing variables. This can be useful for creating categorical or quantitative variables and for creating indices from multiple variables.\n\n# Turn quant_var into a Low/Med/High version\ndata &lt;- data %&gt;%\n    mutate(cat_var = case_when(\n            quant_var &lt; 10 ~ \"Low\",\n            quant_var &gt;= 10 & quant_var &lt;= 20 ~ \"Med\",\n            quant_var &gt; 20 ~ \"High\"\n        )\n    )\n\n# Turn cat_var (A, B, C categories) into another categorical variable\n# (collapse A and B into one category)\ndata &lt;- data %&gt;%\n    mutate(new_cat_var = case_when(\n            cat_var %in% c(\"A\", \"B\") ~ \"A or B\"\n            cat_var==\"C\" ~ \"C\"\n        )\n    )\n\n# Turn a categorical variable (x1) encoded as a numerical 0/1/2 variable into a different quantitative variable\n# Doing this for multiple variables allows you to create an index\ndata &lt;- data %&gt;%\n    mutate(x1_score = case_when(\n            x1==0 ~ 10,\n            x1==1 ~ 20,\n            x1==2 ~ 50\n        )\n    )\n\n# Add together multiple variables with mutate\ndata &lt;- data %&gt;%\n    mutate(index = x1_score + x2_score + x3_score)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Rstudio.html",
    "href": "R_Rstudio.html",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Follow these instructions to set up the software that we‚Äôll be using throughout the semester.\n\n\n\n\n\n\nNote\n\n\n\nEven if you‚Äôve already downloaded both R and RStudio for a previous class, you need to re-download to make sure that you have the most current versions.\n\n\n\n\n\n\n\nRequired: Create a folder for this course on your local harddrive (e.g.¬†Desktop or Documents), not necessarily on a Cloud Drive as you may encounter large datasets in this class.\n\nHighly Recommended: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\n\n\n\n\n\nRequired: Install (or update) R and RStudio\n\nAs of January 2026, the latest versions of R and RStudio are:\n\nR: 4.5.2\nRStudio: 2026.01.0+392 \n\nIf you do not have the latest versions of both R and RStudio installed on your computer, see below. (Not sure if you do? See the THIRD step, below.)\n\nFIRST: Download R here.\n\nYou will see three links ‚ÄúDownload R for ‚Ä¶‚Äù\nChoose the link that corresponds to your computer operating system (and pay attention to processor chip type for Mac - M1/M2 or Intel; on your computer, click Apple &gt; About this Mac to find info about the chip).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\n\nTHIRD: Check your work\n\nOpen an RStudio session.\nRun the following in the Console, and repeat the FIRST or SECOND step if the version numbers that print out are not equal to (or more recent than) those listed above.\n\n\n\n# check R version\nR.Version()\n\n# check RStudio version\nrstudioapi::versionInfo()\n\n\nRequired: Install the most up-to-date versions of the required R packages for this course.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\",\"tidymodels\",\"GGally\",\"ISLR\"), dependencies = TRUE)\n\n\nIf you get a message that says ‚ÄúThere are binary versions available the source versions are later‚Äù type no and press Enter.\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(ggplot2) and hit enter.\nIf you see the message Error in library(ggplot2) : there is no package called ggplot2, then there was a problem installing this package. Jump down to the Troubleshooting section below. (Any other messages that appear are fine, and a lack of any messages is also fine.)\nRepeat the above step for the commands:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(ISLR)\n\nQuit RStudio. You‚Äôre done setting up!\n\n\nHighly Recommended: Set essential RStudio options.\nGo to:\n\nWindows: Edit &gt; Preferences &gt; General\nMac: Tools &gt; Global Options‚Ä¶ &gt; General\n\nNavigate to the ‚ÄúWorkspace‚Äù section.\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select ‚ÄúNever‚Äù\nPress ‚ÄúApply‚Äù and then ‚ÄúOK‚Äù\n\nIf you don‚Äôt change these options, RStudio will save all of the objects you ever create in your Global Environment. In practice, this leads to all of the objects, datasets, etc that you have ever worked with at Macalester being loaded in when you start RStudio.\n\nThis can make startup slow.\nIt clutters the Global Environment. (e.g., You‚Äôre working on something and referring to diamonds not knowing that a diamonds that was used in class last year is already in the Global Environment.)\n\n\nHighly Recommended: Watch this video made by Dr.¬†Lisa Lendway that describes useful configuration options for RStudio.\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\n\n\n\n\n\nProblem: You are on a Mac and getting the following error (or something similar):\n\n\n    Error: package or namespace load failed for ‚Äòggplot2‚Äô in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n     there is no package called ‚Äòrlang‚Äô\nHere‚Äôs how to fix it:\n\nFirst install the suite of Command Line Tools for Mac using the instructions here.\nNext enter install.packages(\"rlang\") in the Console.\nFinally check that entering library(ggplot2) gives no errors.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "R_Rstudio.html#file-organization",
    "href": "R_Rstudio.html#file-organization",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Required: Create a folder for this course on your local harddrive (e.g.¬†Desktop or Documents), not necessarily on a Cloud Drive as you may encounter large datasets in this class.\n\nHighly Recommended: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "R_Rstudio.html#r-rstudio",
    "href": "R_Rstudio.html#r-rstudio",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Required: Install (or update) R and RStudio\n\nAs of January 2026, the latest versions of R and RStudio are:\n\nR: 4.5.2\nRStudio: 2026.01.0+392 \n\nIf you do not have the latest versions of both R and RStudio installed on your computer, see below. (Not sure if you do? See the THIRD step, below.)\n\nFIRST: Download R here.\n\nYou will see three links ‚ÄúDownload R for ‚Ä¶‚Äù\nChoose the link that corresponds to your computer operating system (and pay attention to processor chip type for Mac - M1/M2 or Intel; on your computer, click Apple &gt; About this Mac to find info about the chip).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\n\nTHIRD: Check your work\n\nOpen an RStudio session.\nRun the following in the Console, and repeat the FIRST or SECOND step if the version numbers that print out are not equal to (or more recent than) those listed above.\n\n\n\n# check R version\nR.Version()\n\n# check RStudio version\nrstudioapi::versionInfo()\n\n\nRequired: Install the most up-to-date versions of the required R packages for this course.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\",\"tidymodels\",\"GGally\",\"ISLR\"), dependencies = TRUE)\n\n\nIf you get a message that says ‚ÄúThere are binary versions available the source versions are later‚Äù type no and press Enter.\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(ggplot2) and hit enter.\nIf you see the message Error in library(ggplot2) : there is no package called ggplot2, then there was a problem installing this package. Jump down to the Troubleshooting section below. (Any other messages that appear are fine, and a lack of any messages is also fine.)\nRepeat the above step for the commands:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(ISLR)\n\nQuit RStudio. You‚Äôre done setting up!\n\n\nHighly Recommended: Set essential RStudio options.\nGo to:\n\nWindows: Edit &gt; Preferences &gt; General\nMac: Tools &gt; Global Options‚Ä¶ &gt; General\n\nNavigate to the ‚ÄúWorkspace‚Äù section.\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select ‚ÄúNever‚Äù\nPress ‚ÄúApply‚Äù and then ‚ÄúOK‚Äù\n\nIf you don‚Äôt change these options, RStudio will save all of the objects you ever create in your Global Environment. In practice, this leads to all of the objects, datasets, etc that you have ever worked with at Macalester being loaded in when you start RStudio.\n\nThis can make startup slow.\nIt clutters the Global Environment. (e.g., You‚Äôre working on something and referring to diamonds not knowing that a diamonds that was used in class last year is already in the Global Environment.)\n\n\nHighly Recommended: Watch this video made by Dr.¬†Lisa Lendway that describes useful configuration options for RStudio.\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\n\n\n\n\n\nProblem: You are on a Mac and getting the following error (or something similar):\n\n\n    Error: package or namespace load failed for ‚Äòggplot2‚Äô in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n     there is no package called ‚Äòrlang‚Äô\nHere‚Äôs how to fix it:\n\nFirst install the suite of Command Line Tools for Mac using the instructions here.\nNext enter install.packages(\"rlang\") in the Console.\nFinally check that entering library(ggplot2) gives no errors.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html",
    "href": "activities/L02-evaluating-regression-models.html",
    "title": "Model Evaluation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#instructions",
    "href": "activities/L02-evaluating-regression-models.html#instructions",
    "title": "Model Evaluation",
    "section": "Instructions",
    "text": "Instructions\n\nIn small groups, please first introduce yourself (in whatever way you feel appropriate) and check in with each other as human beings.\nWhen everyone is ready, glance through the summary of concepts covered in the video (see ‚ÄúVideo Recap‚Äù below) and discuss the following prompts:\n\nWhat vocabulary or notation was new to you?\nWhat concepts were new to you?\nWhat concepts are still unclear to you at this moment?\n\nPrepare to share a few highlights from your group discussion with the entire class",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#video-recap",
    "href": "activities/L02-evaluating-regression-models.html#video-recap",
    "title": "Model Evaluation",
    "section": "Video Recap",
    "text": "Video Recap\n\nWe are in the regression setting. We want to build a model of some quantitative output variable \\(y\\) by some predictors \\(x\\):\n\\[y = f(x) + \\varepsilon\\]\nThere are many regression tools that we might use to build this model. We‚Äôll use a linear regression model which assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs:\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots \\beta_p x_p + \\varepsilon\\]\nAfter building any model, it‚Äôs important to evaluate it: Is our regression model a ‚Äúgood‚Äù model?\n\nIs the model wrong?\n\nIs the model strong?\n\nDoes the model produce accurate predictions?\n\nIs the model fair?\n\nWe will review these concepts through today‚Äôs exercises. A detailed overview is provided in the Unit 1 ‚ÄúMotivating Question‚Äù section on the course website.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#intro-to-tidymodels",
    "href": "activities/L02-evaluating-regression-models.html#intro-to-tidymodels",
    "title": "Model Evaluation",
    "section": "Intro to tidymodels",
    "text": "Intro to tidymodels\nThroughout the semester, we are going to use the tidymodels package in R.\n\nSimilar flavor to tidyverse structure\nMore general structure that allows us to fit many other types of models\n\n\n\nAt first, it will seem like a lot more code (perhaps even unnecessarily so).\n\n\nFor example, what you did in STAT 155 with\n\nlm(y ~ x1 + x2, data = sample_data)\n\nwill now look like\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\")# we'll estimate the model using the lm function\n\n# STEP 2: model estimation\nmodel_estimate &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = sample_data)\n\n\n\nFor now, you‚Äôll need to trust me that this will be end up being useful. (It will be!)\n\n\nLet‚Äôs take a look at some code that we‚Äôll use to build future models. Compare the model specification code above to the examples below.\n\nWhat similarities and differences do you notice?\nWhy might the designers of tidymodels have chosen to design the code this way?\n\n\n# Specification for a LASSO model\nlasso_spec &lt;- linear_reg() %&gt;%             \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glmnet\")\n\n# Specification for a k-nearest neighbors model\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(engine = \"kknn\")\n\n# Specification for a logistic regression model\nlogistic_spec &lt;- logistic_reg() %&gt;%\n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\")",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#quick-highlight",
    "href": "activities/L02-evaluating-regression-models.html#quick-highlight",
    "title": "Model Evaluation",
    "section": "Quick Highlight",
    "text": "Quick Highlight\nA few useful functions to use on model_estimate:\n\nmodel_estimate %&gt;% \n  tidy() #gives you coefficients (and se, t-statistics)\n\n\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) # gives you predictions and residuals for sample_data\n\n\nmodel_estimate %&gt;% \n  glance() #gives you some model evaluation metrics (is it strong?)\n\n\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% # get predictions, and then...\n  mae(truth = y, estimate = .pred) # calculate MAE to measure accuracy of predictions\n\nMore info, for future reference, below!",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#future-reference",
    "href": "activities/L02-evaluating-regression-models.html#future-reference",
    "title": "Model Evaluation",
    "section": "Future Reference",
    "text": "Future Reference\n\n\n\n\n\n\nNote\n\n\n\nThis section is for future reference. It is a summary of code you‚Äôll learn below for building and evaluating regression models. You do not need to (and in fact should not) run the code in this section verbatim in R; it is example code and meant for future reference only.\n\n\nBuilding and evaluating regression models using tidymodels.\nThroughout, suppose we wish to build and evaluate a linear regression model of y vs x1 and x2 using a dataset called sample_data.\nYou‚Äôll need both of these packages:\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nBuilding a linear regression model\n\n# STEP 1: specify the type of model to build\nlm_spec &lt;- linear_reg() %&gt;% # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\") # we'll estimate the model using the lm function\n\n# STEP 2: estimate the specified model using sample data\nmodel_estimate &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = sample_data)\n\n# Get the model coefficients\nmodel_estimate %&gt;% \n  tidy()\n\nObtaining predictions (& residuals) for each observation\n\n# Obtain y predictions and residuals for each observation in our sample_data\n# (We can replace sample_data with any data frame that includes y, x1, and x2)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data)\n\n# Obtain y predictions (but not residuals) for some given x1, x2 values, when we haven't yet observed y\n# (We can replace the data.frame with any data frame that includes x1 and x2)\nmodel_estimate %&gt;% \n  augment(new_data = data.frame(x1 = ___, x2 = ___))\n  \n# Another approach using predict()\nmodel_estimate %&gt;% \n  predict(new_data = data.frame(x1 = ___, x2 = ___))\n\nEvaluating the model\n\n# Is it strong? (R^2)\nmodel_estimate %&gt;% \n  glance()\n\n# Does it produce accurate predictions? (MAE)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% \n  mae(truth = y, estimate = .pred)\n\n# Is it wrong? (residual plot)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0) + \n  geom_smooth()",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#instructions-1",
    "href": "activities/L02-evaluating-regression-models.html#instructions-1",
    "title": "Model Evaluation",
    "section": "Instructions",
    "text": "Instructions\n\n\nWork through these exercises as a group, talking through your ideas, questions, and reasoning as you go and taking notes in your QMD.\nFocus on patterns in code. Review, but do not try to memorize any provided code. Focus on the general steps and patterns.\nIf you‚Äôre given some starter code with blanks (e.g.¬†below), don‚Äôt type in those chunks. Instead, copy, paste, and modify the starter code in the chunk below it.\n\n\n# Start small: rides vs temp\nggplot(___, aes(y = ___, x = ___)) + \n  geom___()\n\n\nAsk questions! We will not have time to discuss all exercises at the end of class. Talk through your questions as a group, and ask me questions as I walk around the room!\nBe kind to yourself/each other! You will be rusty and make mistakes, and that‚Äôs ok! Mistakes are important to learning.\n\nIf you‚Äôre feeling rusty on STAT 155 material, in particular, check out the STAT 155 Review Appendix on our course website or the links at the top of the notes for today.\n\nCollaborate. We‚Äôre sitting in groups for a reason. Collaboration improves higher-level thinking, confidence, communication, community, and more. I expect you to:\n\nActively contribute to discussion (don‚Äôt work on your own).\nActively include all group members in discussion.\nCreate a space where others feel comfortable making mistakes & sharing their ideas (remember that we all come to this class with different experiences, both personal and academic).\nStay in sync while respecting that everybody has different learning strategies, work styles, note taking strategies, etc. If some people are working on exercise 10 and others are on exercise 2, that‚Äôs probably not a good collaboration.\nDon‚Äôt rush. You won‚Äôt hand anything in and can finish up outside of class.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#questions",
    "href": "activities/L02-evaluating-regression-models.html#questions",
    "title": "Model Evaluation",
    "section": "Questions",
    "text": "Questions\nCapital Bikeshare provides a bike-sharing service in the Washington DC area. Customers can pick up and drop off bikes at any station around the city. Of primary interest to the company is:\nHow many registered riders can we expect today?\nTo this end, you will build, evaluate, and compare 2 different linear regression models of ridership using the following Capital Bikeshare dataset (originally from the UCI Machine Learning Repository):\n\nModel 1: rides ~ windspeed + temp\nModel 2: rides ~ windspeed + temp + weekend\n\n\n\n\n\nExplore the data\n\nTake a minute to get familiar with the data.\n\n# Load packages we'll need to wrangle and plot the data\nlibrary(tidyverse)\n\n# Load the data\nbikes &lt;- read.csv(\"https://Mac-Stat.github.io/data/bike_share.csv\")\n\n# Only keep / select some variables\n# And round some variables (just for our demo purposes)\nbikes &lt;- bikes %&gt;% \n  rename(rides = riders_registered, temp = temp_feel) %&gt;% \n  mutate(windspeed = round(windspeed), temp = round(temp)) %&gt;% \n  select(rides, windspeed, temp, weekend)\n\n\n# Check out the dimensions\ndim(bikes)\n## [1] 731   4\n\n# Check out the first 3 rows\nhead(bikes, 3)\n##   rides windspeed temp weekend\n## 1   654        11   65    TRUE\n## 2   670        17   64    TRUE\n## 3  1229        17   49   FALSE\n\nThis dataset contains the following information for a sample of different dates:\n\n\n\nvariable\ndescription\n\n\n\n\nrides\ncount of daily rides by registered users\n\n\nwindspeed\nwind speed in miles per hour\n\n\ntemp\nwhat the temperature feels like in degrees Fahrenheit\n\n\nweekend\nwhether or not it falls on a weekend\n\n\n\n\n\n\n\nPlot the relationships\n\nFirst, let‚Äôs plot these relationships.\nREMEMBER: Don‚Äôt write in any chunk with starter code. Copy, paste, and modify the code in the chunk below it.\n\n# Start small: rides vs temp\nggplot(___, aes(y = ___, x = ___)) + \n  geom___()\n\n\n# Start small: rides vs temp\n# Start small: rides vs temp\n\n\n# rides vs temp & windspeed\nggplot(bikes, aes(y = ___, x = ___, ___ = windspeed)) + \n  geom_point()\n\n\n# rides vs temp & windspeed & weekend\nggplot(bikes, aes(y = ___, x = ___, ___ = windspeed)) + \n  geom_point() +  \n  facet_wrap(~ ___)\n\n\n\n\n\ntidymodels STEP 1\n\nWe‚Äôll build and evaluate our two models of ridership using the tidymodels package. This code is more complicated than the lm() function we used in STAT 155. BUT:\n\ntidymodels is part of the broader tidyverse (what we use to plot and wrangle data), thus the syntax is more consistent\ntidymodels generalizes to the other ML algorithms we‚Äôll survey in this course, thus will eventually minimize the unique syntax we need to learn\n\n\n# Load package\nlibrary(tidymodels)\n\nThe first step is to specify what type of model we want to build. We‚Äôll store this as lm_spec, our linear regression model (lm) specification (spec).\n\nlm_spec &lt;- linear_reg() %&gt;%   # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\")            # we'll estimate the model using the lm function\n\nThis code specifies but doesn‚Äôt build any model ‚Äì we didn‚Äôt even give it any data or specify the variables of interest!\n\n# Check it out\nlm_spec\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\n\n\n\n\ntidymodels STEP 2\n\nWe can now estimate or fit our two ridership models using the specified model structure (lm_spec) and our sample bikes data:\n\n# Fit bike_model_1\nbike_model_1 &lt;- lm_spec %&gt;% \n  fit(rides ~ windspeed + temp, data = bikes)\n\n# Check out the coefficients\nbike_model_1 %&gt;% \n  tidy()\n## # A tibble: 3 √ó 5\n##   term        estimate std.error statistic  p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)    -20.8    300.     -0.0694 9.45e- 1\n## 2 windspeed      -36.1      9.42   -3.83   1.37e- 4\n## 3 temp            55.4      3.33   16.6    7.58e-53\n\n\n# YOUR TURN\n# Fit bike_model_2 & check out the coefficients\n\n\n\n\n\nIs it fair?\n\nNow, let‚Äôs evaluate our two models. First, do you have any concerns about the context in which the data were collected and analyzed? About the potential impact of this analysis?\n\n\n\n\nIs it strong?\n\nWe can measure and compare the strength of these models using \\(R^2\\), the proportion of variability in our response variable that‚Äôs explained by the model. Report which model is stronger and interpret its \\(R^2\\).\n\n# Obtain R^2 for bike_model_1\nbike_model_1 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic  p.value    df logLik    AIC    BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1     0.310         0.308 1298.      163. 2.44e-59     2 -6276. 12560. 12578.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n# YOUR TURN\n# Obtain R^2 for bike_model_2\n\n\n\n\n\nPause ‚Äì predictions and residuals\n\nOur next model evaluation questions will focus on the models‚Äô predictions and prediction errors, or residuals. We can obtain this information by augmenting our models with our original bikes data. For example:\n\n# Calculate predicted ridership (.pred) & corresponding residuals (.resid) using bike_model_1\n# Just look at first 6 days\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  head()\n## # A tibble: 6 √ó 6\n##   .pred .resid rides windspeed  temp weekend\n##   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n## 1 3183. -2529.   654        11    65 TRUE   \n## 2 2911. -2241.   670        17    64 TRUE   \n## 3 2080.  -851.  1229        17    49 FALSE  \n## 4 2407.  -953.  1454        11    51 FALSE  \n## 5 2446.  -928.  1518        13    53 FALSE  \n## 6 2699. -1181.  1518         6    53 FALSE\n\nWe can also predict outcomes for new observations using either augment() or predict(). Note the difference in the output:\n\n# Predict ridership on a 60 degree day with 20 mph winds\nbike_model_1 %&gt;% \n  augment(new_data = data.frame(windspeed = 20, temp = 60))\n## # A tibble: 1 √ó 3\n##   .pred windspeed  temp\n##   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n## 1 2581.        20    60\n\n\n# Predict ridership on a 60 degree day with 20 mph winds\nbike_model_1 %&gt;% \n  predict(new_data = data.frame(windspeed = 20, temp = 60))\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1 2581.\n\n\n\n\n\nDoes it produce accurate predictions?\n\nRecall that the mean absolute error (MAE) measures the typical prediction error. Specifically, it is the mean of the absolute values of the residual errors for the days in our dataset.\n\nUse the residuals to calculate the MAE for the 2 models. HINT: abs()\n\n\n# DON'T TYPE IN THIS CHUNK\n# MAE for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  summarize(mae = ___(___(___)))\n\n\n# MAE for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  summarize(mae = mean(abs(.resid)))\n## # A tibble: 1 √ó 1\n##     mae\n##   &lt;dbl&gt;\n## 1 1080.\n\n\n# YOUR TURN: MAE for bike_model_2\n\n\nDoing the calculation from scratch helps solidify your understanding of how MAE is calculated, thus interpreted. Check your calculations using a shortcut function.\n\n\n# Calculate MAE for the first model\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  mae(truth = rides, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard       1080.\n\n\n# YOUR TURN\n# Calculate MAE for the second model\n\n\nWhich model has more accurate predictions?\nInterpret the MAE for this model, in context, and comment on whether it‚Äôs ‚Äúlarge‚Äù or ‚Äúsmall‚Äù. NOTE: ‚Äúlarge‚Äù or ‚Äúsmall‚Äù is defined by the context (e.g.¬†relative to the observed range of ridership, the consequences of a bad prediction, etc).\n\n\n\n\n\nIs it wrong?\n\nTo determine whether the linear regression assumptions behind bike_model_1 and bike_model_2 are reasonable, we can review residual plots, i.e.¬†plots of the residuals vs predictions for each observation in our dataset. Run the code below and summarize your assessment of whether our models are wrong. RECALL: We want the points to appear random and centered around 0 across the entire range of the model / predictions.\n\n# Residual plot for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) + \n    geom_smooth() # add trend line\n\n\n\n\n\n\n\n\n\n# YOUR TURN\n# Residual plot for bike_model_2\n\n\n\n\n\nArt vs science\n\nInspecting residual plots is more art than science.1 It requires a lot of practice. Consider another example using simulated data. First, build a model that assumes all predictors are roughly linearly related:\n\n# Import data\nsimulated_data &lt;- read.csv(\"https://Mac-Stat.github.io/data/simulated_data.csv\")\n\n# Model y by the 6 input variables\nnew_model &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2 + x3 + x4 + x5 + x6, simulated_data)\n\nNext, check out a pairs plot. Is there anything here that makes you think that our model assumption is bad? (NOTE: if you are not familiar with the ggpairs function we are using below, chat with your group and look for resources to figure out what this is doing!)\n\nnew_model %&gt;% \n  augment(new_data = simulated_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point(size = 0.1) + \n  geom_hline(yintercept = 0)\n\n\n\n\n\n\n\n\n\n\n\n\nDetails ‚Äì communication & code style\n\nCommunication is a key machine learning skill, including written summaries, presentations, and code. Just like an essay, code must have structure, signposts, and grammar that will make it easier for others to follow. The below code runs, but it is ‚Äúbad code‚Äù.\n\nFix this code and add comments so that it is easier for yourself and others to follow.\nAlso pay attention to what this code does.\n\n\nbikes %&gt;%\n  group_by(weekend) %&gt;%\n  summarize(median(rides))\n## # A tibble: 2 √ó 2\n##   weekend `median(rides)`\n##   &lt;lgl&gt;             &lt;dbl&gt;\n## 1 FALSE              3848\n## 2 TRUE               2955\n\n\nmynewdatasetissmallerthantheoriginal&lt;-bikes%&gt;%filter(rides&lt;=700,weekend==FALSE,temp&gt;60)\nmynewdatasetissmallerthantheoriginal\n##   rides windspeed temp weekend\n## 1   577        18   67   FALSE\n## 2   655        18   68   FALSE\n## 3    20        24   72   FALSE\n\n\nmynewdatasetusescelsius&lt;-bikes%&gt;%mutate(temp=(temp-32)*5/9)\nhead(mynewdatasetusescelsius)\n##   rides windspeed      temp weekend\n## 1   654        11 18.333333    TRUE\n## 2   670        17 17.777778    TRUE\n## 3  1229        17  9.444444   FALSE\n## 4  1454        11 10.555556   FALSE\n## 5  1518        13 11.666667   FALSE\n## 6  1518         6 11.666667   FALSE\n\n\n\n\n\nSTAT 155 Review ‚Äì model interpretation & application\n\nLet‚Äôs interpret and apply bike_model_2.\n\n___ %&gt;% \n  tidy()\n\n\nHow can we interpret the temp coefficient?\n\n\nWe expect roughly 54 more riders on warm days.\nWe expect roughly 54 more riders per every 1 degree increase in temperature.\nWhen controlling for windspeed and weekend status, we expect roughly 54 more riders on warm days.\nWhen controlling for windspeed and weekend status, we expect roughly 54 more riders per every 1 degree increase in temperature.\n\n\nHow can we interpret the weekendTRUE coefficient?\n\n\nWe expect roughly 858 fewer riders on weekends.\nWe expect roughly 858 fewer riders per every extra weekend.\nWhen controlling for windspeed and temperature, we expect roughly 858 fewer riders on weekends.\nWhen controlling for windspeed and temperature, we expect roughly 858 fewer riders per every extra weekend.\n\n\nReproduce the predicted ridership and corresponding residual for day 1 from scratch (how were these calculated?!):\n\n\nbike_model_2 %&gt;% \n  ___(new_data = bikes) %&gt;% \n  head(1)\n\n\n\n\n\nSTAT 155 Review ‚Äì data wrangling\n\nThrough the ‚ÄúDetails: communication & code style‚Äù and elsewhere, you‚Äôve reviewed the use of various dplyr data wrangling verbs: filter(), mutate(), summarize(), group_by(), select(), arrange(). Use these to complete the following tasks.\n\nCalculate the mean temperature across all days in the data set.\n\n\nCalculate the mean temperature on weekends vs weekdays.\n\n\nPrint out the 3 days with the highest temperatures. HINT: arrange() or arrange(desc())\n\n\nName and store a new data set which:\n\n\nonly includes the days that fall on a weekend and have temps below 80 degrees\nhas a new variable, temp_above_freezing, which calculates how far the temperature is above (or below) freezing (32 degrees F)\nonly includes the windspeed, temp, and temp_above_freezing variables.\n\n\n\n\n\nSTAT 155 Review ‚Äì plots\n\nConstruct plots of the following relationships:\n\n# rides vs temp\n\n\n# rides vs weekend\n\n\n# rides vs temp and weekend",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#footnotes",
    "href": "activities/L02-evaluating-regression-models.html#footnotes",
    "title": "Model Evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nStefanski, Leonard A. (2007). Residual (Sur)Realism. ‚ÄúThe American Statistician,‚Äù 61, pp 163-177.‚Ü©Ô∏é",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html",
    "href": "activities/L04-cross-validation.html",
    "title": "Cross-Validation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#context-evaluating-regression-models",
    "href": "activities/L04-cross-validation.html#context-evaluating-regression-models",
    "title": "Cross-Validation",
    "section": "Context: Evaluating Regression Models",
    "text": "Context: Evaluating Regression Models\nA reminder of our current context:\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) by some predictors \\(x\\).\ntask = regression\n\\(y\\) is quantitative\nmodel = linear regression model via least squares algorithm\nWe‚Äôll assume that the relationship between \\(y\\) and \\(x\\) can be represented by\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\varepsilon\\]\n\n\nGOAL: model evaluation\nWe want more honest metrics of prediction quality that\n\nassess how well our model predicts new outcomes; and\nhelp prevent overfitting.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#why-is-overfitting-so-bad",
    "href": "activities/L04-cross-validation.html#why-is-overfitting-so-bad",
    "title": "Cross-Validation",
    "section": "Why is overfitting so bad?",
    "text": "Why is overfitting so bad?\nNot only can overfitting produce misleading models, it can have serious societal impacts.\nExamples:\n\n\nFacial recognition algorithms are often overfit to the people who build them (who are not broadly representative of society). As one example, this has led to disproportionate bias in policing. For more on this topic, you might check out Coded Bias, a documentary by Shalini Kantayya which features MIT Media Lab researcher Joy Buolamwini.\nPolygenic risk scores (PRSs), which aim to predict a person‚Äôs risk of developing a particular disease/trait based on their genetics, are often overfit to the data on which they are built (which, historically, has exclusively‚Äîor at least primarily‚Äîincluded individuals of European ancestry). As a result, PRS predictions tend to be more accurate in European populations and new research suggests that their continued use in clinical settings could exacerbate health disparities.\nThere are connections to overfitting in the article for the ethics reflection on HW1 (about a former Amazon recruiting algorithm.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#k-fold-cross-validation",
    "href": "activities/L04-cross-validation.html#k-fold-cross-validation",
    "title": "Cross-Validation",
    "section": "k-Fold Cross Validation",
    "text": "k-Fold Cross Validation\nWe can use k-fold cross-validation to estimate the typical error in our model predictions for new data:\n\n\nDivide the data into \\(k\\) folds (or groups) of approximately equal size.\n\nRepeat the following procedures for each fold \\(j = 1,2,...,k\\):\n\nRemove fold \\(j\\) from the data set.\n\nFit a model using the data in the other \\(k-1\\) folds (training).\n\nUse this model to predict the responses for the \\(n_j\\) cases in fold \\(j\\): \\(\\hat{y}_1, ..., \\hat{y}_{n_j}\\).\n\nCalculate the MAE for fold \\(j\\) (testing): \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\).\n\nCombine this information into one measure of model quality: \\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^k \\text{MAE}_j\\]",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#definitions",
    "href": "activities/L04-cross-validation.html#definitions",
    "title": "Cross-Validation",
    "section": "Definitions",
    "text": "Definitions\n\nalgorithm = a step-by-step procedure for solving a problem (Merriam-Webster)\ntuning parameter = a parameter or quantity upon which an algorithm depends, that must be selected or tuned to ‚Äúoptimize‚Äù the algorithm\n\n1",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#prompts",
    "href": "activities/L04-cross-validation.html#prompts",
    "title": "Cross-Validation",
    "section": "Prompts",
    "text": "Prompts\n\nSynchronize as a Team!\n\n\n\nConceptual check\n\n\nWhy is \\(k\\)-fold cross-validation an algorithm?\n\n\nIt follows a list of steps to get to its goal.\n\n\nWhat is the tuning parameter of this algorithm and what values can this take?\n\n\n\\(k\\), the number of folds, is a tuning parameter. \\(k\\) can be any integer from 2, ‚Ä¶, \\(n\\) where \\(n\\) is our sample size.\n\nSPECIAL CASE: Leave One Out Cross-Validation (LOOCV).\nLOOCV is a special case of k-fold cross-validation in which, in each iteration, we hold out one data point as a test case and use the other \\(n-1\\) data points for training. Thus LOOCV is equivalent to \\(k = n\\) fold CV.\nIn pictures: In the end, we fit \\(n\\) training models (blue lines) and test each on one test car (red dots).\n\n## Error in sample_n(., size = 20, replace = FALSE): could not find function \"sample_n\"\n## Error: object 'cars_rep' not found\n## Error in mutate(., replicate = as.factor(replicate)): could not find function \"mutate\"\n## Error: object 'cars_rep' not found\n## Error: object 'cars_rep' not found\n\n\n## Error in ggplot(train_sets, aes(x = horsepower, y = mpg)): could not find function \"ggplot\"\n\n\nHow is 2-fold cross-validation (CV) different from validation? (Validation is what we did last class: splitting our sample into a training dataset and a testing dataset.)\n\n\nWe use both groups as training and testing, in turn.\n\n\nWhy might 3-fold CV be better than 2-fold CV?\n\n\nWe have a larger dataset to train our model on. We are less likely to get an unrepresentative set as our training data. We are also averaging our overall cross-validated MAE estimate over more testing folds, which is likely to result in a more stable estimate of out-of-sample error.\n\n\nWhy might LOOCV (leave-one-out CV) (k-fold CV where k = sample size) be worse than 3-fold cross-validation?\n\n\nPrediction error for 1 person is highly variable. Also, for computational time reasons, fitting models can be very slow.\n\n\nIn practice, \\(k = 10\\) and \\(k=7\\) are common choices for cross-validation. This has been shown to hit the ‚Äòsweet spot‚Äô between the extremes of \\(k=n\\) (LOOCV) and \\(k=2\\).\n\n\n\\(k=2\\) only utilizes 50% of the data for each training model, thus might result in overestimating the prediction error\n\\(k=n\\) leave-one-out cross-validation (LOOCV) requires us to build \\(n\\) training models, thus might be computationally expensive for larger sample sizes \\(n\\). Further, with only one data point in each test set, the training sets have a lot of overlap. This correlation among the training sets can make the ultimate corresponding estimate of prediction error less reliable.\n\n\n\nR Code Preview\n\nWe‚Äôve been doing a 2-step process to build linear regression models using the tidymodels package:\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n  \n# STEP 2: model estimation\nmy_model &lt;- lm_spec %&gt;% \n  fit(\n    y ~ x1 + x2,\n    data = sample_data\n  )\n\nFor k-fold cross-validation, we can tweak STEP 2. Discuss the code below:\n\nWhat‚Äôs similar? What‚Äôs different? &gt; Similar to fit(), we tell the function fit_resamples what model to fit and which data to use. But, instead of fitting that model once to the full data, we use CV.\nWhat do you think each new, or otherwise modified, line does?\nWhy do we need set.seed?\n\n\nset.seed(___) # set seed for reproducibility\n\nmy_model_cv &lt;- lm_spec %&gt;% # take the model specs we defined earlier, and then\n  \n  fit_resamples( # fit multiple models (across multiple resamples of the data)\n    \n    y ~ x1 + x2, # the model we want to fit\n    \n    resamples = vfold_cv(sample_data, v = ___), # use \"v\"-fold CV to create the resamples (fill in the blank to specify \"v\", aka \"k\")\n    \n    metrics = metric_set(mae, rsq) # specify which evaluation metric(s) (MAE, R^2) to use \n    \n  )\n\nHere are a few general tips for breaking down complex code:\n\nRead the R Documentation / help page for any new functions (eg type ?fit_resamples into the Console)\nTry removing or otherwise modifying each line of code and see what happens!\n\nWhy set a seed? The process of creating the folds is random, so we should set the seed to have reproducibility within our work.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#instructions",
    "href": "activities/L04-cross-validation.html#instructions",
    "title": "Cross-Validation",
    "section": "Instructions",
    "text": "Instructions\n\n\nGo to the Course Schedule and find the QMD template for today\n\nSave this in your STAT 253 Notes folder, NOT your downloads!\n\nWork through the exercises implementing CV to compare two possible models predicting height\nSame directions as before:\n\nBe kind to yourself/each other\nCollaborate\nDON‚ÄôT edit starter code (i.e., code with blanks ___). Instead, copy-paste into a new code chunk below and edit from there.\n\nAsk me questions as I move around the room",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#questions",
    "href": "activities/L04-cross-validation.html#questions",
    "title": "Cross-Validation",
    "section": "Questions",
    "text": "Questions\n\n# Load packages and data\nlibrary(tidyverse)\nlibrary(tidymodels)\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat50.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\n\nReview: In-sample metrics- As Group\n\nUse the humans data to build two separate models of height:\n\n# STEP 1: model specification\nlm_spec &lt;- ___() %&gt;% \n  set_mode(___) %&gt;% \n  set_engine(___)\n\n\n# STEP 2: model estimation\nmodel_1 &lt;- ___ %&gt;% \n  ___(height ~ hip + weight + thigh + knee + ankle, data = humans)\nmodel_2 &lt;- ___ %&gt;% \n  ___(height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\nCalculate the in-sample R-squared for both models:\n\n# IN-SAMPLE R^2 for model_1 = ???\nmodel_1 %&gt;% \n  ___()\n\n\n# IN-SAMPLE R^2 for model_2 = ???\nmodel_2 %&gt;% \n  ___()\n\nCalculate the in-sample MAE for both models:\n\n# IN-SAMPLE MAE for model_1 = ???\nmodel_1 %&gt;% \n  ___(new_data = ___) %&gt;% \n  mae(truth = ___, estimate = ___)\n\n\n# IN-SAMPLE MAE for model_2 = ???\nmodel_2 %&gt;% \n  ___(new_data = ___) %&gt;% \n  mae(truth = ___, estimate = ___)\n\n\n\n\nIn-sample model comparison - As Group\n\nWhich model seems ‚Äúbetter‚Äù by the in-sample metrics you calculated above? Any concerns about either of these models?\n\nType your answer\n\n\n\n\n10-fold CV - As Group\n\nComplete the code to run 10-fold cross-validation for our two models.\nModel 1: height ~ hip + weight + thigh + knee + ankle\nModel 2: height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist\n\n# 10-fold cross-validation for model_1\nset.seed(253)\nmodel_1_cv &lt;- ___ %&gt;% \n  ___(\n    ___,\n    ___ = vfold_cv(___, v = ___), \n    ___ = metric_set(mae, rsq)\n  )\n\n\n# 10-fold cross-validation for model_2\nset.seed(253)\nmodel_2_cv &lt;- ___ %&gt;% \n  ___(\n    ___,\n    ___ = vfold_cv(___, v = ___), \n    ___ = metric_set(mae, rsq)\n  )\n\n\n\n\nCalculating the CV MAE - As Group\n\n\nUse collect_metrics() to obtain the cross-validated MAE and \\(R^2\\) for both models.\n\n\n# HINT\n___ %&gt;% \n  collect_metrics()\n\n\nInterpret the cross-validated MAE and \\(R^2\\) for model_1.\n\n\n\n\nDetails: fold-by-fold results - As Group\n\nThe collect_metrics() function gave the final CV MAE, or the average MAE across all 10 test folds. If you want the MAE from each test fold, try unnest(.metrics).\n\nObtain the fold-by-fold results for the model_1 cross-validation procedure using unnest(.metrics).\n\n\n# HINT\n___ %&gt;% \n  unnest(.metrics)\n\n\nWhich fold had the worst average prediction error and what was it?\nRecall that collect_metrics() reported a final CV MAE of 1.87 for model_1. Confirm this calculation by wrangling the fold-by-fold results from part a.\n\n\n\n\nComparing models - As Team\n\nThe table below summarizes the in-sample and 10-fold CV MAE for both models.\n\n\n\nModel\nIN-SAMPLE MAE\n10-fold CV MAE\n\n\n\n\nmodel_1\n1.55\n1.87\n\n\nmodel_2\n0.64\n2.47\n\n\n\n\nBased on the in-sample MAE alone, which model appears better?\n\n\nmodel_2\n\n\nBased on the CV MAE alone, which model appears better?\n\n\nmodel_1\n\n\nBased on all of these results, which model would you pick?\n\n\nmodel_1 ‚Äì model_2 produces bad predictions for new adults\n\n\nDo the in-sample and CV MAE suggest that model_1 is overfit to our humans sample data? What about model_2? Why/why not?\n\n\nmodel_1 is NOT overfit ‚Äì its predictions of height for new adults seem roughly as accurate as the predictions for the adults in our sample. model_2 IS overfit ‚Äì its predictions of height for new adults are worse than the predictions for the adults in our sample.\n\n\n\n\nLOOCV- As Team\n\nNo code to implement for this exercise‚Äìjust answer the following conceptually.\n\nHow could we adapt the code in Exercise 3 to use LOOCV MAE instead of the 10-fold CV MAE?\n\nThere are 39 people in our sample, thus LOOCV is equivalent to 39-fold CV:\n\nnrow(humans)\nmodel_1_loocv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ hip + weight + thigh + knee + ankle,\n    resamples = vfold_cv(humans, v = nrow(humans)), # this will throw an error and tell you to use loo_cv() instead\n    metrics = metric_set(mae)\n  )\n    \nmodel_1_loocv %&gt;% \n  collect_metrics()\n\n\nWhy do we technically not need to set.seed() for the LOOCV algorithm?\n\n\nThere‚Äôs no randomness in the test folds. Each test fold is a single person.\n\n\n\n\nAdditional Exercise: Data drill\n\n\nCalculate the average height of people under 40 years old vs people 40+ years old.\n\n\nPlot height vs age among our subjects that are 30+ years old.\n\n\nFix this code:\n\n\nmodel_3&lt;-lm_spec%&gt;%fit(height~age,data=humans)\nmodel_3%&gt;%tidy()\n\n\n\n\nReflection: Part 1\n\nThe ‚Äúregular‚Äù exercises are over, but class is not done! Your group should agree to either work on HW1 or the remaining reflection questions.\nThis is the end of Unit 1 on ‚ÄúRegression: Model Evaluation‚Äù! Let‚Äôs reflect on the technical content of this unit:\n\nWhat was the main motivation / goal behind this unit?\nWhat are the four main questions that were important to this unit?\nFor each of the following tools, describe how they work and what questions they help us address:\n\nR-squared\nresidual plots\nout-of-sample MAE\nin-sample MAE\nvalidation\ncross-validation\n\nIn your own words, define the following:\n\noverfitting\nalgorithm\ntuning parameter\n\nReview the new tidymodels syntax from this unit. Identify key themes and patterns.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#todays-material",
    "href": "activities/L04-cross-validation.html#todays-material",
    "title": "Cross-Validation",
    "section": "Today‚Äôs Material",
    "text": "Today‚Äôs Material\n\nIf you didn‚Äôt finish the exercises, no problem! Be sure to complete them outside of class, review the solutions on the course site, and ask any outstanding questions on Discussion board on Moodle or in office hours.\nThis is the end of Unit 1, so there are reflection questions at the end of the exercises to help you organize the concepts in your mind. This is a good time to pause, review the material we‚Äôve covered so far, and stop by office hours with any questions!\nAn R tutorial video, talking through the new code, is posted on class schedule.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#upcoming-deadlines",
    "href": "activities/L04-cross-validation.html#upcoming-deadlines",
    "title": "Cross-Validation",
    "section": "Upcoming Deadlines",
    "text": "Upcoming Deadlines\n\nCP4:\n\ndue 10 minutes before our next class\n\nHW1:\n\ndue Sunday, 02/08 at 11:59 pm\nyou have everything you need to finish this assignment after today‚Äôs class!\nreview the homework and late work/extension policies on Syllabus: deadline is so we can get timely feedback to you; three 3-day extensions to acknowledge ‚Äúlife happens‚Äù.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#exercises-1",
    "href": "activities/L04-cross-validation.html#exercises-1",
    "title": "Cross-Validation",
    "section": "Exercises",
    "text": "Exercises\n\nReview: In-sample metrics\n\n\n\nSolution\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight + thigh + knee + ankle, data = humans)\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\n# IN-SAMPLE R^2 for model_1 = 0.40\nmodel_1 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.401         0.310  1.98      4.42 0.00345     5  -78.8  172.  183.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# IN-SAMPLE R^2 for model_2 = 0.87\nmodel_2 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.874         0.680  1.35      4.51 0.00205    23  -48.4  147.  188.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# IN-SAMPLE MAE for model_1 = 1.55\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.55\n\n# IN-SAMPLE MAE for model_2 = 0.64\nmodel_2 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard       0.646\n\n\n\n\nIn-sample model comparison\n\n\n\nSolution\n\nThe in-sample metrics are better for model_2, but from experience in our previous class, we should expect this to be overfit.\n\n\n\n10-fold CV\n\n\n\nSolution\n\n\n# 10-fold cross-validation for model_1\nset.seed(253)\nmodel_1_cv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ hip + weight + thigh + knee + ankle,\n    resamples = vfold_cv(humans, v = 10), \n    metrics = metric_set(mae, rsq)\n  )\n\n# STEP 2: 10-fold cross-validation for model_2\nset.seed(253)\nmodel_2_cv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n    resamples = vfold_cv(humans, v = 10), \n    metrics = metric_set(mae, rsq)\n  )\n\n\n\n\nCalculating the CV MAE\n\n\n\nSolution\n\n\n\n\n\n# model_1\n# CV MAE = 1.87, CV R-squared = 0.41\nmodel_1_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   1.87     10   0.159 pre0_mod0_post0\n## 2 rsq     standard   0.409    10   0.124 pre0_mod0_post0\n\n# model_2\n# CV MAE = 2.47, CV R-squared = 0.53\nmodel_2_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   2.47     10   0.396 pre0_mod0_post0\n## 2 rsq     standard   0.526    10   0.122 pre0_mod0_post0\n\n\nWe expect our first model to explain roughly 40% of variability in height among new adults, and to produce predictions of height (for new adults) that are off by 1.9 inches on average.\n\n\n\n\nDetails: fold-by-fold results\n\n\n\nSolution\n\n\n# a. model_1 MAE for each test fold\nmodel_1_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\")\n## # A tibble: 10 √ó 7\n##    splits         id     .metric .estimator .estimate .config         .notes  \n##    &lt;list&gt;         &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;           &lt;list&gt;  \n##  1 &lt;split [35/4]&gt; Fold01 mae     standard        2.22 pre0_mod0_post0 &lt;tibble&gt;\n##  2 &lt;split [35/4]&gt; Fold02 mae     standard        2.34 pre0_mod0_post0 &lt;tibble&gt;\n##  3 &lt;split [35/4]&gt; Fold03 mae     standard        2.56 pre0_mod0_post0 &lt;tibble&gt;\n##  4 &lt;split [35/4]&gt; Fold04 mae     standard        1.51 pre0_mod0_post0 &lt;tibble&gt;\n##  5 &lt;split [35/4]&gt; Fold05 mae     standard        1.81 pre0_mod0_post0 &lt;tibble&gt;\n##  6 &lt;split [35/4]&gt; Fold06 mae     standard        2.43 pre0_mod0_post0 &lt;tibble&gt;\n##  7 &lt;split [35/4]&gt; Fold07 mae     standard        1.61 pre0_mod0_post0 &lt;tibble&gt;\n##  8 &lt;split [35/4]&gt; Fold08 mae     standard        1.84 pre0_mod0_post0 &lt;tibble&gt;\n##  9 &lt;split [35/4]&gt; Fold09 mae     standard        1.28 pre0_mod0_post0 &lt;tibble&gt;\n## 10 &lt;split [36/3]&gt; Fold10 mae     standard        1.10 pre0_mod0_post0 &lt;tibble&gt;\n\n# b. fold 3 had the worst error (2.56)\n\n# c. use these metrics to confirm the 1.87 CV MAE for model_1\nmodel_1_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\") %&gt;% \n  summarize(mean(.estimate))\n## # A tibble: 1 √ó 1\n##   `mean(.estimate)`\n##               &lt;dbl&gt;\n## 1              1.87\n\n\n\n\nComparing models\n\n\n\nSolution\n\n\nmodel_2\nmodel_1\nmodel_1 ‚Äì model_2 produces bad predictions for new adults\nmodel_1 is NOT overfit ‚Äì its predictions of height for new adults seem roughly as accurate as the predictions for the adults in our sample. model_2 IS overfit ‚Äì its predictions of height for new adults are worse than the predictions for the adults in our sample.\n\n\n\n\nData drill\n\n\n\nSolution\n\n\n# a (one of many solutions)\nhumans %&gt;% \n  mutate(younger_older = age &lt; 40) %&gt;% \n  group_by(younger_older) %&gt;% \n  summarize(mean(height))\n## # A tibble: 2 √ó 2\n##   younger_older `mean(height)`\n##   &lt;lgl&gt;                  &lt;dbl&gt;\n## 1 FALSE                   70.4\n## 2 TRUE                    69.8\n\n# b\nhumans %&gt;% \n  filter(age &gt;= 30) %&gt;% \n  ggplot(aes(x = age, y = height)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# c\nmodel_3 &lt;- lm_spec %&gt;%\n  fit(height ~ age, data = humans)\nmodel_3 %&gt;%\n  tidy()\n## # A tibble: 2 √ó 5\n##   term        estimate std.error statistic  p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)  71.1       1.63      43.7   1.96e-33\n## 2 age          -0.0210    0.0363    -0.577 5.67e- 1",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#footnotes",
    "href": "activities/L04-cross-validation.html#footnotes",
    "title": "Cross-Validation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.wallpaperflare.com/grayscale-photography-of-guitar-headstock-music-low-electric-bass-wallpaper-zzbyn‚Ü©Ô∏é",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Homework Assignment",
    "section": "",
    "text": "‚Ä¶due at 11:59 pm Central on Moodle!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 253: Statistical Machine Learning",
    "section": "",
    "text": "STAT 253: Statistical Machine Learning\nMacalester College, Spring 2026\nStatistics is not just about theories & numbers ‚Äî it‚Äôs about making sense of the world.\n\n\n\n\n\n\nüìñ A Thought from H. G. Wells\n\n\n\n\n‚ÄúStatistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.‚Äù\n\n\n\nWelcome to the world of Statistics! In this course, you‚Äôll learn how to analyze data, test research hypotheses, and make predictions in ways that matter.\nInstructor: Md Mutasim Billah  Class meeting times:\n\nSection 03: M/W/F 02:20-03:20pm, THTR 213\n\nOffice hours:\n\nLocation: My office (OLRI 234) and over Zoom\nTimes: M/W: 12:00pm - 12:30pm (in-person), T/TR: 2pm - 3pm (Over zoom, password: 123456)\nBy Appointment: I‚Äôm also happy to meet one-on-one if my normal drop-in/virtual hours don‚Äôt work for you. Shoot me an email and we can arrange it over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays. Please note that messages sent after 3:00 pm or on weekends may take longer to receive a response.\n\n\nSTAT 253 Preceptor Office Hours: There is a link to a Google Calendar containing all preceptor office hours available at the top of the course Moodle page!\nData and R Support: In addition to our course preceptors, there is support on campus for working with data and R / RStudio. See https://www.macalester.edu/mscs/data-support for more information.\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email mbillah@macalester.edu"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Please download and go through the Project Instructions in details.\nThe Rubrics for grading are here.\nParticipate in the STAT 155 Group Project Survey by Monday, October 27."
  },
  {
    "objectID": "stat155.html",
    "href": "stat155.html",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "In this course, we will build on the linear and logistic regression modeling techniques covered in STAT 155. As such, familiarity with key concepts from STAT 155 is expected. This includes, but is not necessarily limited to, the following topics:\n\ndata context: 5W‚Äôs + H (who, what, where, when, why, how)\ndata visualization in R\nlinear regression: least squares, model interpretation, prediction, model evaluation (eg residuals, \\(R^2\\))\nlogistic regression: odds, model interpretation, prediction, model evaluation (eg accuracy, sensitivity)\nbootstrapping\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are rusty on any of these concepts, please review the resources linked below!\n\n\n\n\n\n\n\n\n\n\nLet \\(y\\) be a response variable with a set of \\(k\\) explanatory variables \\(x = (x_{1}, x_{2}, ..., x_{k})\\). Then the population linear regression model is\n\\[\\begin{split}\ny & = f(x) + \\varepsilon  = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\nNOTES:\n\n\\(\\beta\\) is the Greek letter ‚Äúbeta‚Äù. \\(\\varepsilon\\) is the Greek letter ‚Äúepsilon‚Äù.\n\n‚ÄúLinear‚Äù regression is so named because it assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs. It does not mean that the relationship itself is linear!! For example, one of the predictors might be a quadratic term: \\(x_2 = x_1^2\\).\n\\(f(x) = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k}\\) captures the trend of the relationship\n\n\\(\\beta_0\\) = intercept coefficient\nthe model value when \\(x_1=x_2=\\cdots=x_k=0\\)\n\\(\\beta_i\\) = \\(x_i\\) coefficient\nhow \\(x_i\\) is related to \\(y\\) when holding constant all other \\(x_i\\)\n\n\\(\\epsilon\\) reflects deviation from the trend (the residual)\n\n\n\n\nFitting the Model\nOnce we have a population model in mind, we can ‚Äúfit the model‚Äù (i.e.¬†estimate the \\(\\beta\\) population coefficients) using sample data:\n\\[\\begin{split}\ny & =  \\hat{f}(x) + \\varepsilon \\\\\n& = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1} + \\hat{\\beta}_2 x_{2} + \\cdots + \\hat{\\beta}_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\n\n\nTo this end, collect a sample of data on \\(n\\) subjects. Use subscripts to denote the data for subject \\(i\\): \\(y_i\\) and \\(x_{ij}\\). Then the predicted response and residual (prediction error) for subject \\(i\\) are\n\nprediction \\[\\hat{y}_i = \\hat{f}(x_i) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_k x_{ik}\\]\nresidual / prediction error \\[y_i - \\hat{y}_i\\]\n\n\n\n\nLeast Squares Criterion\nEstimate (\\(\\beta_0, \\beta_1,..., \\beta_k\\)) by (\\(\\hat{\\beta}_0, \\hat{\\beta}_1,..., \\hat{\\beta}_k)\\) that minimize the sum of squared residuals: \\[\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = (y_1-\\hat{y}_1)^2 + (y_2-\\hat{y}_2)^2 + \\cdots + (y_n-\\hat{y}_n)^2\\]\n\n\n\n\n\n\nA comprehensive STAT 155 review is provided by the STAT 155 Notes created by Profs. Grinde, Heggeseth, and Myint (here) and Prof.¬†Bill‚Äôs Fall 25 STAT 155 website (skim the topics from the ‚ÄòActivities‚Äô tab as needed!) (here).",
    "crumbs": [
      "STAT 155 Resources"
    ]
  },
  {
    "objectID": "stat155.html#important-topics",
    "href": "stat155.html#important-topics",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "In this course, we will build on the linear and logistic regression modeling techniques covered in STAT 155. As such, familiarity with key concepts from STAT 155 is expected. This includes, but is not necessarily limited to, the following topics:\n\ndata context: 5W‚Äôs + H (who, what, where, when, why, how)\ndata visualization in R\nlinear regression: least squares, model interpretation, prediction, model evaluation (eg residuals, \\(R^2\\))\nlogistic regression: odds, model interpretation, prediction, model evaluation (eg accuracy, sensitivity)\nbootstrapping\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are rusty on any of these concepts, please review the resources linked below!",
    "crumbs": [
      "STAT 155 Resources"
    ]
  },
  {
    "objectID": "stat155.html#review-resources",
    "href": "stat155.html#review-resources",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "Let \\(y\\) be a response variable with a set of \\(k\\) explanatory variables \\(x = (x_{1}, x_{2}, ..., x_{k})\\). Then the population linear regression model is\n\\[\\begin{split}\ny & = f(x) + \\varepsilon  = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\nNOTES:\n\n\\(\\beta\\) is the Greek letter ‚Äúbeta‚Äù. \\(\\varepsilon\\) is the Greek letter ‚Äúepsilon‚Äù.\n\n‚ÄúLinear‚Äù regression is so named because it assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs. It does not mean that the relationship itself is linear!! For example, one of the predictors might be a quadratic term: \\(x_2 = x_1^2\\).\n\\(f(x) = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k}\\) captures the trend of the relationship\n\n\\(\\beta_0\\) = intercept coefficient\nthe model value when \\(x_1=x_2=\\cdots=x_k=0\\)\n\\(\\beta_i\\) = \\(x_i\\) coefficient\nhow \\(x_i\\) is related to \\(y\\) when holding constant all other \\(x_i\\)\n\n\\(\\epsilon\\) reflects deviation from the trend (the residual)\n\n\n\n\nFitting the Model\nOnce we have a population model in mind, we can ‚Äúfit the model‚Äù (i.e.¬†estimate the \\(\\beta\\) population coefficients) using sample data:\n\\[\\begin{split}\ny & =  \\hat{f}(x) + \\varepsilon \\\\\n& = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1} + \\hat{\\beta}_2 x_{2} + \\cdots + \\hat{\\beta}_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\n\n\nTo this end, collect a sample of data on \\(n\\) subjects. Use subscripts to denote the data for subject \\(i\\): \\(y_i\\) and \\(x_{ij}\\). Then the predicted response and residual (prediction error) for subject \\(i\\) are\n\nprediction \\[\\hat{y}_i = \\hat{f}(x_i) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_k x_{ik}\\]\nresidual / prediction error \\[y_i - \\hat{y}_i\\]\n\n\n\n\nLeast Squares Criterion\nEstimate (\\(\\beta_0, \\beta_1,..., \\beta_k\\)) by (\\(\\hat{\\beta}_0, \\hat{\\beta}_1,..., \\hat{\\beta}_k)\\) that minimize the sum of squared residuals: \\[\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = (y_1-\\hat{y}_1)^2 + (y_2-\\hat{y}_2)^2 + \\cdots + (y_n-\\hat{y}_n)^2\\]\n\n\n\n\n\n\nA comprehensive STAT 155 review is provided by the STAT 155 Notes created by Profs. Grinde, Heggeseth, and Myint (here) and Prof.¬†Bill‚Äôs Fall 25 STAT 155 website (skim the topics from the ‚ÄòActivities‚Äô tab as needed!) (here).",
    "crumbs": [
      "STAT 155 Resources"
    ]
  }
]