[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Section 03: M/W/F 02:20-03:20pm, THTR 213\nWelcome to STAT 253! This class is an introduction to the exciting world of statistical machine learning. Broadly, statistical machine learning consists of tools and algorithms to learn from data. Insights from machine learning help us take action by enabling us to make predictions and understand uncertainty. Applications of machine learning algorithms are used everywhere from finance to biology, medicine, social sciences, language, and the humanities.\nIn this course, you will build on the linear and logistic regression modeling techniques covered in STAT 155 to understand tools of regression (Weeks 2‚Äì6) and classification (Weeks 7‚Äì11) more broadly. You will also learn about unsupervised learning methods (Weeks 12‚Äì15) that can help you find underlying structure in data. Along the way, you‚Äôll also improve your skills in computational thinking/programming, communication, collaboration, ethical thinking, and reflection, all of which are vital in any profession.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#about-your-professor",
    "href": "syllabus.html#about-your-professor",
    "title": "Syllabus",
    "section": "About your professor",
    "text": "About your professor\n\nMd Mutasim Billah, PhD\nPronunciation: listen here\nOffice: Olin-Rice 234\nEmail: mbillah@macalester.edu\n\n\n\n\n\n\nNotes from ‚Äúyour professor‚Äù\n\n\n\nGreetings! You can call me Bill or Professor Billah & I use he/him pronouns. Back when I was an undergrad student, I didn‚Äôt have the best experience in Intro Stat‚Äîthose courses often emphasized formulas over real understanding. That experience has shaped my teaching‚ÄîI concentrate on illustrating how statistical theories connect and can be applied in the real world. I‚Äôm excited to teach STAT 253 and to create a more meaningful experience‚Äîone that helps all students feel confident applying it beyond the classroom. My methodological research lies at the intersection of statistical genetics, biostatistics, and genomics. My current research interests include developing novel statistical methods and computationally efficient bioinfor matics tools, leveraging modern machine- and deep-learning approaches analyze high-dimensional next-generation sequencing and multi-omics data to identify genes and regulatory mechanisms underlying complex diseases. Outside of my academic work, I enjoy spending time outdoors with family and friends or cooking variety of foods. If you can‚Äôt find me anywhere, I might be busy playing soccer or exploring new worlds on my PS5 Pro!\n\n\nOffice hours:\n\nLocation: My office (OLRI 234) and over Zoom\nTimes: M/W: 12:00pm - 12:30pm (in-person), T/TR: 2pm - 3pm (Over zoom, password: 123456)\nBy Appointment: I‚Äôm also happy to meet one-on-one if my normal drop-in/virtual hours don‚Äôt work for you. Shoot me an email and we can arrange it over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays. Please note that messages sent after 3:00 pm or on weekends may take longer to receive a response.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#about-your-preceptors",
    "href": "syllabus.html#about-your-preceptors",
    "title": "Syllabus",
    "section": "About your preceptors",
    "text": "About your preceptors\nWe have four awesome preceptors who will be helping out with STAT 253 this semester. See the calendar on Moodle for up-to-date information about their office hour times and locations.\nThe role of an MSCS preceptor is to help students with content questions, assist in the navigation of available resources, advise on studying approaches for classes, and assist with concepts, tools, and skills needed for problem sets. Students are accountable for their own learning; as such, preceptors are not allowed to share answers to assignments (unless specifically directed by the instructor), are not expected to immediately know the right approach, or provide assistance outside of office hours. Additional guidelines and expectations on how to interact with preceptors can be found here.\nData and R Support: In addition to our course preceptors, there is support on campus for working with data and R / RStudio. See https://www.macalester.edu/mscs/data-support for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbook-online-course-manual",
    "href": "syllabus.html#textbook-online-course-manual",
    "title": "Syllabus",
    "section": "Textbook & Online Course Manual",
    "text": "Textbook & Online Course Manual\n\nOur textbook, ISLR, is available free online: An Introduction to Statistical Learning with Applications in R (2nd edition). James et al, 2021.. The ISLR readings are highly encouraged and serve as a nice complement to the videos and in-class activities.\nThroughout the course, readings will be assigned from these notes, or other sources.\nThe online course websitel includes all in-class activities (with solutions).\nSee the rough schedule of the course, which is subject to change as needed.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#moodle",
    "href": "syllabus.html#moodle",
    "title": "Syllabus",
    "section": "Moodle",
    "text": "Moodle\nMoodle includes important announcements, general resources, a broad course calendar, submission links, feedback, and a forum for student questions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#statistical-software",
    "href": "syllabus.html#statistical-software",
    "title": "Syllabus",
    "section": "Statistical software",
    "text": "Statistical software\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, and RStudio are available on the R Resources tab.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#office-hours-oh-and-r-support",
    "href": "syllabus.html#office-hours-oh-and-r-support",
    "title": "Syllabus",
    "section": "Office hours (OH) and R Support",
    "text": "Office hours (OH) and R Support\nOH: Across the instructor and preceptors, there are several office hours each week. Names, times, and locations are on the Moodle course calendar. IMPORTANT: Always check the calendar before attending OH.\nData & R Support: In addition to the course preceptors, there is support on campus for working with data and R / RStudio. This is a great resource for R setup and troubleshooting throughout the semester. See https://www.macalester.edu/mscs/data-support for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#before-class",
    "href": "syllabus.html#before-class",
    "title": "Syllabus",
    "section": "Before Class",
    "text": "Before Class\nIn order to dedicate our class time to hands-on learning, you will prepare for class by watching short videos, reading from our textbook, and completing short quizzes (checkpoints) to assess your initial understanding of concepts. You can reattempt each checkpoint question multiple times, with a small penalty for incorrect responses.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#during-class",
    "href": "syllabus.html#during-class",
    "title": "Syllabus",
    "section": "During Class",
    "text": "During Class\nDuring class time, you will engage with each other in exercises and discussions that build upon the pre-class work. Please bring your laptop to class every day. Consistent attendance and active participation in these activities is expected of all students and, most importantly, will be crucial for your learning!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#after-class",
    "href": "syllabus.html#after-class",
    "title": "Syllabus",
    "section": "After Class",
    "text": "After Class\nAfter class, you will be expected to finish any remaining exercises from the class activity and review/organize your notes. For each unit, you will also complete homework assignments designed to help you practice and synthesize material and provide an opportunity to receive feedback to further guide your learning.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#group-assignments",
    "href": "syllabus.html#group-assignments",
    "title": "Syllabus",
    "section": "Group Assignments",
    "text": "Group Assignments\nhese assignments will give you an opportunity to practice collaboration, communication, and application of core statistical machine learning concepts in a more open-ended setting. They will also provide an opportunity to review and synthesize key concepts prior to each quiz. We will reserve class time at the end of each module‚ÄîRegression (Units 1‚Äì3), Classification (Units 4‚Äì5), and Unsupervised Learning (Units 6‚Äì7)‚Äîto work on these assignments. Deadlines are posted in the Stat 253 Google Calendar on Moodle.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Syllabus",
    "section": "Quizzes",
    "text": "Quizzes\nThe primary assessment of your understanding of core statistical machine learning concepts and R code will come in the form of three in-class quizzes:\n\nQuiz 1: TBD\nQuiz 2: TBD\nQuiz 3: Thurs. 5/7, 1:30pm-3:30pm in class\n\n\n\n\n\n\n\nüìú Quiz Policies\n\n\n\n\nAll quizzes will have the following format:\n\nTaken individually, using pen/pencil & paper\nClosed notes, but you may use a 3x5 index card with writing on both sides. These can be handwritten or typed, but you may not include screenshots or share note cards. Making your own card is important to the review process- as you are required to submit the index card along with the answer paper.\n\nQuiz corrections:\nAfter Quizzes 1 and 2, you will have the opportunity modify your quiz grade by reviewing feedback, completing a short reflection, and revising your answers. Note: Quiz 3 corrections are not allowed due to time constraints at the end of the semester (I‚Äôll take this into consideration when grading!)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#learning-reflections",
    "href": "syllabus.html#learning-reflections",
    "title": "Syllabus",
    "section": "Learning Reflections",
    "text": "Learning Reflections\nThroughout the semester, I want you to practice reflecting on your progress and learning. I will provide a structured set of reflection questions for you to complete roughly once a month. More details (prompts, deadlines, grading, etc.) will be provided in class!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#flexibility",
    "href": "syllabus.html#flexibility",
    "title": "Syllabus",
    "section": "Flexibility",
    "text": "Flexibility\nI provide transparent accommodations to all students. It helps reduce stress and the ‚Äúhidden curriculum‚Äù (not everybody feels comfortable asking for flexibility).\n\nMissed Class: You are warmly invited, encouraged, and expected to attend and participate in all class meetings. Participation means coming to class prepared, actively discussing material, engaging in the activities, and asking questions. This will be important not only for your own learning, but also for our ability to build a community and maintain a sense of connection and commitment to one another during the semester. That being said, it‚Äôs okay to miss class in the case of an emergency.\n\n\n\n\n\n\n\nWhat to Do If You Miss Class\n\n\n\n\nüìß Send me a quick email. You do not need to share a reason for your absence, especially if it‚Äôs personal. It‚Äôs just a simple courtesy & keeps communication lines open.\nüìÖ Check the Course Schedule in the online manual for what is happening in class that day.\nüìù Complete the in-class activity on your own & check the solutions posted in the online manual.\nüí¨ Ask any follow-up questions on the Moodle forum or in office hours (OH).\n\n\n\n\nHomework: There will be a one hour grace period implemented for each assignment. If you need more time than that, email me to request an extension. Each student will automatically (no reason necessary!) be granted the use of three 3-day homework extensions. Except in rare circumstances, I will not grant more than three (or longer than 3-day) extensions.\nCheckpoints: Except in exceptional circumstances, I will NOT grant extensions or accept late submissions for checkpoints. These are important preparation for class.\nMajor learning activities: I cannot guarantee that I will be able to accommodate late work or extensions for group assignments, quizzes, or reflections, but I will do my best to work with you in exceptional circumstances. Send extension requests for any of these major assignments at least one week in advance for full consideration.\n\n\n\n\n\n\n\nü§ù PLEASE REACH OUT WHEN YOU NEED HELP.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai",
    "href": "syllabus.html#artificial-intelligence-ai",
    "title": "Syllabus",
    "section": "Artificial Intelligence (AI)",
    "text": "Artificial Intelligence (AI)\nUsing AI tools is an emerging skill. You may use AI (ChatGPT, Gemini, Grok, etc), with some caveats & limitations:\n\nAI is often wrong, thus is not a good resource on topics for which you don‚Äôt yet have expertise. Relatedly, though AI can be helpful with parts of a statistical analysis (eg: getting unstuck on code, checking grammar), you have to guide that process (eg: what questions are we trying to answer? what‚Äôs a reasonable approach?).\nWork on an exercise for at least 30 minutes before even thinking about AI. You will learn very little if you overly rely on AI, hence be unprepared for other interactions with the material (eg: in-class discussions, quizzes, future courses that build upon 253, etc). Learning comes from you doing the puzzling, not from you producing a correct answer.\nWhether or not you use AI, you must be able to defend/explain any code/discussion you hand in. You cannot simply use AI to bypass your own learning.\nYou may not use AI to generate entire arguments or discussions. Putting code and discussions into your own words is critical for your own deeper learning, independent thinking, and creativity. (For example, imagine how little you‚Äôd learn in a language course if you simply used AI to translate all text for you!!)\nAny use of AI must be cited, just like any other resource.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#community-academic-integrity",
    "href": "syllabus.html#community-academic-integrity",
    "title": "Syllabus",
    "section": "Community & Academic Integrity",
    "text": "Community & Academic Integrity\nMSCS strives to provide a learning environment that is equitable, inclusive, welcoming, mutually respectful, and free of discrimination. You‚Äôre expected to follow the MSCS Community Guidelines. You‚Äôre also required to be familiar with & follow the college‚Äôs academic integrity & other academic policies. In addition to the examples listed there, academic violations in this course include but are not limited to the following:\n\nUsing any materials from any past STAT 253 course, at Mac or elsewhere. Relatedly, you should not provide any materials to any future 253 students.\nGaining access to, using, or distributing solution sets.\nPassing off others‚Äô work as your own. You must be able to defend / explain all work you hand in.\nUsing AI without citation, to generate entire discussions / code blocks, or without being able to defend the results. Policy violations will result in a score of 0 on the work & be reported to the Asst. Dean of Academic Programs & Advising.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading-system",
    "href": "syllabus.html#grading-system",
    "title": "Syllabus",
    "section": "Grading system",
    "text": "Grading system\nThis course uses a grading system designed to combat some of the (many!) problems with ‚Äútraditional‚Äù grades link. My hope is that this alternative grading system will provide space to make and learn from mistakes, engage in feedback loops link, and encourage self-reflection. You will receive qualitative feedback and marks (e.g., PASS, ATTEMPT), rather than points, on most assignments. I will then translate that feedback into an overall letter grade according to the table to the right. Adjusting to this system may take time. I‚Äôll provide feedback and resources to help you track your progress throughout the semester. If you are ever concerned about your learning (or grade), please set up an appointment with me to discuss!\n\n\n\n\n\n\n\nPassing(C)\n\n\nProgressing(B)\n\n\nExemplary(A)\n\n\n\n\n\n\nCheckpoints\n\n\nATTEMPT ‚â• 10\n\n\n\n\nPASS ‚â• 12\n\n\n\n\nHomework\n\n\nATTEMPT ‚â• 5\n\n\n\n\nPASS ‚â• 7\n\n\n\n\nGroupAssignments\n\n\nATTEMPT ‚â• 2\n\n\nATTEMPT ‚â• 3 and PASS ‚â• 2\n\n\nPASS ‚â• 3\n\n\n\n\nReflections\n\n\nATTEMPT ‚â• 2\n\n\nATTEMPT ‚â• 3 and PASS ‚â• 2\n\n\nPASS ‚â• 3\n\n\n\n\nQuizzes(after revision)\n\n\n‚â• 70%\n\n\n‚â• 80%\n\n\n‚â• 90%\n\n\n\n\n\nIf you meet all criteria in a particular column, you will earn that grade. Intermediate grades (e.g., B+, A-) will be given if most requirements in a given column are achieved but some requirements for lower (-) and/or higher (+) grades are met.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#asking-questionscommunicating",
    "href": "syllabus.html#asking-questionscommunicating",
    "title": "Syllabus",
    "section": "Asking questions/communicating",
    "text": "Asking questions/communicating\n\nOffice Hours\nOH are a great place to chat about the course, career planning, life,‚Ä¶ Please visit us!!\n\nOH times & locations are on the Moodle course calendar.\nOH are oriented around group discussion. They are not first come, first served appointments.\nSince it‚Äôs not an effective way to deepen your learning, OH are not a place to sit and do assignments with me or preceptors. It‚Äôs an opportunity to discuss concepts & specific questions.\n\n\n\nMoodle Forum: STAT 253 Discussion Board\nThis forum is where we‚Äôll communicate outside class. Students can post and answer comments / questions there. This is an informal way to converse, ask questions, share info, & connect. Do not rely on receiving responses outside weekdays between 9am & 5pm.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "href": "syllabus.html#what-to-do-when-you-have-a-question-for-me",
    "title": "Syllabus",
    "section": "What to do when you have a question for me?",
    "text": "What to do when you have a question for me?\n\nIf it‚Äôs non-private (e.g.¬†about policies, homework (Practice Problems), class activities, etc), you must post it on STAT 253 Discussion Board in Moodle. Remember- collaboration is the KEY!\nIf it‚Äôs personal (e.g.¬†about an absence), email me.\nIt‚Äôs good, professional practice to check whether your question is already answered in the provided resources. For example:\n\nInfo (what to do if you miss class): syllabus\nDue dates: course calendar at the top of Moodle + course schedule in the online manual\nQuiz dates: syllabus + course calendar at the top of Moodle + course schedule in the online manual\nHomework policies & grading: homework policies & grading doc\nFinals week: syllabus + course calendar at the top of Moodle + course schedule in the online manual",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#thriving-in-stat-253",
    "href": "syllabus.html#thriving-in-stat-253",
    "title": "Syllabus",
    "section": "Thriving in STAT 253",
    "text": "Thriving in STAT 253\n\n\n\n\n\n\nüóìÔ∏è Plan Ahead\n\n\n\nYou should plan to spend ~10-12 hours on any 4-credit course, including class time.1 Stay up-to-date on the course calendar and carve out time for studying & doing homework.\n\n\n\n\n\n\n\n\n‚úÖ Do the Things\n\n\n\nAt minimum, thriving in this course requires the completion of some concrete tasks. Complete all assignments, regularly attend & engage in class, complete in-class activities (which might mean completing work outside of class), and check the activity solutions.\n\n\n\n\n\n\n\n\nüèóÔ∏è Build a Foundation\n\n\n\nIf your main focus is on checking off some boxes, you won‚Äôt get much out of this course (or college in general). Deeper, enduring learning requires more. Carve out time to rewrite, reflect upon, & review your notes. Summarize concepts in your own words.\n\n\n\n\n\n\n\n\nüéâ Engage, Ask Questions, Have Fun\n\n\n\nActively participate in the class & take ownership of your learning. PLEASE: Don‚Äôt be afraid to ask for help, make mistakes, and ask questions! These skills are critical to your well-being & learning. Finally, have some fun, be curious, and reflect upon what surprises you about the material and yourself",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#attend-class.",
    "href": "syllabus.html#attend-class.",
    "title": "Syllabus",
    "section": "Attend class.",
    "text": "Attend class.\nWe‚Äôll use class time to ask and answer questions, review material, and practice concepts in a collaborative environment. To ensure the best learning experience for you and your classmates, come prepared, engage in class, and make full use of the entire class period.\n\n\n\n\n\n\nüìå If you miss class‚Ä¶\n\n\n\ncheck the course website to see what you missed, review that material and complete the activity on your own, get notes from your classmates, and then (after doing all of the above) come to office hours with any remaining specific questions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#ask-questions.",
    "href": "syllabus.html#ask-questions.",
    "title": "Syllabus",
    "section": "Ask questions.",
    "text": "Ask questions.\nWhen you have questions, please stop me during class, ask your neighbor, post on Moodle discussion board, and come to office hours. Saying ‚ÄúI don‚Äôt understand‚Äù is an important part of learning and it helps others. Office hours are a great time to talk about course material and assignments, study strategies, selecting courses, declaring a major, grad school and/or career planning, or life. You don‚Äôt need to have a specific question in order to attend office hours: it can also be a great space to review concepts, talk through examples, or just chat!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#make-time.",
    "href": "syllabus.html#make-time.",
    "title": "Syllabus",
    "section": "Make time.",
    "text": "Make time.\nPerforming a thoughtful statistical analysis requires time: to plan, to implement, to interpret, and to revise. Start your assignments early. It is very hard to be creative or to debug R code when you are in a rush. You should expect to spend about 10 hours per week on this class (including the 3 hours we spend together during class). If you‚Äôre spending much more (or less!) time than that, please let me know.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#prioritize-your-well-being.",
    "href": "syllabus.html#prioritize-your-well-being.",
    "title": "Syllabus",
    "section": "Prioritize your well-being.",
    "text": "Prioritize your well-being.\nTaking care of yourself will help you engage more fully in your academic experience. Beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities with you. If you are having difficulties maintaining your well-being, I encourage you to contact me and/or check out these resources.\n\n\n\n\n\n\nüìå Important‚Ä¶\n\n\n\nAs part of prioritizing your well-being (and that of others around you), it is important that you stay home if you are feeling sick. This is particularly meaningful to me as someone with a severely immunocompromised family member. I will happily work with you to get you caught up!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#communicate.",
    "href": "syllabus.html#communicate.",
    "title": "Syllabus",
    "section": "Communicate.",
    "text": "Communicate.\nI will do my best to clearly and promptly communicate any changes to expectations, deadlines, office hours, or class meetings. Please make sure to check your email (and Moodle announcement) so you don‚Äôt miss any important announcements. I know that you may also have issues come up: if so, please get in touch with me to discuss solutions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": "Syllabus",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations.\nIn an effort to respect religious diversity, I request that students who plan to observe a religious holiday during scheduled class meetings/class requirements talk to me about reasonable consideration by the end of the second week of the course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": "Syllabus",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address sensitive topics. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester‚Äôs Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others‚Äô ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you. If you are having difficulties maintaining your well-being, please don‚Äôt hesitate to contact me and/or find support from physical and mental health resources here, here, and here.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMacalester Academic Advising ‚Äì High School Preparation‚Ü©Ô∏é",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Course Schedule",
    "section": "",
    "text": "The (tentative) course schedule below will be filled in throughout the semester. For each day, there will be written on what is due ahead of class time OR whats‚Äô the big thing (like quizzes!). Any important announcements will be made over email (moodle)."
  },
  {
    "objectID": "learning.html",
    "href": "learning.html",
    "title": "Learning Goals",
    "section": "",
    "text": "Specific skills and course topics are listed below. Use this list to guide your synthesis of video and reading material for specific topics, and your learning more generally, throughout the semester. It also serves as a study guide for quizzes and other assessments.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#computational-thinking",
    "href": "learning.html#computational-thinking",
    "title": "Learning Goals",
    "section": "Computational Thinking",
    "text": "Computational Thinking\n\nDecomposition: Break a task into smaller tasks to be able to explain the process to another person or computer\nPattern Recognition: Recognize patterns in tasks by noticing similarities and common differences\nAbstraction: Represent an idea or process in general terms so that you can use it to solve other projects that are similar in nature\nAlgorithmic Thinking: Develop a step-by-step strategy for solving a problem",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#ethical-data-thinking",
    "href": "learning.html#ethical-data-thinking",
    "title": "Learning Goals",
    "section": "Ethical Data Thinking",
    "text": "Ethical Data Thinking\n\nIdentify ethical issues associated with applications of statistical machine learning in a variety of settings\nAssess and critique the actions of individuals and organizations as it relates to ethical use of data",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#data-communication",
    "href": "learning.html#data-communication",
    "title": "Learning Goals",
    "section": "Data Communication",
    "text": "Data Communication\n\nIn written and oral formats: Inform and justify data analysis and modeling process and the resulting conclusions with clear, organized, logical, and compelling details that adapt to the background, values, and motivations of the audience and context in which communication occurs.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#collaborative-learning",
    "href": "learning.html#collaborative-learning",
    "title": "Learning Goals",
    "section": "Collaborative Learning",
    "text": "Collaborative Learning\n\nUnderstand and demonstrate characteristics of effective collaboration (team roles, interpersonal communication, self-reflection, awareness of social dynamics, advocating for yourself and others).\nDevelop a common purpose and agreement on goals.\nBe able to contribute questions or concerns in a respectful way.\nShare and contribute to the group‚Äôs learning in an equitable manner.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#reflection",
    "href": "learning.html#reflection",
    "title": "Learning Goals",
    "section": "Reflection",
    "text": "Reflection\n\nRegularly reflect on your learning to make note of and celebrate your progress, identify opportunities for continued growth, and set goals",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-0",
    "href": "learning.html#unit-0",
    "title": "Learning Goals",
    "section": "Unit 0",
    "text": "Unit 0\nIntroduction to Statistical Machine Learning\n\n\n\n\n\n\nTopics\n\n\n\n\nFormulate research questions that align with regression, classification, or unsupervised learning tasks.\nIdentify the appropriate task (regression, classification, unsupervised) for a given research question.",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-1",
    "href": "learning.html#unit-1",
    "title": "Learning Goals",
    "section": "Unit 1",
    "text": "Unit 1\nEvaluating Regression Models\n\n\n\n\n\n\nTopics\n\n\n\n\nCreate and interpret residuals vs.¬†fitted, residuals vs.¬†predictor plots to identify improvements in modeling and address ethical concerns.\nCalculate and interpret MSE, RMSE, MAE, and R-squared in a contextually meaningful way.\n\n\n\nOverfitting and Cross-Validation\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain why training/in-sample model evaluation metrics can provide a misleading view of true test/out-of-sample performance\nAccurately describe all steps of cross-validation to estimate the test/out-of-sample version of a model evaluation metric\nExplain what role CV has in a predictive modeling analysis and its connection to overfitting\nExplain the pros/cons of higher vs.¬†lower k in k-fold CV in terms of sample size and computing time",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-2",
    "href": "learning.html#unit-2",
    "title": "Learning Goals",
    "section": "Unit 2",
    "text": "Unit 2\nVariable Selection\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the difference between inferential models and predictive models and how the model building processes differ\nClearly describe the backward stepwise selection algorithm and why they are examples of greedy algorithms\nCompare best subset and stepwise algorithms in terms of optimality of output and computational time\n\n\n\nLASSO (shrinkage/regularization)\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain how ordinary and penalized least squares are similar and different with regard to (1) the form of the objective function (i.e., the function we are trying to minimize) and (2) the goal of variable selection\nExplain how the lambda tuning parameter affects model performance and how this is related to overfitting",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-3",
    "href": "learning.html#unit-3",
    "title": "Learning Goals",
    "section": "Unit 3",
    "text": "Unit 3\nKNN Regression and the Bias-Variance Tradeoff\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the KNN algorithm for making a regression prediction\nExplain how the number of neighbors relates to the bias-variance tradeoff\nExplain the difference between parametric and nonparametric methods\nExplain how the curse of dimensionality relates to the performance of KNN\n\n\n\nLocal Regression and Splines\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe the local regression algorithm for making a prediction\nExplain how bandwidth (span) relate to the bias-variance tradeoff\nExplain the advantages of splines over global transformations (e.g.¬†y ~ poly(x, 2)) and other types of piecewise polynomials\nExplain how splines are constructed by drawing connections to variable transformations and least squares\nExplain how the number of knots relates to the bias-variance tradeoff",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-4",
    "href": "learning.html#unit-4",
    "title": "Learning Goals",
    "section": "Unit 4",
    "text": "Unit 4\nClassification via Logistic regression\n\n\n\n\n\n\nTopics\n\n\n\n\nUse a logistic regression model to make hard (class) and soft (probability) predictions\nInterpret non-intercept coefficients from logistic regression models in the data context\n\n\n\nEvaluating Classification Models\n\n\n\n\n\n\nTopics\n\n\n\n\nCalculate (by hand from confusion matrices) and contextually interpret overall accuracy, sensitivity, and specificity\nConstruct and interpret plots of predicted probabilities across classes\nExplain how a ROC curve is constructed and the rationale behind AUC as an evaluation metric\nAppropriately use and interpret the no-information rate to evaluate accuracy metrics",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-5",
    "href": "learning.html#unit-5",
    "title": "Learning Goals",
    "section": "Unit 5",
    "text": "Unit 5\nKNN Classification\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the KNN algorithm for making a classification prediction\nInterpret a KNN classification region plot\nDiscuss the pros and cons of KNN classification relative to other classification tools (eg logistic regression, decision trees)\n\n\n\nDecision Trees\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe the recursive binary splitting algorithm for tree building for both regression and classification\nCompute the weighted average Gini index to measure the quality of a classification tree split\nCompute the sum of squared residuals to measure the quality of a regression tree split\nExplain how recursive binary splitting is a greedy algorithm\nExplain how different tree parameters relate to the bias-variance tradeoff\n\n\n\nBagging and Random Forests\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the rationale for bagging\nExplain the rationale for selecting a random subset of predictors at each split (random forests)\nExplain how the size of the random subset of predictors at each split relates to the bias-variance tradeoff\nExplain the rationale for and implement out-of-bag error estimation for both regression and classification\nExplain the rationale behind the random forest variable importance measure and why it is biased towards quantitative predictors (in class)",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-6",
    "href": "learning.html#unit-6",
    "title": "Learning Goals",
    "section": "Unit 6",
    "text": "Unit 6\nHierarchical Clustering\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the hierarchical clustering algorithm\nCompare and contrast k-means and hierarchical clustering in their outputs and algorithms\nInterpret cuts of the dendrogram for single and complete linkage\nDescribe the rationale for how clustering algorithms work in terms of within-cluster variation\nDescribe the tradeoff of more vs.¬†less clusters in terms of interpretability\nImplement strategies for interpreting / contextualizing the clusters\n\n\n\nK-Means Clustering\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement by hand the k-means algorithm\nDescribe the rationale for how clustering algorithms work in terms of within-cluster variation\nDescribe the tradeoff of more vs.¬†less clusters in terms of interpretability\nImplement strategies for interpreting / contextualizing the clusters",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "learning.html#unit-7",
    "href": "learning.html#unit-7",
    "title": "Learning Goals",
    "section": "Unit 7",
    "text": "Unit 7\nPrincipal Component Analysis\n\n\n\n\n\n\nTopics\n\n\n\n\nExplain the goal of dimension reduction and how this can be useful in a supervised learning setting\nInterpret and use the information provided by principal component loadings and scores\nInterpret and use a scree plot to guide dimension reduction\n\n\n\nPrincipal Component Regression\n\n\n\n\n\n\nTopics\n\n\n\n\nClearly describe / implement the principal component regression algorithm\nDescribe the tradeoff of choice of principal components (k) in terms of the bias-variance tradeoff\nImplement strategies for choosing k\nDiscuss the pros and cons of principal component regression relative to variable selection and LASSO",
    "crumbs": [
      "Learning Goals"
    ]
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Broadly, statistical machine learning consists of tools and algorithms to learn from data. Insights from machine learning help us take action by enabling us to make predictions and understand uncertainty. Applications of machine learning algorithms are used everywhere from finance to biology, medicine, social sciences, language, and the humanities.\nIn this course, you will build on the linear and logistic regression modeling techniques covered in STAT 155 to understand tools of regression (Units 1‚Äì3) and classification (Units 4‚Äì5) more broadly. You will also learn about unsupervised methods (Units 6‚Äì7) that can help you find underlying structure in data.\n\n\n\nWe‚Äôll return to this diagram frequently throughout the semester!\n\n\n\n\n\n\nAs we build on ideas from STAT 155, familiarity with core concepts from that course is expected.\nCheck out the STAT 155 Review in the Appendix for a list of important topics that we‚Äôll revisit this semester, as well as links to resources if you need a refresher on any of those topics.\n\n\n\n\n\nWe‚Äôll also be building on your introduction to R/RStudio from STAT 155 (and COMP/STAT 112, if applicable).\nTO-DO: During the first week of class, work through the steps on the R and RStudio Setup page in the Appendix to get everything set up for the semester.\nThroughout the semester, if you find yourself needing a refresher or additional resources related to R, check out the R Resources page!\n\n\n\n\n\nYou‚Äôll access most of the materials that you need for this course via this website. Each class period will have its own page on this site. There, you‚Äôll find daily learning goals, lecture notes, discussion questions, and exercises designed to give you hands-on practice with newly introduced concepts.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#stat-155-review",
    "href": "getting-started.html#stat-155-review",
    "title": "Getting Started",
    "section": "",
    "text": "As we build on ideas from STAT 155, familiarity with core concepts from that course is expected.\nCheck out the STAT 155 Review in the Appendix for a list of important topics that we‚Äôll revisit this semester, as well as links to resources if you need a refresher on any of those topics.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#r-setup-and-resources",
    "href": "getting-started.html#r-setup-and-resources",
    "title": "Getting Started",
    "section": "",
    "text": "We‚Äôll also be building on your introduction to R/RStudio from STAT 155 (and COMP/STAT 112, if applicable).\nTO-DO: During the first week of class, work through the steps on the R and RStudio Setup page in the Appendix to get everything set up for the semester.\nThroughout the semester, if you find yourself needing a refresher or additional resources related to R, check out the R Resources page!",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "getting-started.html#course-notes",
    "href": "getting-started.html#course-notes",
    "title": "Getting Started",
    "section": "",
    "text": "You‚Äôll access most of the materials that you need for this course via this website. Each class period will have its own page on this site. There, you‚Äôll find daily learning goals, lecture notes, discussion questions, and exercises designed to give you hands-on practice with newly introduced concepts.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html",
    "href": "activities/L08-knn-bias-variance.html",
    "title": "Knn-bias-variance",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#context",
    "href": "activities/L08-knn-bias-variance.html#context",
    "title": "Knn-bias-variance",
    "section": "Context",
    "text": "Context\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\ntask = regression\n\\(y\\) is quantitative\n(nonparametric) algorithm = K Nearest Neighbors (KNN)",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#goal",
    "href": "activities/L08-knn-bias-variance.html#goal",
    "title": "Knn-bias-variance",
    "section": "Goal",
    "text": "Goal\nOur usual parametric models (eg: linear regression) are too rigid to represent the relationship between \\(y\\) and our predictors \\(x\\). Thus we need more flexible nonparametric models.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#knn-regression",
    "href": "activities/L08-knn-bias-variance.html#knn-regression",
    "title": "Knn-bias-variance",
    "section": "KNN Regression",
    "text": "KNN Regression\nGoal\nBuild a flexible regression model of a quantitative outcome \\(y\\) by a set of predictors \\(x\\),\n\\[y = f(x) + \\varepsilon\\]\n. . .\nIdea\nPredict \\(y\\) using the data on ‚Äúneighboring‚Äù observations. Since the neighbors have similar \\(x\\) values, they likely have similar \\(y\\) values.\n. . .\nAlgorithm\nFor tuning parameter K, take the following steps to estimate \\(f(x)\\) at each set of possible predictor values \\(x\\):\n\nIdentify the K nearest neighbors of \\(x\\) with respect to Euclidean distance.\nObserve the \\(y\\) values of these neighbors.\nEstimate \\(f(x)\\) by the average \\(y\\) value among the nearest neighbors.\n\n. . .\nOutput\nKNN does not produce a nice formula for \\(\\hat{f}(x)\\), but rather a set of rules for how to calculate \\(\\hat{f}(x)\\).\n. . .\nIn pictures (from ISLR)",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#example-1-review",
    "href": "activities/L08-knn-bias-variance.html#example-1-review",
    "title": "Knn-bias-variance",
    "section": "Example 1: Review",
    "text": "Example 1: Review\nLet‚Äôs review the KNN algorithm using a shiny app. Run the code below and ignore the syntax!!\n\nClick ‚ÄúGo!‚Äù one time only to collect a set of sample data.\nCheck out the KNN with K = 1.\n\nWhat does it mean to pick K = 1?\nWhere are the jumps made?\nCan we write the estimated \\(f(x)\\) (red line) as \\(\\beta_0 + \\beta_1 x + ....\\)?\n\nNow try the KNN with K = 25.\n\nWhat does it mean to pick K = 25?\nIs this more or less wiggly / flexible than when K = 1?\n\nSet K = 100 where 100 is the number of data points. Is this what you expected?\n\n\n\nCode\n# Load packages and data\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(kknn)\nlibrary(ISLR)\n\ndata(College)\ncollege_demo &lt;- College %&gt;% \n  mutate(school = rownames(College)) %&gt;% \n  filter(Grad.Rate &lt;= 100)\nhead(college_demo)\n##                              Private Apps Accept Enroll Top10perc Top25perc\n## Abilene Christian University     Yes 1660   1232    721        23        52\n## Adelphi University               Yes 2186   1924    512        16        29\n## Adrian College                   Yes 1428   1097    336        22        50\n## Agnes Scott College              Yes  417    349    137        60        89\n## Alaska Pacific University        Yes  193    146     55        16        44\n## Albertson College                Yes  587    479    158        38        62\n##                              F.Undergrad P.Undergrad Outstate Room.Board Books\n## Abilene Christian University        2885         537     7440       3300   450\n## Adelphi University                  2683        1227    12280       6450   750\n## Adrian College                      1036          99    11250       3750   400\n## Agnes Scott College                  510          63    12960       5450   450\n## Alaska Pacific University            249         869     7560       4120   800\n## Albertson College                    678          41    13500       3335   500\n##                              Personal PhD Terminal S.F.Ratio perc.alumni Expend\n## Abilene Christian University     2200  70       78      18.1          12   7041\n## Adelphi University               1500  29       30      12.2          16  10527\n## Adrian College                   1165  53       66      12.9          30   8735\n## Agnes Scott College               875  92       97       7.7          37  19016\n## Alaska Pacific University        1500  76       72      11.9           2  10922\n## Albertson College                 675  67       73       9.4          11   9727\n##                              Grad.Rate                       school\n## Abilene Christian University        60 Abilene Christian University\n## Adelphi University                  56           Adelphi University\n## Adrian College                      54               Adrian College\n## Agnes Scott College                 59          Agnes Scott College\n## Alaska Pacific University           15    Alaska Pacific University\n## Albertson College                   55            Albertson College\n\n\n\n\nCode\n# Define a KNN plotting function\nplot_knn &lt;- function(k, plot_data){\n  expend_seq &lt;- sort(c(plot_data$Expend, seq(3000, 57000, length = 5000)))\n  #knn_mod &lt;- knn.reg(train = plot_data$Expend, test = data.frame(expend_seq), y = plot_data$Grad.Rate, k = k)\n  knn_results &lt;- nearest_neighbor() %&gt;%\n    set_mode(\"regression\") %&gt;% \n    set_engine(engine = \"kknn\") %&gt;% \n    set_args(neighbors = k) %&gt;% \n    fit(Grad.Rate ~ Expend, data = plot_data) %&gt;% \n    augment(new_data = data.frame(Expend = expend_seq)) %&gt;% \n    rename(expend_seq = Expend, pred_2 = .pred)\n  ggplot(plot_data, aes(x = Expend, y = Grad.Rate)) + \n    geom_point() + \n    geom_line(data = knn_results, aes(x = expend_seq, y = pred_2), color = \"red\") + \n    labs(title = paste(\"K = \", k), y = \"Graduation Rate\", x = \"Per student expenditure ($)\") +\n    lims(y = c(0,100))\n}\n\n\n# BUILD THE SERVER\n# These are instructions for building the app - what plot to make, what quantities to calculate, etc\nserver_KNN &lt;- function(input, output) {\n  new_data &lt;- eventReactive(input$do, {\n    sample_n(college_demo, size = 100)\n  })\n  output$knnpic &lt;- renderPlot({\n    plot_knn(k = input$kTune, plot_data = new_data())\n  })\n}\n\n\n# BUILD THE USER INTERFACE (UI)\n# The UI controls the layout, appearance, and widgets (eg: slide bars).\nui_KNN &lt;- fluidPage(\n  sidebarLayout(\n    sidebarPanel(\n      h4(\"Sample 100 schools:\"), \n      actionButton(\"do\", \"Go!\"),\n      h4(\"Tune the KNN algorithm:\"), \n      sliderInput(\"kTune\", \"K\", min = 1, max = 100, value = 1)\n    ),\n    mainPanel(\n      h4(\"KNN Plot:\"), \n      plotOutput(\"knnpic\")\n    )\n  )\n)\n\n\n# RUN THE SHINY APP!\nshinyApp(ui = ui_KNN, server = server_KNN)",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#knn-details-weighted-average",
    "href": "activities/L08-knn-bias-variance.html#knn-details-weighted-average",
    "title": "Knn-bias-variance",
    "section": "KNN Details: Weighted Average",
    "text": "KNN Details: Weighted Average\nThe tidymodels KNN algorithm predicts \\(y\\) using weighted averages. kknn package documentation\nThe idea is to give more weight or influence to closer neighbors, and less weight to ‚Äúfar away‚Äù neighbors.\nOptional math:\nLet (\\(y_1, y_2, ..., y_K\\)) be the \\(y\\) outcomes of the K neighbors and (\\(w_1, w_2, ..., w_K\\)) denote the corresponding weights. These weights are defined by a ‚Äúkernel function‚Äù which ensures that: (1) the \\(w_i\\) add up to 1; and (2) the closer the neighbor \\(i\\), the greater its \\(w_i\\). Then the neighborhood prediction of \\(y\\) is:\n\\[\\sum_{i=1}^K w_i y_i\\] The kernel wikipedia page shows common kernel functions.\nThe default ‚Äúoptimal‚Äù kernel used in kknn was defined in a 2012 Annals of Statistics paper.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#example-2-bias-variance-tradeoff",
    "href": "activities/L08-knn-bias-variance.html#example-2-bias-variance-tradeoff",
    "title": "Knn-bias-variance",
    "section": "Example 2: Bias-Variance Tradeoff",
    "text": "Example 2: Bias-Variance Tradeoff\nWhat would happen if we had gotten a different sample of data?!?\n\n\nBias:  On average, across different datasets, how close are the estimates of \\(f(x)\\) to the observed \\(y\\) outcomes?\n\nWe have high bias if our estimates are far from the observed \\(y\\) outcomes\nWe have low bias if our estimates are close to the observed \\(y\\) outcomes\n\nVariance: How variable are the estimates of \\(f(x)\\) from dataset to dataset? Are the estimates stable or do they vary a lot?\n\nWe have high variance if our estimates change a lot from dataset to dataset\nWe have low variance if our estimates don‚Äôt change much from dataset to dataset\n\n\n\n\n\nTo explore the properties of overly flexible models, set K = 1 and click ‚ÄúGo!‚Äù several times to change the sample data. How would you describe how KNN behaves from dataset to dataset:\n\nlow bias, low variance\nlow bias, high variance\nmoderate bias, low variance\nhigh bias, low variance\nhigh bias, high variance\n\nTo explore the properties of overly rigid models, repeat part a for K = 100:\n\nlow bias, low variance\nlow bias, high variance\nmoderate bias, low variance\nhigh bias, low variance\nhigh bias, high variance\n\nTo explore the properties of more balanced models, repeat part a for K = 25:\n\nlow bias, low variance\nlow bias, high variance\nmoderate bias, low variance\nhigh bias, low variance\nhigh bias, high variance",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#example-3-bias-variance-reflection",
    "href": "activities/L08-knn-bias-variance.html#example-3-bias-variance-reflection",
    "title": "Knn-bias-variance",
    "section": "Example 3: Bias-Variance Reflection",
    "text": "Example 3: Bias-Variance Reflection\nIn general‚Ä¶\n\nWhy is ‚Äúhigh bias‚Äù bad?\n\n\nOn average, our prediction errors are large or high\n\n\nWhy is ‚Äúhigh variability‚Äù bad?\n\n\nThe model is not stable / trustworthy, changes depending on the sample data\n\n\nWhat is meant by the bias-variance tradeoff?\n\n\nIdeally, both bias and variance would be low. BUT when we improve one of the features, we hurt the other.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#example-4-bias-variance-tradeoff-for-past-algorithms",
    "href": "activities/L08-knn-bias-variance.html#example-4-bias-variance-tradeoff-for-past-algorithms",
    "title": "Knn-bias-variance",
    "section": "Example 4: Bias-Variance Tradeoff for Past Algorithms",
    "text": "Example 4: Bias-Variance Tradeoff for Past Algorithms\n\nThe LASSO algorithm depends upon tuning parameter \\(\\lambda\\):\n\nWhen \\(\\lambda\\) is too small, the model might keep too many predictors, hence be overfit.\nWhen \\(\\lambda\\) is too big, the model might kick out too many predictors, hence be too simple.\n\nWith this in mind:\n\n\nFor which values of \\(\\lambda\\) (small or large) will LASSO be the most biased?\n\nFor which values of \\(\\lambda\\) (small or large) will LASSO be the most variable?\n\n\nThe bias-variance tradeoff also comes into play when comparing across algorithms, not just within algorithms. Consider LASSO vs least squares:\n\nWhich will tend to be more biased?\n\nWhich will tend to be more variable?\n\nWhen will LASSO beat least squares in the bias-variance tradeoff game?",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#instructions",
    "href": "activities/L08-knn-bias-variance.html#instructions",
    "title": "Knn-bias-variance",
    "section": "Instructions",
    "text": "Instructions\nContext\nUsing the College dataset from the ISLR package, we‚Äôll explore the KNN model of college graduation rates (Grad.Rate) by:\n\ninstructional expenditures per student (Expend)\nnumber of first year students (Enroll)\nwhether the college is Private\n\n\n# Load packages\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(ISLR)\n\n# Load data\ndata(College)\n\n# Wrangle the data\ncollege_sub &lt;- College %&gt;% \n  mutate(school = rownames(College)) %&gt;% \n  arrange(factor(school, levels = c(\"Macalester College\", \"Luther College\", \"University of Minnesota Twin Cities\"))) %&gt;% \n  filter(Grad.Rate &lt;= 100) %&gt;% \n  filter((Grad.Rate &gt; 50 | Expend &lt; 40000)) %&gt;% \n  select(Grad.Rate, Expend, Enroll, Private)\n\nCheck out a codebook from the console:\n\n?College\n\n. . .\nGoals\n\nUnderstand how ‚Äúneighborhoods‚Äù are defined using multiple predictors (both quantitative and categorical) and how data pre-processing steps are critical to this definition.\nTune and build a KNN model in R.\nApply the KNN model.\nIt is easier to review code than to deepen your understanding of new concepts outside class. Prioritize and focus on the concepts over the R code. You will later come back and reflect on the code.\n\n. . .\nDirections\n\nStay engaged. Studies show that when you‚Äôre playing cards, watching vids, continuously on your message app, it impacts both your learning and the learning of those around you.\nBe kind to yourself. You will make mistakes!\nBe kind to each other. Collaboration improves higher-level thinking, confidence, communication, community, & more.\n\nactively contribute to discussion\nactively include all other group members in discussion\ncreate a space where others feel comfortable making mistakes & sharing their ideas\nstay in sync\n\nAs you go, consider: W.A.I.T. (Why Am/Aren‚Äôt I Talking?)",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#questions",
    "href": "activities/L08-knn-bias-variance.html#questions",
    "title": "Knn-bias-variance",
    "section": "Questions",
    "text": "Questions\n\nPart 1: Identifying neighborhoods\nThe KNN model for Grad.Rate will hinge upon the neighborhoods defined by the 3 Expend, Enroll, and Private predictors. And these neighborhoods hinge upon how we pre-process our predictors.\nWe‚Äôll explore these ideas below using the results of the following chunk. Run this, but DON‚ÄôT spend time examining the code!\n\nrecipe_fun &lt;- function(recipe){\n  recipe &lt;- recipe %&gt;% \n    prep() %&gt;% \n    bake(new_data = college_sub) %&gt;% \n    head(3) %&gt;% \n    select(-Grad.Rate) %&gt;% \n    as.data.frame()\n  row.names(recipe) &lt;- c(\"Mac\",\"Luther\", \"UMN\")\n  return(recipe)\n}\n# Recipe 1: create dummies, but don't standardize\nrecipe_1 &lt;- recipe(Grad.Rate ~ Expend + Enroll + Private, data = college_sub) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())\nrecipe_1_data &lt;- recipe_fun(recipe_1)\n\n# Recipe 2: standardize, then create dummies\nrecipe_2 &lt;- recipe(Grad.Rate ~ Expend + Enroll + Private, data = college_sub) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors())\nrecipe_2_data &lt;- recipe_fun(recipe_2)\n\n# Recipe 3: create dummies, then standardize\nrecipe_3 &lt;- recipe(Grad.Rate ~ Expend + Enroll + Private, data = college_sub) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\nrecipe_3_data &lt;- recipe_fun(recipe_3)\n\n\n\n\nFeature space\n\nCheck out the feature space of our 3 predictors and take note of which school is the closer neighbor of Mac: UMN or Luther.\n\nggplot(college_sub, aes(x = Expend, y = Enroll, color = Private)) + \n  geom_point(alpha = 0.5) + \n  geom_text(data = head(college_sub, 3), aes(x = Expend, y = Enroll, label = c(\"Mac\",\"Luther\", \"UMN\")), color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nWhat happens when we don‚Äôt standardize the predictors?\n\nOf course, KNN relies upon mathematical metrics (Euclidean distance), not visuals, to define neighborhoods. And these neighborhoods depend upon how we pre-process our predictors. Consider the pre-processing recipe_1 which uses step_dummy() but not step_normalize():\n\nrecipe_1_data\n##        Expend Enroll Private_Yes\n## Mac     14213    452           1\n## Luther   8949    587           1\n## UMN     16122   3524           0\n\n\nUse this pre-processed data to calculate the Euclidean distance between Mac and Luther:\n\n\nsqrt((14213 - ___)^2 + (452 - ___)^2 + (1 - ___)^2)\n\n\nsqrt((14213 - 8949)^2 + (452 - 587)^2 + (1 - 1)^2)\n## [1] 5265.731\n\n\nCheck your distance calculation, and calculate the distances between the other school pairs, using dist().\n\n\ndist(recipe_1_data)\n##             Mac   Luther\n## Luther 5265.731         \n## UMN    3616.831 7750.993\n\n\nBy this metric, is Mac closer to Luther or UMN? So is this a reasonable metric? If not, why did this happen?\n\n\n\n\nWhat happens when we standardize then create dummy predictors?\nThe metric above was misleading because it treated enrollments (people) and expenditures ($) as if they were on the same scale. In contrast, recipe_2 first uses step_normalize() and then step_dummy() to pre-process the predictors:\n\n\nrecipe_2_data\n##            Expend     Enroll Private_Yes\n## Mac     0.9025248 -0.3536904           1\n## Luther -0.1318021 -0.2085505           1\n## UMN     1.2776255  2.9490477           0\n\nCalculate the distance between each pair of schools using these pre-processed data:\n\ndist(recipe_2_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    3.471135 3.599571\n\nBy this metric, is Mac closer to Luther or UMN? So is this a reasonable metric?\n\n\n\nWhat happens when we create dummy predictors then standardize?\nWhereas recipe_2 first uses step_normalize() and then step_dummy() to pre-process the predictors, recipe_3 first uses step_dummy() and then step_normalize():\n\n\nrecipe_3_data\n##            Expend     Enroll Private_Yes\n## Mac     0.9025248 -0.3536904   0.6132441\n## Luther -0.1318021 -0.2085505   0.6132441\n## UMN     1.2776255  2.9490477  -1.6285680\n\n\nHow do the pre-processed data from recipe_3 compare those to recipe_2?\nRECALL: The standardized dummy variables lose some contextual meaning. But, in general, negative values correspond to 0s (not that category), positive values correspond to 1s (in that category), and the further a value is from zero, the less common that category is.\nCalculate the distance between each pair of schools using these pre-processed data. By this metric, is Mac closer to Luther or UMN?\n\n\ndist(recipe_3_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    4.009302 4.120999\n\n\nHow do the distances resulting from recipe_3 compare to those from recipe_2?\n\n\ndist(recipe_2_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    3.471135 3.599571\n\n\nUnlike recipe_2, recipe_3 considered the fact that private schools are relatively more common in this dataset, making the public UMN a bit more unique. Why might this be advantageous when defining neighborhoods? Thus why will we typically first use step_dummy() before step_normalize()?\n\n\ncollege_sub %&gt;% \n  count(Private)\n##   Private   n\n## 1      No 212\n## 2     Yes 563\n\n\n\n\n\n\nPart 2: Build the KNN\nWith a grip on neighborhoods, let‚Äôs now build a KNN model for Grad.Rate.\nFor the purposes of this activity (focusing on concepts over R code), simply run each chunk and note what object it‚Äôs storing.\nYou will later be asked to come back and comment on the code.\nSTEP 1: Specifying the KNN model\n\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(engine = \"kknn\") %&gt;% \n  set_args(neighbors = tune())\n\nSTEP 2: Variable recipe (with pre-processing)\nNote that we use step_dummy() before step_normalize().\n\nvariable_recipe &lt;- recipe(Grad.Rate ~ ., data = college_sub) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nSTEP 3: workflow specification (model + recipe)\n\nknn_workflow &lt;- workflow() %&gt;% \n  add_model(knn_spec) %&gt;% \n  add_recipe(variable_recipe)\n\nSTEP 4: estimate multiple KNN models\nThis code builds 50 KNN models of Grad.Rate, using 50 possible values of K ranging from 1 to 200 (roughly 25% of the sample size of 775).\nIt then evaluates these models with respect to their 10-fold CV MAE.\n\nset.seed(253)\nknn_models &lt;- knn_workflow %&gt;% \n  tune_grid(\n    grid = grid_regular(neighbors(range = c(1, 200)), levels = 50),\n    resamples = vfold_cv(college_sub, v = 10),\n    metrics = metric_set(mae)\n  )\n\n\n\n\n\n\nPart 3: Finalize and apply the KNN\n\nCompare the KNN models\nPlot the CV MAE for each of the KNN models with different tuning parameters K. NOTE: This is the same function we used for the LASSO!\n\n\nknn_models %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nUse this plot to describe the goldilocks problem in tuning the KNN:\n\nWhen K is too small, CV MAE increases because the model is too ‚Ä¶\n\nWhen K is too big, CV MAE increases because the model is too ‚Ä¶\n\n\nWhy did we try a range of K values?\nIn KNN modeling, we typically want to minimize the prediction errors. Given this goal, is the range of K values we tried wide enough? Or might there be a better value for K outside this range?\nIn KNN modeling, why won‚Äôt we typically worry about ‚Äúparsimony‚Äù?\n\n\n\n\nPick K\n\n\nIdentify which value of K minimizes the CV MAE. Make sure this matches up with what you observe in the plot.\n\n\nbest_k &lt;- knn_models %&gt;% \n  select_best()\nbest_k\n## # A tibble: 1 √ó 2\n##   neighbors .config         \n##       &lt;int&gt; &lt;chr&gt;           \n## 1        33 pre0_mod09_post0\n\n\nCalculate and interpret the CV MAE for this model.\n\n\n# Plug in a number or best_k$neighbors\nknn_models %&gt;% \n  collect_metrics() %&gt;% \n  filter(neighbors == ___)\n\n\n\n\nFinal KNN model\n\nBuild your ‚Äúfinal‚Äù KNN model using the optimal value you found for K above. NOTE: We only looked at roughly every 4th possible value of K (K = 1, 5, 9, etc). If we wanted to be very thorough, we could re-run our algorithm using each value of K close to our optimal K.\n\nfinal_knn &lt;- knn_workflow %&gt;% \n  finalize_workflow(parameters = best_k) %&gt;% \n  fit(data = college_sub)\n\nWhat does a tidy() summary of final_knn give you? Does this surprise you?\n\n# DO NOT REMOVE eval = FALSE\nfinal_knn %&gt;% \n  tidy()\n\n\n\n\nMake some predictions\nCheck out Mac and Luther. NOTE: This is old data. Mac‚Äôs current graduation rate is one of the highest (roughly 90%)!\n\n\n# Check out Mac & Luther\nmac_luther &lt;- college_sub %&gt;% \n  head(2)\nmac_luther\n##                    Grad.Rate Expend Enroll Private\n## Macalester College        77  14213    452     Yes\n## Luther College            77   8949    587     Yes\n\n\nUse your KNN model to predict Mac and Luther‚Äôs graduation rates. How close are these to the truth?\n\n\n# Prediction\n___ %&gt;% \n  ___(new_data = ___)\n\n\nDo you have any idea why Mac‚Äôs KNN prediction is higher than Luther‚Äôs? If so, are you using context or something you learned from the KNN?\n\n\n\n\nKNN pros and cons\n\n\nWhat assumptions did the KNN model make about the relationship of Grad.Rate with Expend, Enroll, and Private?\nWhat did the KNN model tell us about the relationship of Grad.Rate with Expend, Enroll, and Private?\nReflecting upon a and b, name one pro of using a nonparametric algorithm like the KNN instead of a parametric algorithm like least squares or LASSO.\nSimilarly, name one con.\nConsider another ‚Äúcon‚Äù. Just as with parametric models, we could add more and more predictors to our KNN model. However, the KNN algorithm is known to suffer from the curse of dimensionality. Why? (A quick Google search might help.)\n\n\n\n\nParametric or nonparametric\n\n\nSuppose we wanted to model the relationship of room and board costs vs out-of-state tuition. Would you use the parametric least squares algorithm or the nonparametric KNN algorithm?\n\n\nggplot(College, aes(x = Outstate, y = Room.Board)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nIn general, in what situations would you use least squares instead of KNN? Why?\n\n\n\n\nR code reflection\n\nRevisit all code in Parts 2 and 3 of the exercises. Comment upon each chunk:\n\nWhat is it doing?\nHow, if at all, does it differ from the least squares and LASSO code?\n\n\n\n\nData drill\n\n\nCalculate the mean Enroll for public vs private schools.\n\n\nPlot the relationship of Grad.Rate vs Enroll, Private, and Expend.\n\n\nIdentify the private schools with first year enrollments exceeding 3000.\n\n\nAsk and answer another question of interest to you.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#todays-material",
    "href": "activities/L08-knn-bias-variance.html#todays-material",
    "title": "Knn-bias-variance",
    "section": "Today‚Äôs Material",
    "text": "Today‚Äôs Material\n\nFinish all the unfinished activities!\nRemember that there‚Äôs an R code reference section at the bottom of these notes!",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#small-group-discussion",
    "href": "activities/L08-knn-bias-variance.html#small-group-discussion",
    "title": "Knn-bias-variance",
    "section": "Small Group Discussion",
    "text": "Small Group Discussion\n\nReview\n\n\n\nSolution\n\n\ndone\nKNN with K = 1:\n\npredict grad rate using the data on the 1 closest neighbor\nwhere the neighorhood changes (in between observed points)\nno\n\nKNN with K = 25:\n\npredict grad rate by average grad rate among 25 closest neighbors\nless wiggly / less flexible\n\nprobably not. it‚Äôs not a straight line. You might have expected a horizontal line at one value. There is a bit more going on to the algorithm (a weighted average).\n\n\n\n\n\n\n\n\n\n\n\nBias-Variance Tradeoff\n\n\n\nSolution\n\n\nlow bias, high variance\nhigh bias, low variance\nmoderate bias, low variance\n\n\n\n\nBias-Variance Reflection\n\n\n\nSolution\n\n\nOn average, our prediction errors are large or high\nThe model is not stable / trustworthy, changes depending on the sample data\nIdeally, both bias and variance would be low. BUT when we improve one of the features, we hurt the other.\n\n\n\n\n\n\n\n\n\n\nBias-Variance Tradeoff for Past Algorithms\n\n\n\nSolution\n\n\n.\n\nlarge. too simple / rigid\nsmall. too overfit / flexible\n\n.\n\nLASSO. it‚Äôs simpler\nleast squares. it‚Äôs more flexible\nwhen the least squares is overfit",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L08-knn-bias-variance.html#exercises-1",
    "href": "activities/L08-knn-bias-variance.html#exercises-1",
    "title": "Knn-bias-variance",
    "section": "Exercises",
    "text": "Exercises\n\nPart 1: Identifying neighborhoods\n\nFeature space\n\n\n\nSolution\n\nLuther\n\n\n\nWhat happens when we don‚Äôt standardize the predictors?\n\n\n\nSolution\n\n\n# a\nsqrt((14213 - 8949)^2 + (452 - 587)^2 + (1 - 1)^2)\n## [1] 5265.731\n    \n# b\ndist(recipe_1_data)\n##             Mac   Luther\n## Luther 5265.731         \n## UMN    3616.831 7750.993\n\n\nUMN. The quantitative predictors are on different scales\n\n\n\n\nWhat happens when we standardize then create dummy predictors?\n\n\n\nSolution\n\nLuther. Yes.\n\nrecipe_2_data\n##            Expend     Enroll Private_Yes\n## Mac     0.9025248 -0.3536904           1\n## Luther -0.1318021 -0.2085505           1\n## UMN     1.2776255  2.9490477           0\ndist(recipe_2_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    3.471135 3.599571\n\n\n\n\nWhat happens when we create dummy predictors then standardize?\n\n\n\nSolution\n\n\nrecipe_3_data\n##            Expend     Enroll Private_Yes\n## Mac     0.9025248 -0.3536904   0.6132441\n## Luther -0.1318021 -0.2085505   0.6132441\n## UMN     1.2776255  2.9490477  -1.6285680\n\n\nPrivate_Yes is now 0.6132441 or -1.6285680, not 1 or 0.\nLuther\n\n\ndist(recipe_3_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    4.009302 4.120999\n\n\nThe distance between Mac and Luther is the same, but the distance between Mac and UMN is bigger.\n\n\ndist(recipe_2_data)\n##             Mac   Luther\n## Luther 1.044461         \n## UMN    3.471135 3.599571\n\n\nSince public schools are more ‚Äúrare‚Äù, the difference between Mac (private) and UMN (public) is conceptually bigger than if private and public schools were equally common.\n\n\n \n\n\nPart 2: Build the KNN\n\n\nSolution\n\nNo ‚Äúanswers‚Äù here. Just run the provided code and make note of what it‚Äôs doing.\nSTEP 1: Specifying the KNN model\n\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(engine = \"kknn\") %&gt;% \n  set_args(neighbors = tune())\n\nSTEP 2: Variable recipe (with pre-processing)\nNote that we use step_dummy() before step_normalize().\n\nvariable_recipe &lt;- recipe(Grad.Rate ~ ., data = college_sub) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nSTEP 3: workflow specification (model + recipe)\n\nknn_workflow &lt;- workflow() %&gt;% \n  add_model(knn_spec) %&gt;% \n  add_recipe(variable_recipe)\n\nSTEP 4: estimate multiple KNN models\nThis code builds 50 KNN models of Grad.Rate, using 50 possible values of K ranging from 1 to 200 (roughly 25% of the sample size of 775).\nIt then evaluates these models with respect to their 10-fold CV MAE.\n\nset.seed(253)\nknn_models &lt;- knn_workflow %&gt;% \n  tune_grid(\n    grid = grid_regular(neighbors(range = c(1, 200)), levels = 50),\n    resamples = vfold_cv(college_sub, v = 10),\n    metrics = metric_set(mae)\n  )\n\n\n\n\n\n\n\nPart 3: Finalize and apply the KNN\n\nCompare the KNN models\n\n\n\nSolution\n\n\nknn_models %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nWhen K is too small, CV MAE increases because the model is too flexible (overfit). When K is too big, CV MAE increases because the model is too rigid (simple).\nBecause we can‚Äôt know in advance what a good value of K is.\nYes, it‚Äôs wide enough. We observe that CV MAE is minimized when K is around 25, it then increases from there.\nKNN always uses all of the predictors we give it. The concept of parsimony in the sense of simplicity/complexity of how many variables are included is not relevant here. Changing \\(K\\) does not lead to a simpler/more complex model in the way changing \\(\\lambda\\) does for LASSO.\n\n\n\n\nPick K\n\n\n\nSolution\n\n\n33 neighbors\n\n\nbest_k &lt;- knn_models %&gt;% \n  select_best()\nbest_k\n## # A tibble: 1 √ó 2\n##   neighbors .config         \n##       &lt;int&gt; &lt;chr&gt;           \n## 1        33 pre0_mod09_post0\n\n\nWe expect the predictions of grad rate for new schools (not in our sample) to be off by 11.3 percentage points.\n\n\n# Plug in a number\nknn_models %&gt;% \n  collect_metrics() %&gt;% \n  filter(neighbors == 33)\n## # A tibble: 1 √ó 7\n##   neighbors .metric .estimator  mean     n std_err .config         \n##       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n## 1        33 mae     standard    11.3    10   0.516 pre0_mod09_post0\n\n# an equivalent but more reproducible way to do this:\nknn_models %&gt;% \n  collect_metrics() %&gt;% \n  filter(neighbors == best_k$neighbors)\n## # A tibble: 1 √ó 7\n##   neighbors .metric .estimator  mean     n std_err .config         \n##       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n## 1        33 mae     standard    11.3    10   0.516 pre0_mod09_post0\n\n\n\n\nFinal KNN model\n\n\n\nSolution\n\n\nfinal_knn &lt;- knn_workflow %&gt;% \n  finalize_workflow(parameters = best_k) %&gt;% \n  fit(data = college_sub)\n\nSince this is a nonparametric method, we can‚Äôt summarize the functional relationship between our outcome and predictors with parameters and thus tidy() doesn‚Äôt have estimates to give us.\n\n\n\nMake some predictions\n\n\n\nSolution\n\n\n.\n\n\n# Prediction\nmac_luther &lt;- college_sub %&gt;% \n  head(2)\n\nfinal_knn %&gt;% \n  predict(new_data = mac_luther)\n## # A tibble: 2 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1  78.8\n## 2  75.7\n\n\nIf you have any ideas, it‚Äôs probably based on context because the KNN hasn‚Äôt given us any info about why it returns higher or lower predictions of grad rate.\n\n\n\n\nKNN pros and cons\n\n\n\nSolution\n\n\nessentially none ‚Äì just that colleges with similar expenditures, enrollments, and school types (private vs public) would have similar graduation rates\nnot much ‚Äì we can just use it for predictions\nKNN doesn‚Äôt make assumptions about relationships (which is very flexible!)\nKNN doesn‚Äôt provide much insight into the relationships between y and x\nWhen calculated by more and more predictors, our nearest neighbors might actually be far away (thus not very similar).\n\n\n\n\nParametric or nonparametric\n\n\n\nSolution\n\n\nleast squares. the relationship is linear, so doesn‚Äôt require the flexibility of a nonparametric algorithm\nwhen the relationships of interest can be reasonably represented by least squares, we should use least squares. It provides much more insight into the relationships.\n\n\n\n\nR code reflection\n\n\n\nSolution\n\nCome to office hours to discuss.\n\n\n\nData drill\n\n\n\nSolution\n\n\n# a\ncollege_sub %&gt;% \n  group_by(Private) %&gt;% \n  summarize(mean(Enroll))\n## # A tibble: 2 √ó 2\n##   Private `mean(Enroll)`\n##   &lt;fct&gt;            &lt;dbl&gt;\n## 1 No               1641.\n## 2 Yes               457.\n# b\nggplot(college_sub, aes(y = Grad.Rate, x = Enroll, size = Expend, color = Private)) + \n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n# c\ncollege_sub %&gt;% \n  filter(Enroll &gt; 3000, Private == \"Yes\")\n##                                   Grad.Rate Expend Enroll Private\n## Boston University                        72  16836   3810     Yes\n## Brigham Young University at Provo        33   7916   4615     Yes\n## University of Delaware                   75  10650   3252     Yes\n\n\nAnswers will vary. Come to office hours to discuss.",
    "crumbs": [
      "Knn-bias-variance"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html",
    "href": "activities/L06-lasso.html",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#context",
    "href": "activities/L06-lasso.html#context",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Context",
    "text": "Context\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\ntask = regression\n\\(y\\) is quantitative\nmodel = linear regression\nWe‚Äôll assume that the relationship between \\(y\\) and (\\(x_1, x_2, ..., x_p\\)) can be represented by\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\varepsilon\\]\nestimation algorithm = LASSO (instead of least squares)",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#least-absolute-shrinkage-and-selection-operator",
    "href": "activities/L06-lasso.html#least-absolute-shrinkage-and-selection-operator",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Least Absolute Shrinkage and Selection Operator",
    "text": "Least Absolute Shrinkage and Selection Operator\nLASSO: Least Absolute Shrinkage and Selection Operator\nDates back to 1996, proposed by Robert Tibshirani (one of the authors of ISLR)\n\nRobert Tibshirani, Regression Shrinkage and Selection Via the Lasso, Journal of the Royal Statistical Society: Series B (Methodological), Volume 58, Issue 1, January 1996, Pages 267‚Äì288, https://doi.org/10.1111/j.2517-6161.1996.tb02080.x",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#goal-model-selection",
    "href": "activities/L06-lasso.html#goal-model-selection",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Goal: Model Selection",
    "text": "Goal: Model Selection\nUse the LASSO algorithm to help us regularize and select the ‚Äúbest‚Äù predictors \\(x\\) to use in a predictive linear regression model of \\(y\\):\n\\[y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\cdots + \\hat{\\beta}_p x_p + \\varepsilon\\]",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#big-idea",
    "href": "activities/L06-lasso.html#big-idea",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Big Idea",
    "text": "Big Idea\n\nPenalize a predictor for adding complexity to the model (by penalizing its coefficient).\nTrack whether the predictor‚Äôs contribution to the model (lowering RSS) is enough to offset this penalty.",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#algorithm-criterion",
    "href": "activities/L06-lasso.html#algorithm-criterion",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Algorithm Criterion",
    "text": "Algorithm Criterion\nIdentify the model coefficients \\(\\hat{\\beta}_1, \\hat{\\beta}_2, ...  \\hat{\\beta}_p\\) that minimize the penalized residual sum of squares:\n\\[\n\\begin{aligned}\nRSS + \\lambda \\sum_{j=1}^p \\vert \\hat{\\beta}_j\\vert &= \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p \\vert \\hat{\\beta}_j\\vert \\\\\n& = \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_{1i} - \\cdots - \\hat{\\beta}_p x_{pi})^2 + \\lambda \\sum_{j=1}^p \\vert \\hat{\\beta}_j\\vert\n\\end{aligned}\n\\]\nwhere\n\nresidual sum of squares (RSS) measures the overall model prediction error\nthe penalty term measures the overall size of the model coefficients\n\\(\\lambda \\ge 0\\) (‚Äúlambda‚Äù) is a tuning parameter\n\n\n\n\n\n\n\nNote\n\n\n\nThis problem is equivalent to finding the model coefficients \\(\\hat{\\beta}_1, \\hat{\\beta}_2, ...  \\hat{\\beta}_p\\) that minimize the residual sum of squares subject to the constraint that \\(\\sum_{j=1}^p \\vert \\beta_j \\vert \\le t\\) where \\(t\\) is a budget for how large \\(\\sum_{j=1}^p \\vert \\beta_j \\vert\\) can be.\n\nLarge budgets, \\(t\\), equate with small penalties, \\(\\lambda\\).\nSmall budgets, \\(t\\), equate with large penalties, \\(\\lambda\\).",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#questions",
    "href": "activities/L06-lasso.html#questions",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Questions",
    "text": "Questions\n1: LASSO vs other algorithms for building linear regression models\nQ. LASSO vs least squares\n- What‚Äôs one advantage of LASSO vs least squares? - Which algorithm(s) require us (or R) to scale the predictors?\nA. LASSO vs least squares - LASSO helps with model selection, i.e.¬†kicks some predictors out of the model, and preventing overfitting. - LASSO requires that the predictors be scaled, but R will do this for us! Least squares does not require us to scale predictors. (As we saw in HW1, scaling predictors doesn‚Äôt affect our predictions or model quality if use least squares.)\nQ. What is one advantage of LASSO vs backward stepwise selection?\nA. LASSO isn‚Äôt greedy- LASSO doesn‚Äôt overestimate the significance of the predictors it retains (its variable selection isn‚Äôt based on p-values).\n\n\n2: LASSO tuning\nWe have to pick a \\(\\lambda\\) penalty tuning parameter for our LASSO model. What‚Äôs the impact of \\(\\lambda\\)?\n\nWhen \\(\\lambda\\) is 0, LASSO is equivalent to least squares.\nAs \\(\\lambda\\) increases, the predictor coefficient estimates shrink toward or to 0.\nIf \\(\\lambda\\) is too big: all predictors are kicked out of the model, and we‚Äôre left with just an intercept. If \\(\\lambda\\) is too small: too few predictors are kicked out, hence the model is complicated and maybe overfit.\nTo decide between a LASSO model that uses \\(\\lambda = 0.01\\) vs \\(\\lambda = 0.1\\), for example, we can compare CV MAE of the LASSO models that use each of these values of \\(\\lambda\\) and pick the one with the smaller CV MAE. (Unless the MAEs are similar, in which case we may prefer the model with the simpler model, i.e.¬†larger \\(\\lambda\\), even if it has a slightly higher MAE.)\n\n\n\n\nCOMMENT: Picking \\(\\lambda\\)\nWe cannot know the ‚Äúbest‚Äù value for \\(\\lambda\\) in advance. This varies from analysis to analysis.\nWe must try a reasonable range of possible values for \\(\\lambda\\). This also varies from analysis to analysis.\nIn general, we have to use trial-and-error to identify a range that is‚Ä¶\n\nwide enough that it doesn‚Äôt miss the best values for \\(\\lambda\\)\nnarrow enough that it focuses on reasonable values for \\(\\lambda\\)",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#instructions",
    "href": "activities/L06-lasso.html#instructions",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Instructions",
    "text": "Instructions\n\nOpen the QMD fo today and scroll down to the Exercises\nWork on implementing LASSO to familiar data\nBecome familiar with the new code structures:\n\ninstead of fit_resamples to run CV, we‚Äôll use tune_grid to tune the algorithm with CV\nnew engine: set_engine('glmnet')\nin general: focus on the concepts over the R code\n\nAs always:\n\nBe kind to yourself/each other\nCollaborate\nAsk me questions as I move around the room",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#questions-1",
    "href": "activities/L06-lasso.html#questions-1",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Questions",
    "text": "Questions\nWe‚Äôll use the LASSO algorithm to help us build a good predictive model of height using the collection of 12 possible predictors in the humans dataset:\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Resolves package conflicts by preferring tidymodels functions\ntidymodels_prefer()\n\n# Load data\nhumans &lt;- read.csv(\"https://mac-stat.github.io/data/bodyfat2.csv\")\nhead(humans)\n##   age weight neck chest abdomen   hip thigh knee ankle biceps forearm wrist\n## 1  36 226.75 41.5 115.3   108.8 114.4  69.2 42.4  24.0   35.4    21.0  20.1\n## 2  55 169.50 37.2 101.7    91.1  97.1  56.6 38.5  22.6   33.4    29.3  18.8\n## 3  44 208.75 41.9 105.6    96.3 102.0  63.3 39.8  24.1   37.3    23.1  19.4\n## 4  49 216.25 40.2 115.6   104.0 109.0  63.7 40.3  23.2   36.8    31.0  18.9\n## 5  43 177.00 39.6 104.0    98.6  99.5  59.5 36.1  22.0   30.1    27.2  17.7\n## 6  43 200.50 37.9 107.2   103.1 105.5  68.8 38.3  23.7   32.1    28.9  18.7\n##   height\n## 1  71.75\n## 2  68.25\n## 3  73.00\n## 4  74.50\n## 5  69.25\n## 6  71.50\n\n\n\n\nLet‚Äôs implement the LASSO. We‚Äôll pause to examine the code. The R code notes section, below, and R code tutorial video (see course Schedule) provide more detail.\n\n# STEP 1: LASSO algorithm / model specification\n# NOTE: we're using a new engine now: glmnet instead of lm\nlasso_spec &lt;- linear_reg() %&gt;%             \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glmnet\") %&gt;%                 \n  set_args(mixture = 1, penalty = tune())  \n\n\n# STEP 2: variable recipe\n# NOTE: \"y ~ .\" is shorthand for \"y as a function of all other variables\"\nvariable_recipe &lt;- recipe(height ~ ., data = humans) %&gt;% \n  step_dummy(all_nominal_predictors())\n\n\n# STEP 3: workflow specification (model + recipe)\nlasso_workflow &lt;- workflow() %&gt;% \n  add_recipe(variable_recipe) %&gt;% \n  add_model(lasso_spec)\n\n\n# STEP 4: Estimate 50 LASSO models using\n# lambda values on a \"grid\" or range from 10^(-5) to 10^(-0.1).\n# Calculate the CV MAE for each of the 50 models.\n# NOTE: we use tune_grid instead of fit_resamples to run CV\n# NOTE: I usually start with a range from 10^(-5) to 10^1 and tweak through trial-and-error.\nset.seed(253)\nlasso_models &lt;- lasso_workflow %&gt;% \n  tune_grid(\n    grid = grid_regular(penalty(range = c(-5, -0.1)), levels = 50),  \n    resamples = vfold_cv(humans, v = 10),   \n    metrics = metric_set(mae)\n  )\n\n\n\n\nExamining the impact of \\(\\lambda\\)- Team\n\nLet‚Äôs compare the CV MAEs (y-axis) for our 50 LASSO models which used 50 different \\(\\lambda\\) values (x-axis):\n\n\nCode\nautoplot(lasso_models) + \n  scale_x_continuous() + \n  xlab(expression(lambda))\n\n\n\n\n\n\n\n\n\n\nWe told R to use a range of \\(\\lambda\\) from -5 to -0.1 on the log10 scale. Calculate this range on the non-log scale and confirm that it matches the x-axis.\n\n\n10^(-5)\n## [1] 1e-05\n10^(-0.1)\n## [1] 0.7943282\n\n\nExplain why this plot displays the ‚ÄúGoldilocks‚Äù problem of tuning \\(\\lambda\\).\n\n\nThe Goldilocks problem is an idea, not a formal statistical theorem. It comes from the fairy tale Goldilocks and the Three Bears, and in statistics / data science it means: Choosing a value that is neither too small nor too large, but ‚Äújust right.‚Äù\n\nCV MAE is large when \\(\\lambda\\) is either too small or too big.\n\n\n\nPicking a \\(\\lambda\\) value- Team\n\n\nIn the plot above, roughly which value of the \\(\\lambda\\) penalty parameter produces the smallest CV MAE? Check your approximation:\n\n\n# get \"best\" lambda\nbest_penalty &lt;- lasso_models %&gt;% \n  select_best(metric = \"mae\")\n\n# print out result\nbest_penalty\n## # A tibble: 1 √ó 2\n##   penalty .config         \n##     &lt;dbl&gt; &lt;chr&gt;           \n## 1  0.0126 pre0_mod32_post0\n\n\nSuppose we prefer a parsimonious model (i.e.¬†as simple as possible, but still explains the data well). The plot below adds error bars to the CV MAE estimates of prediction error (+/- one standard error). (The CV MAE results are estimates because they would change if we had different training data or if we had set a different random seed which would result in different folds.) Any model with a CV MAE that falls within another model‚Äôs error bars is not significantly better or worse at prediction:\n\n\n\nCode\n# with error bars\n# NOTE: we start with the same code as above (lines 1--3), \n# then add error bars (`geom_errorbar`)\nautoplot(lasso_models) + \n  scale_x_continuous() + \n  xlab(expression(lambda)) + \n  geom_errorbar(data = collect_metrics(lasso_models),\n                aes(x = penalty, ymin = mean - std_err, ymax = mean + std_err), \n                alpha = 0.5)\n\n\n\n\n\n\n\n\n\nUse this to approximate the largest \\(\\lambda\\), thus the most simple LASSO model, that produces a CV MAE that‚Äôs within 1 standard error of the best model (thus is not significantly worse). Check your approximation:\n\n# get \"parsimonous\" lambda\nparsimonious_penalty &lt;- lasso_models %&gt;% \n  select_by_one_std_err(metric = \"mae\", desc(penalty))\n\n\n# print out selected lambda\nparsimonious_penalty\n## # A tibble: 1 √ó 2\n##   penalty .config         \n##     &lt;dbl&gt; &lt;chr&gt;           \n## 1   0.200 pre0_mod44_post0\n\n\nMoving forward, we‚Äôll use the parsimonious LASSO model. Simply report the tuning parameter \\(\\lambda\\) here. Just as a radio show needs to tell its audience where to tune the radio dial, it‚Äôs important to explicitly report \\(\\lambda\\) so that we and others can reproduce the model!\n\n\n0.2\n\n\n\n\nPAUSE: Picking a range to try for \\(\\lambda\\)\nThe range of values we tried for \\(\\lambda\\) had the following nice properties. If it didn‚Äôt, we should adjust our range (make it narrower or wider).\n\nOur range was wide enough.\nWe observed the goldilocks effect. Further, the ‚Äúbest‚Äù and ‚Äúparsimonious‚Äù \\(\\lambda\\) values were not at the edges of the range, suggesting there aren‚Äôt better \\(\\lambda\\) values outside our range.\nOur range was narrow enough.\nWe didn‚Äôt observe any loooooong flat lines in CV MAE, thus we narrowed in on the \\(\\lambda\\) values where the ‚Äúaction is happening‚Äù, i.e.¬†where changing \\(\\lambda\\) impacts the model.\n\n\n\n\n\nFinalizing our LASSO model - Group\n\nLet‚Äôs finalize our parsimonious LASSO model:\n\n# fit final LASSO model \n# using selected lambda (parameters = parsimonious_penalty)\n# and full dataset (data = humans)\nfinal_lasso &lt;- lasso_workflow %&gt;% \n  finalize_workflow(parameters = parsimonious_penalty) %&gt;% \n  fit(data = humans)\n\n\n# look at coefficients\nfinal_lasso %&gt;% \n  tidy()\n## # A tibble: 13 √ó 3\n##    term        estimate penalty\n##    &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n##  1 (Intercept)  63.8      0.200\n##  2 age           0        0.200\n##  3 weight        0.0696   0.200\n##  4 neck          0        0.200\n##  5 chest         0        0.200\n##  6 abdomen      -0.126    0.200\n##  7 hip           0        0.200\n##  8 thigh        -0.0199   0.200\n##  9 knee          0.156    0.200\n## 10 ankle         0.0474   0.200\n## 11 biceps        0        0.200\n## 12 forearm       0        0.200\n## 13 wrist         0        0.200\n\n\nHow many and which predictors were kept in this model?\nHow do these compare to the 5-predictor model identified using the backward stepwise selection algorithm with this subset of data: weight, abdomen, thigh, neck, chest\nThrough shrinkage, the LASSO coefficients lose some contextual meaning, so we typically shouldn‚Äôt interpret them. Why don‚Äôt we care?! THINK: What is the goal of LASSO modeling?\nThe LASSO tidy() summary doesn‚Äôt report p-values for testing the ‚Äúsignificance‚Äù of our predictors. Why don‚Äôt we care? (Name two reasons.)\n\n\n\n\nLASSO vs LASSO- Group\n\n\nOur parsimonious LASSO selected only 5 of the 12 possible predictors. Out of curiosity, how many predictors would have remained if we had used the best_penalty value for \\(\\lambda\\)?\n\n\nlasso_workflow %&gt;% \n  finalize_workflow(parameters = ___) %&gt;% \n  fit(data = humans) %&gt;% \n  tidy()\n\n\nlasso_workflow %&gt;% \n  finalize_workflow(parameters = best_penalty) %&gt;% \n  fit(data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(estimate != 0) # add this line to print only non-zero coefficients\n## # A tibble: 12 √ó 3\n##    term        estimate penalty\n##    &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n##  1 (Intercept) 104.      0.0126\n##  2 age          -0.0208  0.0126\n##  3 weight        0.243   0.0126\n##  4 neck         -0.595   0.0126\n##  5 chest        -0.102   0.0126\n##  6 abdomen      -0.200   0.0126\n##  7 hip          -0.0491  0.0126\n##  8 thigh        -0.307   0.0126\n##  9 knee          0.180   0.0126\n## 10 biceps       -0.145   0.0126\n## 11 forearm      -0.0640  0.0126\n## 12 wrist        -0.0864  0.0126\n\n\nBased on this example, do you think LASSO is a greedy algorithm? Are you ‚Äústuck‚Äù with your past locally optimal choices? Compare the predictors in this larger model with those in the smaller, parsimonious model.\n&gt; ankle is not in this larger model but it is in the more parsimonious model. Therefore, the algorithm can‚Äôt be greedy. If it were greedy, then ankle would get removed for all smaller models.\n\n\n\n\nLASSO vs least squares- Group\n\nLet‚Äôs compare our final_lasso model to the least squares model using all predictors:\n\n# Build the least squares model using recipes and workflows\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\nls_workflow &lt;- workflow() %&gt;%\n  add_model(lm_spec) %&gt;%\n  add_recipe(variable_recipe) \n\nls_model &lt;- ls_workflow %&gt;% \n  fit(data = humans) \n\n\n# examine coefficients\nls_model %&gt;% \n  tidy()\n## # A tibble: 13 √ó 5\n##    term        estimate std.error statistic     p.value\n##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n##  1 (Intercept) 110.       16.9       6.51   0.000000561\n##  2 age          -0.0234    0.0367   -0.637  0.529      \n##  3 weight        0.266     0.0573    4.64   0.0000810  \n##  4 neck         -0.671     0.335    -2.00   0.0556     \n##  5 chest        -0.119     0.131    -0.908  0.372      \n##  6 abdomen      -0.196     0.113    -1.73   0.0946     \n##  7 hip          -0.0978    0.189    -0.518  0.609      \n##  8 thigh        -0.313     0.163    -1.92   0.0661     \n##  9 knee          0.199     0.272     0.733  0.470      \n## 10 ankle        -0.0262    0.449    -0.0583 0.954      \n## 11 biceps       -0.168     0.200    -0.837  0.410      \n## 12 forearm      -0.0770    0.144    -0.536  0.596      \n## 13 wrist        -0.0962    0.647    -0.149  0.883\n\n\n# get 10-fold CV MAE\nset.seed(253)\nls_workflow %&gt;% \n  fit_resamples(\n    resamples = vfold_cv(humans,v = 10),\n    metrics = metric_set(mae)\n  ) %&gt;% \n  collect_metrics()\n## # A tibble: 1 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard    1.81    10   0.212 pre0_mod0_post0\n\n\nOur final_lasso has 5 predictors and a CV MAE of 1.9 (calculated above). The ls_model has 12 predictors and a CV MAE of 1.8 (confirm). Comment.\n\n\nLASSO model is much simpler, and has only slightly worse predictions (on the scale of inches).\n\n\nUse both final_lasso and ls_model to predict the height of the new patient below. How do these compare? Does this add to or calm any fears you might have had about shrinking coefficients?!\n\n\nnew_patient &lt;- data.frame(age = 50, weight = 200, neck = 40, chest = 115, abdomen = 105, hip = 100, thigh = 60, knee = 38, ankle = 23, biceps = 32, forearm = 29, wrist = 19) \n\n\n# LS prediction\n___ %&gt;% \npredict(new_data = ___)\n\n\n# LS prediction\nls_model %&gt;% \n  predict(new_data = new_patient)\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1  70.1\n\n\n# LASSO prediction\n___ %&gt;% \npredict(new_data = ___)\n\n\n# LASSO prediction\nfinal_lasso %&gt;% \n  predict(new_data = new_patient)\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1  70.3\n\n\nThey‚Äôre very similar! Shrinking coefficients doesn‚Äôt mean our predictions are odd.\n\n\nWhich final model would you choose, the LASSO or least squares?\n\n\nI‚Äôd choose LASSO since it seems to yield comparably accurate predictions but is much simpler than the full least squares model.\n\n\n\n6. Visualizing LASSO shrinkage\nFinally, let‚Äôs zoom back out and compare the coefficients for all 50 LASSO models:\n\n# Get output for each LASSO model\nall_lassos &lt;- final_lasso %&gt;% \n  extract_fit_parsnip() %&gt;%\n  pluck(\"fit\")\n    \n# Plot coefficient paths as a function of lambda\nplot(all_lassos, xvar = \"lambda\", label = TRUE, col = rainbow(20))\n\n\n\n\n\n\n\n    \n# Codebook for which variables the numbers correspond to\nrownames(all_lassos$beta)\n##  [1] \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"     \"thigh\"  \n##  [8] \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"\n\nThere‚Äôs a lot of information in this plot!\n\nlines = each line represents a different predictor. The small number to the right of each line indicates the predictor by its order in the rownames() list. Click ‚ÄúZoom‚Äù to zoom in.\nx-axis = our range of \\(\\lambda\\) values, on the log scale\ny-axis = coefficient values at the corresponding \\(\\lambda\\)\n\nnumbers above the plot = how many predictors remain in the model with the corresponding \\(\\lambda\\)\n\nWe‚Äôll process this information in the next 2 exercises.\nIf you‚Äôre curious, here is some code to recreate this plot using ggplot:\n\n\nCode\nlasso_coefs &lt;- all_lassos$beta  %&gt;% \n  as.matrix() %&gt;%  \n  t() %&gt;% \n  as.data.frame() %&gt;% \n  mutate(lambda = all_lassos$lambda ) %&gt;%\n  pivot_longer(cols = -lambda, \n               names_to = \"term\", \n               values_to = \"coef\")\n\nlasso_coefs %&gt;% filter(coef != 0, lambda &gt; 1)\n## # A tibble: 2 √ó 3\n##   lambda term      coef\n##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n## 1   1.01 weight 0.00228\n## 2   1.01 knee   0.0271\n\nlasso_coefs %&gt;%\n  ggplot(aes(x = lambda, y = coef, color = term)) +\n  geom_line() +\n  geom_text(data = lasso_coefs %&gt;% filter(lambda == min(lambda)), aes(x = 0.001, label = term), size = 2) + \n  scale_x_log10(limits = c(-2, 2)) +\n  guides(color = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nplot: examining specific predictors\n\nAnswer the following questions for predictor 7.\n\nWhich predictor is this?\n\n\nthigh\n\n\nApproximate the coefficient in the LASSO with \\(log(\\lambda) \\approx -5\\).\n\n\nvery roughly -0.32\n\n\nAt what \\(log(\\lambda)\\) does the coefficient start to significantly shrink?\n\n\nroughly -3.5\n\n\nAt what \\(log(\\lambda)\\) does the predictor get dropped from the model?\n\n\nroughly -1.8\n\n\n\n\nplot: big picture\n\n\nHow does this plot reflect the LASSO shrinkage phenomenon?\n\n\ncoefficients are shrinking toward or to 0 as \\(\\lambda\\) increases (ie \\(-\\log(\\lambda)\\) decreases)\n\n\nWhat is one of the most ‚Äúimportant‚Äù or ‚Äúpersistent‚Äù predictors?\n\n\nweight (variable 2), knee (variable 8)\n\n\nWhat is one of the least persistent predictors?\n\n\nlots of options here. look for the lines that drop to 0 sooner.\n\n\nOur parsimonious LASSO model had 5 predictors. How many predictors would remain if we had minimized the CV MAE using \\(\\lambda \\approx 0.0126\\) (\\(log(\\lambda) = -4.4\\))?\n\n\n11\n\n\n\n\nREVIEW: Model evaluation\n\nLet‚Äôs finalize our LASSO analysis. Just as in least squares, it‚Äôs important to evaluate a LASSO model before applying it. We‚Äôve already examined whether our LASSO model produces accurate predictions. Use a residual plot to determine if this model is wrong. NOTE: augment() gives predictions, but not residuals :/. You‚Äôll need to calculate them.\n\n# Note what augment() gives us\nfinal_lasso %&gt;% \n  augment(new_data = humans) %&gt;% \n  names()\n##  [1] \".pred\"   \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"    \n##  [8] \"thigh\"   \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"   \"height\"\n\n\n# Now calculate and plot the residuals\nfinal_lasso %&gt;% \n  augment(new_data = humans) %&gt;% \n  mutate(.resid = ___) %&gt;% \n  ggplot(aes(x = ___, y = ___)) + \n  geom_point() + \n  geom_smooth() +\n  geom_hline(yintercept = 0)\n\n\n# Now calculate and plot the residuals\nfinal_lasso %&gt;% \n  augment(new_data = humans) %&gt;% \n  mutate(.resid = height - .pred) %&gt;% # resid = observed - predicted\n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point() + \n  geom_smooth() +\n  geom_hline(yintercept = 0) + \n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nAdditional Practice on another dataset.\n\nThe Hitters data in the ISLR package contains the salaries and performance measures for 322 Major League Baseball players. Use LASSO to determine the ‚Äúbest‚Äù predictive model of player Salary.\n\n# Load the data\nlibrary(ISLR)\ndata(Hitters)\nHitters &lt;- Hitters %&gt;% \n  filter(!is.na(Salary))\n\n# IN THE CONSOLE (not in the QMD): Examine codebook\n#?Hitters  \n\n\n\n\nReflection\nThis is the end of the (short!) Unit 2 on ‚ÄúRegression: Model Selection‚Äù! Let‚Äôs reflect on the technical content of this unit:\n\nWhat was the main motivation / goal behind this unit?\nFor each of the following algorithms, describe the steps, pros, cons, and comparisons to least squares:\n\nbest subset selection\nbackward stepwise selection\nLASSO\n\nIn your own words, define the following: parsimonious models, greedy algorithms, Goldilocks problem.\nReview the new tidymodels syntax from this unit. Identify key themes and patterns.",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#ridge-regression",
    "href": "activities/L06-lasso.html#ridge-regression",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Ridge Regression",
    "text": "Ridge Regression\nLASSO isn‚Äôt the only shrinkage & regularization algorithm. An alternative is ridge regression. This algorithm also seeks to build a (predictive) linear regression model of \\(y\\):\n\\[y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\cdots + \\hat{\\beta}_p x_p + \\varepsilon\\]\nIt also does so by selecting coefficients which minimize a penalized residual sum of squares. HOWEVER, the ridge regression penalty is based upon the sum of squared coefficients instead of the sum of absolute coefficients:\n\\[RSS + \\lambda \\sum_{j=1}^p \\hat{\\beta}_j^2\\]\nThis penalty regularizes / shrinks the coefficients. BUT, unlike the LASSO, ridge regression does NOT shrink coefficients to 0, thus cannot be used for variable selection. (Check out the ISLR text for a more rigorous, geometric explanation for why LASSO often shrinks coefficients to 0.)",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#elastic-net",
    "href": "activities/L06-lasso.html#elastic-net",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Elastic Net",
    "text": "Elastic Net\nThe elastic net is yet another shrinkage & regularization algorithm. It combines the penalties used in LASSO and ridge regression. This algorithm seeks to build a (predictive) linear regression model of \\(y\\):\n\\[y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\cdots + \\hat{\\beta}_p x_p + \\varepsilon\\]\nby selecting coefficients which minimize the following penalized residual sum of squares:\n\\[RSS + \\lambda_1 \\sum_{j=1}^p \\vert \\hat{\\beta}_j \\vert + \\lambda_2 \\sum_{j=1}^p \\hat{\\beta}_j^2\\]\nNOTE:\n\nElastic net depends upon two tuning parameters, \\(\\lambda_1\\) and \\(\\lambda_2\\), thus is more complicated than the LASSO.\nIn cases when we have a group of correlated predictors, LASSO tends to select only one of these predictors. The elastic net does not.",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#bayesian-connections",
    "href": "activities/L06-lasso.html#bayesian-connections",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Bayesian Connections",
    "text": "Bayesian Connections\nIF you have taken or will take Bayesian statistics (STAT 454), we can also write the LASSO as a Bayesian model. Specifically, LASSO estimates are equivalent to the posterior mode estimates of \\(\\beta_j\\).\n\\[\\begin{split}\nY_i | \\beta_0,...\\beta_k & \\sim N(\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_p X_p, \\sigma^2) \\\\\n\\beta_j & \\sim \\text{ Laplace (double-exponential)}(0, f(\\lambda)) \\\\\n\\sigma^2 & \\sim \\text{ some prior} \\\\\n\\end{split}\\]",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L06-lasso.html#exercises-1",
    "href": "activities/L06-lasso.html#exercises-1",
    "title": "LASSO: Shrinkage / Regularization",
    "section": "Exercises",
    "text": "Exercises\n\nExamining the impact of \\(\\lambda\\)\n\n\n\nSolution\n\n\nYep it matches.\n\n\n10^(-5)\n## [1] 1e-05\n10^(-0.1)\n## [1] 0.7943282\n\n\nCV MAE is large when \\(\\lambda\\) is either too small or too big.\n\n\n\n\nPicking a \\(\\lambda\\) value\n\n\n\nSolution\n\n\n\\(\\lambda\\) close to 0, specifically:\n\n\n# plot\nautoplot(lasso_models) + \n  scale_x_continuous() + \n  xlab(expression(lambda))\n\n\n\n\n\n\n\n\n# get \"best\" lambda\nbest_penalty &lt;- lasso_models %&gt;% \n  select_best(metric = \"mae\")\n\n# print out selected lambda\nbest_penalty\n## # A tibble: 1 √ó 2\n##   penalty .config         \n##     &lt;dbl&gt; &lt;chr&gt;           \n## 1  0.0126 pre0_mod32_post0\n\n\n\\(\\lambda\\) around 0.2\n\n\n# plot with error bars\nautoplot(lasso_models) + \n  scale_x_continuous() + \n  xlab(expression(lambda)) + \n  geom_errorbar(data = collect_metrics(lasso_models),\n                aes(x = penalty, ymin = mean - std_err, ymax = mean + std_err), \n                alpha = 0.5)\n\n\n\n\n\n\n\n\n# get \"parsimonious\" lambda\nparsimonious_penalty &lt;- lasso_models %&gt;% \n  select_by_one_std_err(metric = \"mae\", desc(penalty))\n\n# print out selected lambda\nparsimonious_penalty\n## # A tibble: 1 √ó 2\n##   penalty .config         \n##     &lt;dbl&gt; &lt;chr&gt;           \n## 1   0.200 pre0_mod44_post0\n\n\n\n0.2\n\n\n\n\nFinalizing our LASSO model\n\n\n\nSolution\n\n\n# fit final model with selected lambda (parameters = parsimonious_penalty)\n# note we are fitting to the entire dataset (data = humans)\nfinal_lasso &lt;- lasso_workflow %&gt;% \n  finalize_workflow(parameters = parsimonious_penalty) %&gt;% \n  fit(data = humans)\n\n# look at coefficient estimates\nfinal_lasso %&gt;% \n  tidy() %&gt;% \n  filter(estimate != 0) # optional: focus only on non-zero coefficient estimates\n## # A tibble: 6 √ó 3\n##   term        estimate penalty\n##   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n## 1 (Intercept)  63.8      0.200\n## 2 weight        0.0696   0.200\n## 3 abdomen      -0.126    0.200\n## 4 thigh        -0.0199   0.200\n## 5 knee          0.156    0.200\n## 6 ankle         0.0474   0.200\n\n\n5: weight, abdomen, thigh, knee, ankle\n3 of the predictors are the same (weight, abdomen, thigh). Interestingly, LASSO includes knee (which is the most highly correlated with height in this dataset) but the model chosen by the backward stepwise selection algorithm did not.\n\n\ncor(humans)[,'height'] %&gt;% sort()\n##        age    abdomen    forearm      thigh       neck      chest      wrist \n## -0.1469746  0.1120756  0.1303829  0.2059575  0.2382709  0.2399610  0.2451834 \n##     biceps        hip      ankle     weight       knee     height \n##  0.3173460  0.3470352  0.3628819  0.4440995  0.4441473  1.0000000\n\nIf you‚Äôre curious, here‚Äôs some code for implementing backward stepwise section:\n\n\nCode\n# setup\npredictors &lt;- c(\"age\", \"abdomen\", \"forearm\", \"thigh\", \"neck\", \"chest\", \"wrist\", \"biceps\", \"hip\", \"ankle\",  \"weight\",  \"knee\")\np &lt;- length(predictors)\nkick_out &lt;- rep(0, p)\ncvs &lt;- rep(0, p)\n\n# model spec\nlm_spec &lt;- linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# loop through predictors\nfor(i in 1:12){\n  # fit model\n  my_model &lt;- lm_spec %&gt;% \n    fit(as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))), \n        data = humans) %&gt;% \n    tidy() %&gt;% \n    filter(term != \"(Intercept)\") %&gt;% \n    arrange(desc(p.value))\n  \n  # use 10-fold CV to get MAE for model\n  set.seed(253)\n  cv_process &lt;- lm_spec %&gt;% \n      fit_resamples(\n        as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))),\n        resamples = vfold_cv(humans, v = 10), \n        metrics = metric_set(mae)\n      ) %&gt;% \n      collect_metrics()\n  \n  # get name of worst variable (biggest p-value)\n  worst &lt;- as.data.frame(my_model)[1,1]\n  kick_out[i] &lt;- worst\n  \n  # get rid of worst variable from predictor list\n  predictors &lt;- predictors[predictors != worst]\n  \n  # save CV MAE for this model\n  cvs[i] &lt;- as.data.frame(cv_process)$mean\n}\n\nkick_out # final 5 variables: chest, neck, thigh, abdomen, weight\n##  [1] \"ankle\"   \"wrist\"   \"forearm\" \"hip\"     \"knee\"    \"age\"     \"biceps\" \n##  [8] \"chest\"   \"neck\"    \"thigh\"   \"abdomen\" \"weight\"\ncvs # 5-variable model has MAE of 1.337\n##  [1] 1.806683 1.745948 1.661283 1.594183 1.568480 1.443465 1.342838 1.337059\n##  [9] 1.407843 1.490213 1.509317 1.930033\n\n\n\nWe‚Äôre using this model to give good predictions, not to explore / make inferences about relationships.\nThe remaining predictors are those that have good predictive power in this linear regression model (thus we get conclusions like a hypothesis test without doing a test). Also, our goal is to build a good predictive model, not to do inference.\n\n\n\n\n\nLASSO vs LASSO\n\n\n\nSolution\n\n\nThis would have 11 predictors.\n\n\nlasso_workflow %&gt;% \n  finalize_workflow(parameters = best_penalty) %&gt;% \n  fit(data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(estimate != 0) # add this line to print only non-zero coefficients\n## # A tibble: 12 √ó 3\n##    term        estimate penalty\n##    &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n##  1 (Intercept) 104.      0.0126\n##  2 age          -0.0208  0.0126\n##  3 weight        0.243   0.0126\n##  4 neck         -0.595   0.0126\n##  5 chest        -0.102   0.0126\n##  6 abdomen      -0.200   0.0126\n##  7 hip          -0.0491  0.0126\n##  8 thigh        -0.307   0.0126\n##  9 knee          0.180   0.0126\n## 10 biceps       -0.145   0.0126\n## 11 forearm      -0.0640  0.0126\n## 12 wrist        -0.0864  0.0126\n\n\nankle is not in this larger model but it is in the more parsimonious model. Therefore, the algorithm can‚Äôt be greedy. If it were greedy, then ankle would get removed for all smaller models.\n\n\n\n\n\nLASSO vs least squares\n\n\n\nSolution\n\n\n# Build the LS model\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# NOTE: we created variable_recipe above\n# here's what that looked like: \n## variable_recipe &lt;- recipe(height ~ ., data = humans) %&gt;% \n##   step_dummy(all_nominal_predictors())\n\nls_workflow &lt;- workflow() %&gt;%\n  add_model(lm_spec) %&gt;%\n  add_recipe(variable_recipe) \n\nls_model &lt;- ls_workflow %&gt;% \n  fit(data = humans) \n\n# examine coefficients\nls_model %&gt;% \n  tidy()\n## # A tibble: 13 √ó 5\n##    term        estimate std.error statistic     p.value\n##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n##  1 (Intercept) 110.       16.9       6.51   0.000000561\n##  2 age          -0.0234    0.0367   -0.637  0.529      \n##  3 weight        0.266     0.0573    4.64   0.0000810  \n##  4 neck         -0.671     0.335    -2.00   0.0556     \n##  5 chest        -0.119     0.131    -0.908  0.372      \n##  6 abdomen      -0.196     0.113    -1.73   0.0946     \n##  7 hip          -0.0978    0.189    -0.518  0.609      \n##  8 thigh        -0.313     0.163    -1.92   0.0661     \n##  9 knee          0.199     0.272     0.733  0.470      \n## 10 ankle        -0.0262    0.449    -0.0583 0.954      \n## 11 biceps       -0.168     0.200    -0.837  0.410      \n## 12 forearm      -0.0770    0.144    -0.536  0.596      \n## 13 wrist        -0.0962    0.647    -0.149  0.883\n\n# get 10-fold CV MAE\nset.seed(253)\nls_workflow %&gt;% \n  fit_resamples(\n    resamples = vfold_cv(humans,v = 10),\n    metrics = metric_set(mae)\n  ) %&gt;% \n  collect_metrics()\n## # A tibble: 1 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard    1.81    10   0.212 pre0_mod0_post0\n\n\nLASSO model is much simpler, and has only slightly worse predictions (on the scale of inches).\nThey‚Äôre very similar! Shrinking coefficients doesn‚Äôt mean our predictions are odd.\n\n\nnew_patient &lt;- data.frame(age = 50, weight = 200, neck = 40, chest = 115, abdomen = 105, hip = 100, thigh = 60, knee = 38, ankle = 23, biceps = 32, forearm = 29, wrist = 19) \n\n# LS prediction\nls_model %&gt;% \n  predict(new_data = new_patient)\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1  70.1\n\n# LASSO prediction\nfinal_lasso %&gt;% \n  predict(new_data = new_patient)\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1  70.3\n\n\nI‚Äôd choose LASSO since it seems to yield comparably accurate predictions but is much simpler than the full least squares model.\n\n\n\n\nVisualizing LASSO shrinkage.\n\n\n\nSolution\n\n\n# Get output for each LASSO model\nall_lassos &lt;- final_lasso %&gt;% \n  extract_fit_parsnip() %&gt;%\n  pluck(\"fit\")\n    \n# Plot coefficient paths as a function of lambda\nplot(all_lassos, xvar = \"lambda\", label = TRUE, col = rainbow(20))\n\n\n\n\n\n\n\n    \n# Codebook for which variables the numbers correspond to\nrownames(all_lassos$beta)\n##  [1] \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"     \"thigh\"  \n##  [8] \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"\n\nggplot version:\n\nlasso_coefs &lt;- all_lassos$beta  %&gt;% \n  as.matrix() %&gt;%  \n  t() %&gt;% \n  as.data.frame() %&gt;% \n  mutate(lambda = all_lassos$lambda ) %&gt;%\n  pivot_longer(cols = -lambda, \n               names_to = \"term\", \n               values_to = \"coef\")\n\nlasso_coefs %&gt;% filter(coef != 0, lambda &gt; 1)\n## # A tibble: 2 √ó 3\n##   lambda term      coef\n##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n## 1   1.01 weight 0.00228\n## 2   1.01 knee   0.0271\n\nlasso_coefs %&gt;%\n  ggplot(aes(x = lambda, y = coef, color = term)) +\n  geom_line() +\n  geom_text(data = lasso_coefs %&gt;% filter(lambda == min(lambda)), aes(x = 0.001, label = term), size = 2) + \n  scale_x_log10(limits = c(-2, 2)) +\n  guides(color = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nplot: examining specific predictors\n\n\n\nSolution\n\n\nthigh\nvery roughly -0.32\nroughly -3.5\n\nroughly -1.8\n\n\n\n\nplot: big picture\n\n\n\nSolution\n\n\ncoefficients are shrinking toward or to 0 as \\(\\lambda\\) increases (ie \\(-\\log(\\lambda)\\) decreases)\nweight (variable 2), knee (variable 8)\nlots of options here. look for the lines that drop to 0 sooner.\n11\n\n\n\n\nREVIEW: Model evaluation\n\n\n\nSolution\n\n\n# use augment to get predictions (.pred)\n# NOTE: we don't get the residuals (.resid) automatically\nfinal_lasso %&gt;% \n  augment(new_data = humans) %&gt;% \n  names()\n##  [1] \".pred\"   \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"    \n##  [8] \"thigh\"   \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"   \"height\"\n\n# Now calculate and plot the residuals\nfinal_lasso %&gt;% \n  augment(new_data = humans) %&gt;% \n  mutate(.resid = height - .pred) %&gt;% # resid = observed - predicted\n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point() + \n  geom_smooth() +\n  geom_hline(yintercept = 0) + \n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nDo you notice any concerning patterns?\n\n\n\nOPTIONAL: Practice on another dataset.\n\n\n\nSolution\n\nSolutions to this exercise are not provided. Stop by office hours to discuss!\n\n\n\nReflection.\n\n\n\nSolution\n\nSolutions to this exercise are not provided. Stop by office hours to discuss!",
    "crumbs": [
      "LASSO: Shrinkage / Regularization"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html",
    "href": "activities/L04-cross-validation.html",
    "title": "Cross-Validation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#context-evaluating-regression-models",
    "href": "activities/L04-cross-validation.html#context-evaluating-regression-models",
    "title": "Cross-Validation",
    "section": "Context: Evaluating Regression Models",
    "text": "Context: Evaluating Regression Models\nA reminder of our current context:\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) by some predictors \\(x\\).\ntask = regression\n\\(y\\) is quantitative\nmodel = linear regression model via least squares algorithm\nWe‚Äôll assume that the relationship between \\(y\\) and \\(x\\) can be represented by\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\varepsilon\\]\n\n\nGOAL: model evaluation\nWe want more honest metrics of prediction quality that\n\nassess how well our model predicts new outcomes; and\nhelp prevent overfitting.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#why-is-overfitting-so-bad",
    "href": "activities/L04-cross-validation.html#why-is-overfitting-so-bad",
    "title": "Cross-Validation",
    "section": "Why is overfitting so bad?",
    "text": "Why is overfitting so bad?\nNot only can overfitting produce misleading models, it can have serious societal impacts.\nExamples:\n\n\nFacial recognition algorithms are often overfit to the people who build them (who are not broadly representative of society). As one example, this has led to disproportionate bias in policing. For more on this topic, you might check out Coded Bias, a documentary by Shalini Kantayya which features MIT Media Lab researcher Joy Buolamwini.\nPolygenic risk scores (PRSs), which aim to predict a person‚Äôs risk of developing a particular disease/trait based on their genetics, are often overfit to the data on which they are built (which, historically, has exclusively‚Äîor at least primarily‚Äîincluded individuals of European ancestry). As a result, PRS predictions tend to be more accurate in European populations and new research suggests that their continued use in clinical settings could exacerbate health disparities.\nThere are connections to overfitting in the article for the ethics reflection on HW1 (about a former Amazon recruiting algorithm.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#k-fold-cross-validation",
    "href": "activities/L04-cross-validation.html#k-fold-cross-validation",
    "title": "Cross-Validation",
    "section": "k-Fold Cross Validation",
    "text": "k-Fold Cross Validation\nWe can use k-fold cross-validation to estimate the typical error in our model predictions for new data:\n\n\nDivide the data into \\(k\\) folds (or groups) of approximately equal size.\n\nRepeat the following procedures for each fold \\(j = 1,2,...,k\\):\n\nRemove fold \\(j\\) from the data set.\n\nFit a model using the data in the other \\(k-1\\) folds (training).\n\nUse this model to predict the responses for the \\(n_j\\) cases in fold \\(j\\): \\(\\hat{y}_1, ..., \\hat{y}_{n_j}\\).\n\nCalculate the MAE for fold \\(j\\) (testing): \\(\\text{MAE}_j = \\frac{1}{n_j}\\sum_{i=1}^{n_j} |y_i - \\hat{y}_i|\\).\n\nCombine this information into one measure of model quality: \\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^k \\text{MAE}_j\\]",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#definitions",
    "href": "activities/L04-cross-validation.html#definitions",
    "title": "Cross-Validation",
    "section": "Definitions",
    "text": "Definitions\n\nalgorithm = a step-by-step procedure for solving a problem (Merriam-Webster)\ntuning parameter = a parameter or quantity upon which an algorithm depends, that must be selected or tuned to ‚Äúoptimize‚Äù the algorithm\n\n1",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#prompts",
    "href": "activities/L04-cross-validation.html#prompts",
    "title": "Cross-Validation",
    "section": "Prompts",
    "text": "Prompts\n\nSynchronize as a Team!\n\n\n\nConceptual check\n\n\nWhy is \\(k\\)-fold cross-validation an algorithm?\n\n\nIt follows a list of steps to get to its goal.\n\n\nWhat is the tuning parameter of this algorithm and what values can this take?\n\n\n\\(k\\), the number of folds, is a tuning parameter. \\(k\\) can be any integer from 2, ‚Ä¶, \\(n\\) where \\(n\\) is our sample size.\n\nSPECIAL CASE: Leave One Out Cross-Validation (LOOCV).\nLOOCV is a special case of k-fold cross-validation in which, in each iteration, we hold out one data point as a test case and use the other \\(n-1\\) data points for training. Thus LOOCV is equivalent to \\(k = n\\) fold CV.\nIn pictures: In the end, we fit \\(n\\) training models (blue lines) and test each on one test car (red dots).\n\n## Error in sample_n(., size = 20, replace = FALSE): could not find function \"sample_n\"\n## Error: object 'cars_rep' not found\n## Error in mutate(., replicate = as.factor(replicate)): could not find function \"mutate\"\n## Error: object 'cars_rep' not found\n## Error: object 'cars_rep' not found\n\n\n## Error in ggplot(train_sets, aes(x = horsepower, y = mpg)): could not find function \"ggplot\"\n\n\nHow is 2-fold cross-validation (CV) different from validation? (Validation is what we did last class: splitting our sample into a training dataset and a testing dataset.)\n\n\nWe use both groups as training and testing, in turn.\n\n\nWhy might 3-fold CV be better than 2-fold CV?\n\n\nWe have a larger dataset to train our model on. We are less likely to get an unrepresentative set as our training data. We are also averaging our overall cross-validated MAE estimate over more testing folds, which is likely to result in a more stable estimate of out-of-sample error.\n\n\nWhy might LOOCV (leave-one-out CV) (k-fold CV where k = sample size) be worse than 3-fold cross-validation?\n\n\nPrediction error for 1 person is highly variable. Also, for computational time reasons, fitting models can be very slow.\n\n\nIn practice, \\(k = 10\\) and \\(k=7\\) are common choices for cross-validation. This has been shown to hit the ‚Äòsweet spot‚Äô between the extremes of \\(k=n\\) (LOOCV) and \\(k=2\\).\n\n\n\\(k=2\\) only utilizes 50% of the data for each training model, thus might result in overestimating the prediction error\n\\(k=n\\) leave-one-out cross-validation (LOOCV) requires us to build \\(n\\) training models, thus might be computationally expensive for larger sample sizes \\(n\\). Further, with only one data point in each test set, the training sets have a lot of overlap. This correlation among the training sets can make the ultimate corresponding estimate of prediction error less reliable.\n\n\n\nR Code Preview\n\nWe‚Äôve been doing a 2-step process to build linear regression models using the tidymodels package:\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n  \n# STEP 2: model estimation\nmy_model &lt;- lm_spec %&gt;% \n  fit(\n    y ~ x1 + x2,\n    data = sample_data\n  )\n\nFor k-fold cross-validation, we can tweak STEP 2. Discuss the code below:\n\nWhat‚Äôs similar? What‚Äôs different? &gt; Similar to fit(), we tell the function fit_resamples what model to fit and which data to use. But, instead of fitting that model once to the full data, we use CV.\nWhat do you think each new, or otherwise modified, line does?\nWhy do we need set.seed?\n\n\nset.seed(___) # set seed for reproducibility\n\nmy_model_cv &lt;- lm_spec %&gt;% # take the model specs we defined earlier, and then\n  \n  fit_resamples( # fit multiple models (across multiple resamples of the data)\n    \n    y ~ x1 + x2, # the model we want to fit\n    \n    resamples = vfold_cv(sample_data, v = ___), # use \"v\"-fold CV to create the resamples (fill in the blank to specify \"v\", aka \"k\")\n    \n    metrics = metric_set(mae, rsq) # specify which evaluation metric(s) (MAE, R^2) to use \n    \n  )\n\nHere are a few general tips for breaking down complex code:\n\nRead the R Documentation / help page for any new functions (eg type ?fit_resamples into the Console)\nTry removing or otherwise modifying each line of code and see what happens!\n\nWhy set a seed? The process of creating the folds is random, so we should set the seed to have reproducibility within our work.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#instructions",
    "href": "activities/L04-cross-validation.html#instructions",
    "title": "Cross-Validation",
    "section": "Instructions",
    "text": "Instructions\n\n\nGo to the Course Schedule and find the QMD template for today\n\nSave this in your STAT 253 Notes folder, NOT your downloads!\n\nWork through the exercises implementing CV to compare two possible models predicting height\nSame directions as before:\n\nBe kind to yourself/each other\nCollaborate\nDON‚ÄôT edit starter code (i.e., code with blanks ___). Instead, copy-paste into a new code chunk below and edit from there.\n\nAsk me questions as I move around the room",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#questions",
    "href": "activities/L04-cross-validation.html#questions",
    "title": "Cross-Validation",
    "section": "Questions",
    "text": "Questions\n\n# Load packages and data\nlibrary(tidyverse)\nlibrary(tidymodels)\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat50.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\n\nReview: In-sample metrics- As Group\n\nUse the humans data to build two separate models of height:\n\n# STEP 1: model specification\nlm_spec &lt;- ___() %&gt;% \n  set_mode(___) %&gt;% \n  set_engine(___)\n\n\n# STEP 2: model estimation\nmodel_1 &lt;- ___ %&gt;% \n  ___(height ~ hip + weight + thigh + knee + ankle, data = humans)\nmodel_2 &lt;- ___ %&gt;% \n  ___(height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\nCalculate the in-sample R-squared for both models:\n\n# IN-SAMPLE R^2 for model_1 = ???\nmodel_1 %&gt;% \n  ___()\n\n\n# IN-SAMPLE R^2 for model_2 = ???\nmodel_2 %&gt;% \n  ___()\n\nCalculate the in-sample MAE for both models:\n\n# IN-SAMPLE MAE for model_1 = ???\nmodel_1 %&gt;% \n  ___(new_data = ___) %&gt;% \n  mae(truth = ___, estimate = ___)\n\n\n# IN-SAMPLE MAE for model_2 = ???\nmodel_2 %&gt;% \n  ___(new_data = ___) %&gt;% \n  mae(truth = ___, estimate = ___)\n\n\n\n\nIn-sample model comparison - As Group\n\nWhich model seems ‚Äúbetter‚Äù by the in-sample metrics you calculated above? Any concerns about either of these models?\n\nType your answer\n\n\n\n\n10-fold CV - As Group\n\nComplete the code to run 10-fold cross-validation for our two models.\nModel 1: height ~ hip + weight + thigh + knee + ankle\nModel 2: height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist\n\n# 10-fold cross-validation for model_1\nset.seed(253)\nmodel_1_cv &lt;- ___ %&gt;% \n  ___(\n    ___,\n    ___ = vfold_cv(___, v = ___), \n    ___ = metric_set(mae, rsq)\n  )\n\n\n# 10-fold cross-validation for model_2\nset.seed(253)\nmodel_2_cv &lt;- ___ %&gt;% \n  ___(\n    ___,\n    ___ = vfold_cv(___, v = ___), \n    ___ = metric_set(mae, rsq)\n  )\n\n\n\n\nCalculating the CV MAE - As Group\n\n\nUse collect_metrics() to obtain the cross-validated MAE and \\(R^2\\) for both models.\n\n\n# HINT\n___ %&gt;% \n  collect_metrics()\n\n\nInterpret the cross-validated MAE and \\(R^2\\) for model_1.\n\n\n\n\nDetails: fold-by-fold results - As Group\n\nThe collect_metrics() function gave the final CV MAE, or the average MAE across all 10 test folds. If you want the MAE from each test fold, try unnest(.metrics).\n\nObtain the fold-by-fold results for the model_1 cross-validation procedure using unnest(.metrics).\n\n\n# HINT\n___ %&gt;% \n  unnest(.metrics)\n\n\nWhich fold had the worst average prediction error and what was it?\nRecall that collect_metrics() reported a final CV MAE of 1.87 for model_1. Confirm this calculation by wrangling the fold-by-fold results from part a.\n\n\n\n\nComparing models - As Team\n\nThe table below summarizes the in-sample and 10-fold CV MAE for both models.\n\n\n\nModel\nIN-SAMPLE MAE\n10-fold CV MAE\n\n\n\n\nmodel_1\n1.55\n1.87\n\n\nmodel_2\n0.64\n2.47\n\n\n\n\nBased on the in-sample MAE alone, which model appears better?\n\n\nmodel_2\n\n\nBased on the CV MAE alone, which model appears better?\n\n\nmodel_1\n\n\nBased on all of these results, which model would you pick?\n\n\nmodel_1 ‚Äì model_2 produces bad predictions for new adults\n\n\nDo the in-sample and CV MAE suggest that model_1 is overfit to our humans sample data? What about model_2? Why/why not?\n\n\nmodel_1 is NOT overfit ‚Äì its predictions of height for new adults seem roughly as accurate as the predictions for the adults in our sample. model_2 IS overfit ‚Äì its predictions of height for new adults are worse than the predictions for the adults in our sample.\n\n\n\n\nLOOCV- As Team\n\nNo code to implement for this exercise‚Äìjust answer the following conceptually.\n\nHow could we adapt the code in Exercise 3 to use LOOCV MAE instead of the 10-fold CV MAE?\n\nThere are 39 people in our sample, thus LOOCV is equivalent to 39-fold CV:\n\nnrow(humans)\nmodel_1_loocv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ hip + weight + thigh + knee + ankle,\n    resamples = vfold_cv(humans, v = nrow(humans)), # this will throw an error and tell you to use loo_cv() instead\n    metrics = metric_set(mae)\n  )\n    \nmodel_1_loocv %&gt;% \n  collect_metrics()\n\n\nWhy do we technically not need to set.seed() for the LOOCV algorithm?\n\n\nThere‚Äôs no randomness in the test folds. Each test fold is a single person.\n\n\n\n\nAdditional Exercise: Data drill\n\n\nCalculate the average height of people under 40 years old vs people 40+ years old.\n\n\nPlot height vs age among our subjects that are 30+ years old.\n\n\nFix this code:\n\n\nmodel_3&lt;-lm_spec%&gt;%fit(height~age,data=humans)\nmodel_3%&gt;%tidy()\n\n\n\n\nReflection: Part 1\n\nThe ‚Äúregular‚Äù exercises are over, but class is not done! Your group should agree to either work on HW1 or the remaining reflection questions.\nThis is the end of Unit 1 on ‚ÄúRegression: Model Evaluation‚Äù! Let‚Äôs reflect on the technical content of this unit:\n\nWhat was the main motivation / goal behind this unit?\nWhat are the four main questions that were important to this unit?\nFor each of the following tools, describe how they work and what questions they help us address:\n\nR-squared\nresidual plots\nout-of-sample MAE\nin-sample MAE\nvalidation\ncross-validation\n\nIn your own words, define the following:\n\noverfitting\nalgorithm\ntuning parameter\n\nReview the new tidymodels syntax from this unit. Identify key themes and patterns.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#todays-material",
    "href": "activities/L04-cross-validation.html#todays-material",
    "title": "Cross-Validation",
    "section": "Today‚Äôs Material",
    "text": "Today‚Äôs Material\n\nIf you didn‚Äôt finish the exercises, no problem! Be sure to complete them outside of class, review the solutions on the course site, and ask any outstanding questions on Discussion board on Moodle or in office hours.\nThis is the end of Unit 1, so there are reflection questions at the end of the exercises to help you organize the concepts in your mind. This is a good time to pause, review the material we‚Äôve covered so far, and stop by office hours with any questions!\nAn R tutorial video, talking through the new code, is posted on class schedule.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#upcoming-deadlines",
    "href": "activities/L04-cross-validation.html#upcoming-deadlines",
    "title": "Cross-Validation",
    "section": "Upcoming Deadlines",
    "text": "Upcoming Deadlines\n\nCP4:\n\ndue 10 minutes before our next class\n\nHW1:\n\ndue Sunday, 02/08 at 11:59 pm\nyou have everything you need to finish this assignment after today‚Äôs class!\nreview the homework and late work/extension policies on Syllabus: deadline is so we can get timely feedback to you; three 3-day extensions to acknowledge ‚Äúlife happens‚Äù.",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#exercises-1",
    "href": "activities/L04-cross-validation.html#exercises-1",
    "title": "Cross-Validation",
    "section": "Exercises",
    "text": "Exercises\n\nReview: In-sample metrics\n\n\n\nSolution\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight + thigh + knee + ankle, data = humans)\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\n# IN-SAMPLE R^2 for model_1 = 0.40\nmodel_1 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.401         0.310  1.98      4.42 0.00345     5  -78.8  172.  183.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# IN-SAMPLE R^2 for model_2 = 0.87\nmodel_2 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.874         0.680  1.35      4.51 0.00205    23  -48.4  147.  188.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# IN-SAMPLE MAE for model_1 = 1.55\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.55\n\n# IN-SAMPLE MAE for model_2 = 0.64\nmodel_2 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard       0.646\n\n\n\n\nIn-sample model comparison\n\n\n\nSolution\n\nThe in-sample metrics are better for model_2, but from experience in our previous class, we should expect this to be overfit.\n\n\n\n10-fold CV\n\n\n\nSolution\n\n\n# 10-fold cross-validation for model_1\nset.seed(253)\nmodel_1_cv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ hip + weight + thigh + knee + ankle,\n    resamples = vfold_cv(humans, v = 10), \n    metrics = metric_set(mae, rsq)\n  )\n\n# STEP 2: 10-fold cross-validation for model_2\nset.seed(253)\nmodel_2_cv &lt;- lm_spec %&gt;% \n  fit_resamples(\n    height ~ chest * age * weight * body_fat + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n    resamples = vfold_cv(humans, v = 10), \n    metrics = metric_set(mae, rsq)\n  )\n\n\n\n\nCalculating the CV MAE\n\n\n\nSolution\n\n\n\n\n\n# model_1\n# CV MAE = 1.87, CV R-squared = 0.41\nmodel_1_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   1.87     10   0.159 pre0_mod0_post0\n## 2 rsq     standard   0.409    10   0.124 pre0_mod0_post0\n\n# model_2\n# CV MAE = 2.47, CV R-squared = 0.53\nmodel_2_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 √ó 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   2.47     10   0.396 pre0_mod0_post0\n## 2 rsq     standard   0.526    10   0.122 pre0_mod0_post0\n\n\nWe expect our first model to explain roughly 40% of variability in height among new adults, and to produce predictions of height (for new adults) that are off by 1.9 inches on average.\n\n\n\n\nDetails: fold-by-fold results\n\n\n\nSolution\n\n\n# a. model_1 MAE for each test fold\nmodel_1_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\")\n## # A tibble: 10 √ó 7\n##    splits         id     .metric .estimator .estimate .config         .notes  \n##    &lt;list&gt;         &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;           &lt;list&gt;  \n##  1 &lt;split [35/4]&gt; Fold01 mae     standard        2.22 pre0_mod0_post0 &lt;tibble&gt;\n##  2 &lt;split [35/4]&gt; Fold02 mae     standard        2.34 pre0_mod0_post0 &lt;tibble&gt;\n##  3 &lt;split [35/4]&gt; Fold03 mae     standard        2.56 pre0_mod0_post0 &lt;tibble&gt;\n##  4 &lt;split [35/4]&gt; Fold04 mae     standard        1.51 pre0_mod0_post0 &lt;tibble&gt;\n##  5 &lt;split [35/4]&gt; Fold05 mae     standard        1.81 pre0_mod0_post0 &lt;tibble&gt;\n##  6 &lt;split [35/4]&gt; Fold06 mae     standard        2.43 pre0_mod0_post0 &lt;tibble&gt;\n##  7 &lt;split [35/4]&gt; Fold07 mae     standard        1.61 pre0_mod0_post0 &lt;tibble&gt;\n##  8 &lt;split [35/4]&gt; Fold08 mae     standard        1.84 pre0_mod0_post0 &lt;tibble&gt;\n##  9 &lt;split [35/4]&gt; Fold09 mae     standard        1.28 pre0_mod0_post0 &lt;tibble&gt;\n## 10 &lt;split [36/3]&gt; Fold10 mae     standard        1.10 pre0_mod0_post0 &lt;tibble&gt;\n\n# b. fold 3 had the worst error (2.56)\n\n# c. use these metrics to confirm the 1.87 CV MAE for model_1\nmodel_1_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\") %&gt;% \n  summarize(mean(.estimate))\n## # A tibble: 1 √ó 1\n##   `mean(.estimate)`\n##               &lt;dbl&gt;\n## 1              1.87\n\n\n\n\nComparing models\n\n\n\nSolution\n\n\nmodel_2\nmodel_1\nmodel_1 ‚Äì model_2 produces bad predictions for new adults\nmodel_1 is NOT overfit ‚Äì its predictions of height for new adults seem roughly as accurate as the predictions for the adults in our sample. model_2 IS overfit ‚Äì its predictions of height for new adults are worse than the predictions for the adults in our sample.\n\n\n\n\nData drill\n\n\n\nSolution\n\n\n# a (one of many solutions)\nhumans %&gt;% \n  mutate(younger_older = age &lt; 40) %&gt;% \n  group_by(younger_older) %&gt;% \n  summarize(mean(height))\n## # A tibble: 2 √ó 2\n##   younger_older `mean(height)`\n##   &lt;lgl&gt;                  &lt;dbl&gt;\n## 1 FALSE                   70.4\n## 2 TRUE                    69.8\n\n# b\nhumans %&gt;% \n  filter(age &gt;= 30) %&gt;% \n  ggplot(aes(x = age, y = height)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# c\nmodel_3 &lt;- lm_spec %&gt;%\n  fit(height ~ age, data = humans)\nmodel_3 %&gt;%\n  tidy()\n## # A tibble: 2 √ó 5\n##   term        estimate std.error statistic  p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)  71.1       1.63      43.7   1.96e-33\n## 2 age          -0.0210    0.0363    -0.577 5.67e- 1",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L04-cross-validation.html#footnotes",
    "href": "activities/L04-cross-validation.html#footnotes",
    "title": "Cross-Validation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.wallpaperflare.com/grayscale-photography-of-guitar-headstock-music-low-electric-bass-wallpaper-zzbyn‚Ü©Ô∏é",
    "crumbs": [
      "Cross-Validation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html",
    "href": "activities/L02-evaluating-regression-models.html",
    "title": "Model Evaluation",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#instructions",
    "href": "activities/L02-evaluating-regression-models.html#instructions",
    "title": "Model Evaluation",
    "section": "Instructions",
    "text": "Instructions\n\nIn small groups, please first introduce yourself (in whatever way you feel appropriate) and check in with each other as human beings.\nWhen everyone is ready, glance through the summary of concepts covered in the video (see ‚ÄúVideo Recap‚Äù below) and discuss the following prompts:\n\nWhat vocabulary or notation was new to you?\nWhat concepts were new to you?\nWhat concepts are still unclear to you at this moment?\n\nPrepare to share a few highlights from your group discussion with the entire class",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#video-recap",
    "href": "activities/L02-evaluating-regression-models.html#video-recap",
    "title": "Model Evaluation",
    "section": "Video Recap",
    "text": "Video Recap\n\nWe are in the regression setting. We want to build a model of some quantitative output variable \\(y\\) by some predictors \\(x\\):\n\\[y = f(x) + \\varepsilon\\]\nThere are many regression tools that we might use to build this model. We‚Äôll use a linear regression model which assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs:\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots \\beta_p x_p + \\varepsilon\\]\nAfter building any model, it‚Äôs important to evaluate it: Is our regression model a ‚Äúgood‚Äù model?\n\nIs the model wrong?\n\nIs the model strong?\n\nDoes the model produce accurate predictions?\n\nIs the model fair?\n\nWe will review these concepts through today‚Äôs exercises. A detailed overview is provided in the Unit 1 ‚ÄúMotivating Question‚Äù section on the course website.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#intro-to-tidymodels",
    "href": "activities/L02-evaluating-regression-models.html#intro-to-tidymodels",
    "title": "Model Evaluation",
    "section": "Intro to tidymodels",
    "text": "Intro to tidymodels\nThroughout the semester, we are going to use the tidymodels package in R.\n\nSimilar flavor to tidyverse structure\nMore general structure that allows us to fit many other types of models\n\n\n\nAt first, it will seem like a lot more code (perhaps even unnecessarily so).\n\n\nFor example, what you did in STAT 155 with\n\nlm(y ~ x1 + x2, data = sample_data)\n\nwill now look like\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\")# we'll estimate the model using the lm function\n\n# STEP 2: model estimation\nmodel_estimate &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = sample_data)\n\n\n\nFor now, you‚Äôll need to trust me that this will be end up being useful. (It will be!)\n\n\nLet‚Äôs take a look at some code that we‚Äôll use to build future models. Compare the model specification code above to the examples below.\n\nWhat similarities and differences do you notice?\nWhy might the designers of tidymodels have chosen to design the code this way?\n\n\n# Specification for a LASSO model\nlasso_spec &lt;- linear_reg() %&gt;%             \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"glmnet\")\n\n# Specification for a k-nearest neighbors model\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(engine = \"kknn\")\n\n# Specification for a logistic regression model\nlogistic_spec &lt;- logistic_reg() %&gt;%\n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\")",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#quick-highlight",
    "href": "activities/L02-evaluating-regression-models.html#quick-highlight",
    "title": "Model Evaluation",
    "section": "Quick Highlight",
    "text": "Quick Highlight\nA few useful functions to use on model_estimate:\n\nmodel_estimate %&gt;% \n  tidy() #gives you coefficients (and se, t-statistics)\n\n\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) # gives you predictions and residuals for sample_data\n\n\nmodel_estimate %&gt;% \n  glance() #gives you some model evaluation metrics (is it strong?)\n\n\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% # get predictions, and then...\n  mae(truth = y, estimate = .pred) # calculate MAE to measure accuracy of predictions\n\nMore info, for future reference, below!",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#future-reference",
    "href": "activities/L02-evaluating-regression-models.html#future-reference",
    "title": "Model Evaluation",
    "section": "Future Reference",
    "text": "Future Reference\n\n\n\n\n\n\nNote\n\n\n\nThis section is for future reference. It is a summary of code you‚Äôll learn below for building and evaluating regression models. You do not need to (and in fact should not) run the code in this section verbatim in R; it is example code and meant for future reference only.\n\n\nBuilding and evaluating regression models using tidymodels.\nThroughout, suppose we wish to build and evaluate a linear regression model of y vs x1 and x2 using a dataset called sample_data.\nYou‚Äôll need both of these packages:\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nBuilding a linear regression model\n\n# STEP 1: specify the type of model to build\nlm_spec &lt;- linear_reg() %&gt;% # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\") # we'll estimate the model using the lm function\n\n# STEP 2: estimate the specified model using sample data\nmodel_estimate &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = sample_data)\n\n# Get the model coefficients\nmodel_estimate %&gt;% \n  tidy()\n\nObtaining predictions (& residuals) for each observation\n\n# Obtain y predictions and residuals for each observation in our sample_data\n# (We can replace sample_data with any data frame that includes y, x1, and x2)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data)\n\n# Obtain y predictions (but not residuals) for some given x1, x2 values, when we haven't yet observed y\n# (We can replace the data.frame with any data frame that includes x1 and x2)\nmodel_estimate %&gt;% \n  augment(new_data = data.frame(x1 = ___, x2 = ___))\n  \n# Another approach using predict()\nmodel_estimate %&gt;% \n  predict(new_data = data.frame(x1 = ___, x2 = ___))\n\nEvaluating the model\n\n# Is it strong? (R^2)\nmodel_estimate %&gt;% \n  glance()\n\n# Does it produce accurate predictions? (MAE)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% \n  mae(truth = y, estimate = .pred)\n\n# Is it wrong? (residual plot)\nmodel_estimate %&gt;% \n  augment(new_data = sample_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0) + \n  geom_smooth()",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#instructions-1",
    "href": "activities/L02-evaluating-regression-models.html#instructions-1",
    "title": "Model Evaluation",
    "section": "Instructions",
    "text": "Instructions\n\n\nWork through these exercises as a group, talking through your ideas, questions, and reasoning as you go and taking notes in your QMD.\nFocus on patterns in code. Review, but do not try to memorize any provided code. Focus on the general steps and patterns.\nIf you‚Äôre given some starter code with blanks (e.g.¬†below), don‚Äôt type in those chunks. Instead, copy, paste, and modify the starter code in the chunk below it.\n\n\n# Start small: rides vs temp\nggplot(___, aes(y = ___, x = ___)) + \n  geom___()\n\n\nAsk questions! We will not have time to discuss all exercises at the end of class. Talk through your questions as a group, and ask me questions as I walk around the room!\nBe kind to yourself/each other! You will be rusty and make mistakes, and that‚Äôs ok! Mistakes are important to learning.\n\nIf you‚Äôre feeling rusty on STAT 155 material, in particular, check out the STAT 155 Review Appendix on our course website or the links at the top of the notes for today.\n\nCollaborate. We‚Äôre sitting in groups for a reason. Collaboration improves higher-level thinking, confidence, communication, community, and more. I expect you to:\n\nActively contribute to discussion (don‚Äôt work on your own).\nActively include all group members in discussion.\nCreate a space where others feel comfortable making mistakes & sharing their ideas (remember that we all come to this class with different experiences, both personal and academic).\nStay in sync while respecting that everybody has different learning strategies, work styles, note taking strategies, etc. If some people are working on exercise 10 and others are on exercise 2, that‚Äôs probably not a good collaboration.\nDon‚Äôt rush. You won‚Äôt hand anything in and can finish up outside of class.",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#questions",
    "href": "activities/L02-evaluating-regression-models.html#questions",
    "title": "Model Evaluation",
    "section": "Questions",
    "text": "Questions\nCapital Bikeshare provides a bike-sharing service in the Washington DC area. Customers can pick up and drop off bikes at any station around the city. Of primary interest to the company is:\nHow many registered riders can we expect today?\nTo this end, you will build, evaluate, and compare 2 different linear regression models of ridership using the following Capital Bikeshare dataset (originally from the UCI Machine Learning Repository):\n\nModel 1: rides ~ windspeed + temp\nModel 2: rides ~ windspeed + temp + weekend\n\n\n\n\n\nExplore the data\n\nTake a minute to get familiar with the data.\n\n# Load packages we'll need to wrangle and plot the data\nlibrary(tidyverse)\n\n# Load the data\nbikes &lt;- read.csv(\"https://Mac-Stat.github.io/data/bike_share.csv\")\n\n# Only keep / select some variables\n# And round some variables (just for our demo purposes)\nbikes &lt;- bikes %&gt;% \n  rename(rides = riders_registered, temp = temp_feel) %&gt;% \n  mutate(windspeed = round(windspeed), temp = round(temp)) %&gt;% \n  select(rides, windspeed, temp, weekend)\n\n\n# Check out the dimensions\ndim(bikes)\n## [1] 731   4\n\n# Check out the first 3 rows\nhead(bikes, 3)\n##   rides windspeed temp weekend\n## 1   654        11   65    TRUE\n## 2   670        17   64    TRUE\n## 3  1229        17   49   FALSE\n\nThis dataset contains the following information for a sample of different dates:\n\n\n\nvariable\ndescription\n\n\n\n\nrides\ncount of daily rides by registered users\n\n\nwindspeed\nwind speed in miles per hour\n\n\ntemp\nwhat the temperature feels like in degrees Fahrenheit\n\n\nweekend\nwhether or not it falls on a weekend\n\n\n\n\n\n\n\nPlot the relationships\n\nFirst, let‚Äôs plot these relationships.\nREMEMBER: Don‚Äôt write in any chunk with starter code. Copy, paste, and modify the code in the chunk below it.\n\n# Start small: rides vs temp\nggplot(___, aes(y = ___, x = ___)) + \n  geom___()\n\n\n# Start small: rides vs temp\n# Start small: rides vs temp\n\n\n# rides vs temp & windspeed\nggplot(bikes, aes(y = ___, x = ___, ___ = windspeed)) + \n  geom_point()\n\n\n# rides vs temp & windspeed & weekend\nggplot(bikes, aes(y = ___, x = ___, ___ = windspeed)) + \n  geom_point() +  \n  facet_wrap(~ ___)\n\n\n\n\n\ntidymodels STEP 1\n\nWe‚Äôll build and evaluate our two models of ridership using the tidymodels package. This code is more complicated than the lm() function we used in STAT 155. BUT:\n\ntidymodels is part of the broader tidyverse (what we use to plot and wrangle data), thus the syntax is more consistent\ntidymodels generalizes to the other ML algorithms we‚Äôll survey in this course, thus will eventually minimize the unique syntax we need to learn\n\n\n# Load package\nlibrary(tidymodels)\n\nThe first step is to specify what type of model we want to build. We‚Äôll store this as lm_spec, our linear regression model (lm) specification (spec).\n\nlm_spec &lt;- linear_reg() %&gt;%   # we want a linear regression model\n  set_mode(\"regression\") %&gt;%  # this is a regression task (y is quantitative)\n  set_engine(\"lm\")            # we'll estimate the model using the lm function\n\nThis code specifies but doesn‚Äôt build any model ‚Äì we didn‚Äôt even give it any data or specify the variables of interest!\n\n# Check it out\nlm_spec\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\n\n\n\n\ntidymodels STEP 2\n\nWe can now estimate or fit our two ridership models using the specified model structure (lm_spec) and our sample bikes data:\n\n# Fit bike_model_1\nbike_model_1 &lt;- lm_spec %&gt;% \n  fit(rides ~ windspeed + temp, data = bikes)\n\n# Check out the coefficients\nbike_model_1 %&gt;% \n  tidy()\n## # A tibble: 3 √ó 5\n##   term        estimate std.error statistic  p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)    -20.8    300.     -0.0694 9.45e- 1\n## 2 windspeed      -36.1      9.42   -3.83   1.37e- 4\n## 3 temp            55.4      3.33   16.6    7.58e-53\n\n\n# YOUR TURN\n# Fit bike_model_2 & check out the coefficients\n\n\n\n\n\nIs it fair?\n\nNow, let‚Äôs evaluate our two models. First, do you have any concerns about the context in which the data were collected and analyzed? About the potential impact of this analysis?\n\n\n\n\nIs it strong?\n\nWe can measure and compare the strength of these models using \\(R^2\\), the proportion of variability in our response variable that‚Äôs explained by the model. Report which model is stronger and interpret its \\(R^2\\).\n\n# Obtain R^2 for bike_model_1\nbike_model_1 %&gt;% \n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic  p.value    df logLik    AIC    BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1     0.310         0.308 1298.      163. 2.44e-59     2 -6276. 12560. 12578.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n# YOUR TURN\n# Obtain R^2 for bike_model_2\n\n\n\n\n\nPause ‚Äì predictions and residuals\n\nOur next model evaluation questions will focus on the models‚Äô predictions and prediction errors, or residuals. We can obtain this information by augmenting our models with our original bikes data. For example:\n\n# Calculate predicted ridership (.pred) & corresponding residuals (.resid) using bike_model_1\n# Just look at first 6 days\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  head()\n## # A tibble: 6 √ó 6\n##   .pred .resid rides windspeed  temp weekend\n##   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n## 1 3183. -2529.   654        11    65 TRUE   \n## 2 2911. -2241.   670        17    64 TRUE   \n## 3 2080.  -851.  1229        17    49 FALSE  \n## 4 2407.  -953.  1454        11    51 FALSE  \n## 5 2446.  -928.  1518        13    53 FALSE  \n## 6 2699. -1181.  1518         6    53 FALSE\n\nWe can also predict outcomes for new observations using either augment() or predict(). Note the difference in the output:\n\n# Predict ridership on a 60 degree day with 20 mph winds\nbike_model_1 %&gt;% \n  augment(new_data = data.frame(windspeed = 20, temp = 60))\n## # A tibble: 1 √ó 3\n##   .pred windspeed  temp\n##   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n## 1 2581.        20    60\n\n\n# Predict ridership on a 60 degree day with 20 mph winds\nbike_model_1 %&gt;% \n  predict(new_data = data.frame(windspeed = 20, temp = 60))\n## # A tibble: 1 √ó 1\n##   .pred\n##   &lt;dbl&gt;\n## 1 2581.\n\n\n\n\n\nDoes it produce accurate predictions?\n\nRecall that the mean absolute error (MAE) measures the typical prediction error. Specifically, it is the mean of the absolute values of the residual errors for the days in our dataset.\n\nUse the residuals to calculate the MAE for the 2 models. HINT: abs()\n\n\n# DON'T TYPE IN THIS CHUNK\n# MAE for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  summarize(mae = ___(___(___)))\n\n\n# MAE for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  summarize(mae = mean(abs(.resid)))\n## # A tibble: 1 √ó 1\n##     mae\n##   &lt;dbl&gt;\n## 1 1080.\n\n\n# YOUR TURN: MAE for bike_model_2\n\n\nDoing the calculation from scratch helps solidify your understanding of how MAE is calculated, thus interpreted. Check your calculations using a shortcut function.\n\n\n# Calculate MAE for the first model\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  mae(truth = rides, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard       1080.\n\n\n# YOUR TURN\n# Calculate MAE for the second model\n\n\nWhich model has more accurate predictions?\nInterpret the MAE for this model, in context, and comment on whether it‚Äôs ‚Äúlarge‚Äù or ‚Äúsmall‚Äù. NOTE: ‚Äúlarge‚Äù or ‚Äúsmall‚Äù is defined by the context (e.g.¬†relative to the observed range of ridership, the consequences of a bad prediction, etc).\n\n\n\n\n\nIs it wrong?\n\nTo determine whether the linear regression assumptions behind bike_model_1 and bike_model_2 are reasonable, we can review residual plots, i.e.¬†plots of the residuals vs predictions for each observation in our dataset. Run the code below and summarize your assessment of whether our models are wrong. RECALL: We want the points to appear random and centered around 0 across the entire range of the model / predictions.\n\n# Residual plot for bike_model_1\nbike_model_1 %&gt;% \n  augment(new_data = bikes) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) + \n    geom_smooth() # add trend line\n\n\n\n\n\n\n\n\n\n# YOUR TURN\n# Residual plot for bike_model_2\n\n\n\n\n\nArt vs science\n\nInspecting residual plots is more art than science.1 It requires a lot of practice. Consider another example using simulated data. First, build a model that assumes all predictors are roughly linearly related:\n\n# Import data\nsimulated_data &lt;- read.csv(\"https://Mac-Stat.github.io/data/simulated_data.csv\")\n\n# Model y by the 6 input variables\nnew_model &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2 + x3 + x4 + x5 + x6, simulated_data)\n\nNext, check out a pairs plot. Is there anything here that makes you think that our model assumption is bad? (NOTE: if you are not familiar with the ggpairs function we are using below, chat with your group and look for resources to figure out what this is doing!)\n\nnew_model %&gt;% \n  augment(new_data = simulated_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) + \n  geom_point(size = 0.1) + \n  geom_hline(yintercept = 0)\n\n\n\n\n\n\n\n\n\n\n\n\nDetails ‚Äì communication & code style\n\nCommunication is a key machine learning skill, including written summaries, presentations, and code. Just like an essay, code must have structure, signposts, and grammar that will make it easier for others to follow. The below code runs, but it is ‚Äúbad code‚Äù.\n\nFix this code and add comments so that it is easier for yourself and others to follow.\nAlso pay attention to what this code does.\n\n\nbikes %&gt;%\n  group_by(weekend) %&gt;%\n  summarize(median(rides))\n## # A tibble: 2 √ó 2\n##   weekend `median(rides)`\n##   &lt;lgl&gt;             &lt;dbl&gt;\n## 1 FALSE              3848\n## 2 TRUE               2955\n\n\nmynewdatasetissmallerthantheoriginal&lt;-bikes%&gt;%filter(rides&lt;=700,weekend==FALSE,temp&gt;60)\nmynewdatasetissmallerthantheoriginal\n##   rides windspeed temp weekend\n## 1   577        18   67   FALSE\n## 2   655        18   68   FALSE\n## 3    20        24   72   FALSE\n\n\nmynewdatasetusescelsius&lt;-bikes%&gt;%mutate(temp=(temp-32)*5/9)\nhead(mynewdatasetusescelsius)\n##   rides windspeed      temp weekend\n## 1   654        11 18.333333    TRUE\n## 2   670        17 17.777778    TRUE\n## 3  1229        17  9.444444   FALSE\n## 4  1454        11 10.555556   FALSE\n## 5  1518        13 11.666667   FALSE\n## 6  1518         6 11.666667   FALSE\n\n\n\n\n\nSTAT 155 Review ‚Äì model interpretation & application\n\nLet‚Äôs interpret and apply bike_model_2.\n\n___ %&gt;% \n  tidy()\n\n\nHow can we interpret the temp coefficient?\n\n\nWe expect roughly 54 more riders on warm days.\nWe expect roughly 54 more riders per every 1 degree increase in temperature.\nWhen controlling for windspeed and weekend status, we expect roughly 54 more riders on warm days.\nWhen controlling for windspeed and weekend status, we expect roughly 54 more riders per every 1 degree increase in temperature.\n\n\nHow can we interpret the weekendTRUE coefficient?\n\n\nWe expect roughly 858 fewer riders on weekends.\nWe expect roughly 858 fewer riders per every extra weekend.\nWhen controlling for windspeed and temperature, we expect roughly 858 fewer riders on weekends.\nWhen controlling for windspeed and temperature, we expect roughly 858 fewer riders per every extra weekend.\n\n\nReproduce the predicted ridership and corresponding residual for day 1 from scratch (how were these calculated?!):\n\n\nbike_model_2 %&gt;% \n  ___(new_data = bikes) %&gt;% \n  head(1)\n\n\n\n\n\nSTAT 155 Review ‚Äì data wrangling\n\nThrough the ‚ÄúDetails: communication & code style‚Äù and elsewhere, you‚Äôve reviewed the use of various dplyr data wrangling verbs: filter(), mutate(), summarize(), group_by(), select(), arrange(). Use these to complete the following tasks.\n\nCalculate the mean temperature across all days in the data set.\n\n\nCalculate the mean temperature on weekends vs weekdays.\n\n\nPrint out the 3 days with the highest temperatures. HINT: arrange() or arrange(desc())\n\n\nName and store a new data set which:\n\n\nonly includes the days that fall on a weekend and have temps below 80 degrees\nhas a new variable, temp_above_freezing, which calculates how far the temperature is above (or below) freezing (32 degrees F)\nonly includes the windspeed, temp, and temp_above_freezing variables.\n\n\n\n\n\nSTAT 155 Review ‚Äì plots\n\nConstruct plots of the following relationships:\n\n# rides vs temp\n\n\n# rides vs weekend\n\n\n# rides vs temp and weekend",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "activities/L02-evaluating-regression-models.html#footnotes",
    "href": "activities/L02-evaluating-regression-models.html#footnotes",
    "title": "Model Evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nStefanski, Leonard A. (2007). Residual (Sur)Realism. ‚ÄúThe American Statistician,‚Äù 61, pp 163-177.‚Ü©Ô∏é",
    "crumbs": [
      "Model Evaluation"
    ]
  },
  {
    "objectID": "R_Rstudio.html",
    "href": "R_Rstudio.html",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Follow these instructions to set up the software that we‚Äôll be using throughout the semester.\n\n\n\n\n\n\nNote\n\n\n\nEven if you‚Äôve already downloaded both R and RStudio for a previous class, you need to re-download to make sure that you have the most current versions.\n\n\n\n\n\n\n\nRequired: Create a folder for this course on your local harddrive (e.g.¬†Desktop or Documents), not necessarily on a Cloud Drive as you may encounter large datasets in this class.\n\nHighly Recommended: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\n\n\n\n\n\nRequired: Install (or update) R and RStudio\n\nAs of January 2026, the latest versions of R and RStudio are:\n\nR: 4.5.2\nRStudio: 2026.01.0+392 \n\nIf you do not have the latest versions of both R and RStudio installed on your computer, see below. (Not sure if you do? See the THIRD step, below.)\n\nFIRST: Download R here.\n\nYou will see three links ‚ÄúDownload R for ‚Ä¶‚Äù\nChoose the link that corresponds to your computer operating system (and pay attention to processor chip type for Mac - M1/M2 or Intel; on your computer, click Apple &gt; About this Mac to find info about the chip).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\n\nTHIRD: Check your work\n\nOpen an RStudio session.\nRun the following in the Console, and repeat the FIRST or SECOND step if the version numbers that print out are not equal to (or more recent than) those listed above.\n\n\n\n# check R version\nR.Version()\n\n# check RStudio version\nrstudioapi::versionInfo()\n\n\nRequired: Install the most up-to-date versions of the required R packages for this course.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\",\"tidymodels\",\"GGally\",\"ISLR\"), dependencies = TRUE)\n\n\nIf you get a message that says ‚ÄúThere are binary versions available the source versions are later‚Äù type no and press Enter.\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(ggplot2) and hit enter.\nIf you see the message Error in library(ggplot2) : there is no package called ggplot2, then there was a problem installing this package. Jump down to the Troubleshooting section below. (Any other messages that appear are fine, and a lack of any messages is also fine.)\nRepeat the above step for the commands:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(ISLR)\n\nQuit RStudio. You‚Äôre done setting up!\n\n\nHighly Recommended: Set essential RStudio options.\nGo to:\n\nWindows: Edit &gt; Preferences &gt; General\nMac: Tools &gt; Global Options‚Ä¶ &gt; General\n\nNavigate to the ‚ÄúWorkspace‚Äù section.\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select ‚ÄúNever‚Äù\nPress ‚ÄúApply‚Äù and then ‚ÄúOK‚Äù\n\nIf you don‚Äôt change these options, RStudio will save all of the objects you ever create in your Global Environment. In practice, this leads to all of the objects, datasets, etc that you have ever worked with at Macalester being loaded in when you start RStudio.\n\nThis can make startup slow.\nIt clutters the Global Environment. (e.g., You‚Äôre working on something and referring to diamonds not knowing that a diamonds that was used in class last year is already in the Global Environment.)\n\n\nHighly Recommended: Watch this video made by Dr.¬†Lisa Lendway that describes useful configuration options for RStudio.\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\n\n\n\n\n\nProblem: You are on a Mac and getting the following error (or something similar):\n\n\n    Error: package or namespace load failed for ‚Äòggplot2‚Äô in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n     there is no package called ‚Äòrlang‚Äô\nHere‚Äôs how to fix it:\n\nFirst install the suite of Command Line Tools for Mac using the instructions here.\nNext enter install.packages(\"rlang\") in the Console.\nFinally check that entering library(ggplot2) gives no errors.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "R_Rstudio.html#file-organization",
    "href": "R_Rstudio.html#file-organization",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Required: Create a folder for this course on your local harddrive (e.g.¬†Desktop or Documents), not necessarily on a Cloud Drive as you may encounter large datasets in this class.\n\nHighly Recommended: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "R_Rstudio.html#r-rstudio",
    "href": "R_Rstudio.html#r-rstudio",
    "title": "R and RStudio Resources",
    "section": "",
    "text": "Required: Install (or update) R and RStudio\n\nAs of January 2026, the latest versions of R and RStudio are:\n\nR: 4.5.2\nRStudio: 2026.01.0+392 \n\nIf you do not have the latest versions of both R and RStudio installed on your computer, see below. (Not sure if you do? See the THIRD step, below.)\n\nFIRST: Download R here.\n\nYou will see three links ‚ÄúDownload R for ‚Ä¶‚Äù\nChoose the link that corresponds to your computer operating system (and pay attention to processor chip type for Mac - M1/M2 or Intel; on your computer, click Apple &gt; About this Mac to find info about the chip).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\n\nTHIRD: Check your work\n\nOpen an RStudio session.\nRun the following in the Console, and repeat the FIRST or SECOND step if the version numbers that print out are not equal to (or more recent than) those listed above.\n\n\n\n# check R version\nR.Version()\n\n# check RStudio version\nrstudioapi::versionInfo()\n\n\nRequired: Install the most up-to-date versions of the required R packages for this course.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\",\"tidymodels\",\"GGally\",\"ISLR\"), dependencies = TRUE)\n\n\nIf you get a message that says ‚ÄúThere are binary versions available the source versions are later‚Äù type no and press Enter.\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(ggplot2) and hit enter.\nIf you see the message Error in library(ggplot2) : there is no package called ggplot2, then there was a problem installing this package. Jump down to the Troubleshooting section below. (Any other messages that appear are fine, and a lack of any messages is also fine.)\nRepeat the above step for the commands:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(ISLR)\n\nQuit RStudio. You‚Äôre done setting up!\n\n\nHighly Recommended: Set essential RStudio options.\nGo to:\n\nWindows: Edit &gt; Preferences &gt; General\nMac: Tools &gt; Global Options‚Ä¶ &gt; General\n\nNavigate to the ‚ÄúWorkspace‚Äù section.\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select ‚ÄúNever‚Äù\nPress ‚ÄúApply‚Äù and then ‚ÄúOK‚Äù\n\nIf you don‚Äôt change these options, RStudio will save all of the objects you ever create in your Global Environment. In practice, this leads to all of the objects, datasets, etc that you have ever worked with at Macalester being loaded in when you start RStudio.\n\nThis can make startup slow.\nIt clutters the Global Environment. (e.g., You‚Äôre working on something and referring to diamonds not knowing that a diamonds that was used in class last year is already in the Global Environment.)\n\n\nHighly Recommended: Watch this video made by Dr.¬†Lisa Lendway that describes useful configuration options for RStudio.\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\n\n\n\n\n\nProblem: You are on a Mac and getting the following error (or something similar):\n\n\n    Error: package or namespace load failed for ‚Äòggplot2‚Äô in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n     there is no package called ‚Äòrlang‚Äô\nHere‚Äôs how to fix it:\n\nFirst install the suite of Command Line Tools for Mac using the instructions here.\nNext enter install.packages(\"rlang\") in the Console.\nFinally check that entering library(ggplot2) gives no errors.",
    "crumbs": [
      "R and RStudio Resources"
    ]
  },
  {
    "objectID": "R_Resources.html",
    "href": "R_Resources.html",
    "title": "R Resources",
    "section": "",
    "text": "Tidymodels package documentation\nTidy Modeling with R textbook (Max Kuhn and Julia Silge)\nISLR Labs with Tidymodels (Emil Hvitfeldt)\nIntro to Tidymodels Presentation (Lucy D‚ÄôAgostino McGowan)\n\n\n\n\n\nCOMP/STAT 112 website (with code examples and videos)\nR for Data Science\nExploratory Data Analysis with R\nJohn‚Äôs Hopkins Tidyverse course text\n\n\n\n\n\nggplot2 reference\nColors in R\n\n\n\n\n\nCOMP/STAT 112 website (including an example quarto document)\nQuarto cheatsheet\nQuarto tutorial\nComprehensive Quarto Guide\n\n\n\n\n\nRStudio cheatsheets\nAdvanced R\nR Programming Wikibook\nDebugging in R\n\nArticle\nVideo\n\n\n\n\n\n\nCreating new variables\ncase_when() from the dplyr package is a very versatile function for creating new variables based on existing variables. This can be useful for creating categorical or quantitative variables and for creating indices from multiple variables.\n\n# Turn quant_var into a Low/Med/High version\ndata &lt;- data %&gt;%\n    mutate(cat_var = case_when(\n            quant_var &lt; 10 ~ \"Low\",\n            quant_var &gt;= 10 & quant_var &lt;= 20 ~ \"Med\",\n            quant_var &gt; 20 ~ \"High\"\n        )\n    )\n\n# Turn cat_var (A, B, C categories) into another categorical variable\n# (collapse A and B into one category)\ndata &lt;- data %&gt;%\n    mutate(new_cat_var = case_when(\n            cat_var %in% c(\"A\", \"B\") ~ \"A or B\"\n            cat_var==\"C\" ~ \"C\"\n        )\n    )\n\n# Turn a categorical variable (x1) encoded as a numerical 0/1/2 variable into a different quantitative variable\n# Doing this for multiple variables allows you to create an index\ndata &lt;- data %&gt;%\n    mutate(x1_score = case_when(\n            x1==0 ~ 10,\n            x1==1 ~ 20,\n            x1==2 ~ 50\n        )\n    )\n\n# Add together multiple variables with mutate\ndata &lt;- data %&gt;%\n    mutate(index = x1_score + x2_score + x3_score)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#tidymodels-resources",
    "href": "R_Resources.html#tidymodels-resources",
    "title": "R Resources",
    "section": "",
    "text": "Tidymodels package documentation\nTidy Modeling with R textbook (Max Kuhn and Julia Silge)\nISLR Labs with Tidymodels (Emil Hvitfeldt)\nIntro to Tidymodels Presentation (Lucy D‚ÄôAgostino McGowan)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#tidyverse-resources",
    "href": "R_Resources.html#tidyverse-resources",
    "title": "R Resources",
    "section": "",
    "text": "COMP/STAT 112 website (with code examples and videos)\nR for Data Science\nExploratory Data Analysis with R\nJohn‚Äôs Hopkins Tidyverse course text",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#visualization-resources",
    "href": "R_Resources.html#visualization-resources",
    "title": "R Resources",
    "section": "",
    "text": "ggplot2 reference\nColors in R",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#quarto-resources",
    "href": "R_Resources.html#quarto-resources",
    "title": "R Resources",
    "section": "",
    "text": "COMP/STAT 112 website (including an example quarto document)\nQuarto cheatsheet\nQuarto tutorial\nComprehensive Quarto Guide",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#general-r-resources",
    "href": "R_Resources.html#general-r-resources",
    "title": "R Resources",
    "section": "",
    "text": "RStudio cheatsheets\nAdvanced R\nR Programming Wikibook\nDebugging in R\n\nArticle\nVideo",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "R_Resources.html#some-example-code",
    "href": "R_Resources.html#some-example-code",
    "title": "R Resources",
    "section": "",
    "text": "Creating new variables\ncase_when() from the dplyr package is a very versatile function for creating new variables based on existing variables. This can be useful for creating categorical or quantitative variables and for creating indices from multiple variables.\n\n# Turn quant_var into a Low/Med/High version\ndata &lt;- data %&gt;%\n    mutate(cat_var = case_when(\n            quant_var &lt; 10 ~ \"Low\",\n            quant_var &gt;= 10 & quant_var &lt;= 20 ~ \"Med\",\n            quant_var &gt; 20 ~ \"High\"\n        )\n    )\n\n# Turn cat_var (A, B, C categories) into another categorical variable\n# (collapse A and B into one category)\ndata &lt;- data %&gt;%\n    mutate(new_cat_var = case_when(\n            cat_var %in% c(\"A\", \"B\") ~ \"A or B\"\n            cat_var==\"C\" ~ \"C\"\n        )\n    )\n\n# Turn a categorical variable (x1) encoded as a numerical 0/1/2 variable into a different quantitative variable\n# Doing this for multiple variables allows you to create an index\ndata &lt;- data %&gt;%\n    mutate(x1_score = case_when(\n            x1==0 ~ 10,\n            x1==1 ~ 20,\n            x1==2 ~ 50\n        )\n    )\n\n# Add together multiple variables with mutate\ndata &lt;- data %&gt;%\n    mutate(index = x1_score + x2_score + x3_score)",
    "crumbs": [
      "R Resources"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html",
    "href": "activities/L01-introductions.html",
    "title": "Introduction to Statistical Machine Learning",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#whats-machine-learning",
    "href": "activities/L01-introductions.html#whats-machine-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "What‚Äôs Machine Learning?",
    "text": "What‚Äôs Machine Learning?\n\n\n‚ÄúMachine Learning‚Äù was coined back in 1959 by Arthur Samuel, an early contributor to AI.\nFrom Kohavi & Provost (1998): Machine Learning is the exploration & application of algorithms that can learn from existing patterns and make predictions using data.\n\nIMPORTANT: humans are in charge of the ‚Äúexploration & application‚Äù!\n\nFrom James et al (2021) [link]: Statistical Learning refers to a vast set of tools for understanding data.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#in-stat-253-we-will",
    "href": "activities/L01-introductions.html#in-stat-253-we-will",
    "title": "Introduction to Statistical Machine Learning",
    "section": "In STAT 253 we will‚Ä¶",
    "text": "In STAT 253 we will‚Ä¶\n\n\nPick up where STAT 155 left off, acquiring tools that can be used to learn from data in greater depth and a wider variety of settings. (STAT 155 is a foundational subset of ML!)\nExplore universal ML concepts using tools and software common among statisticians (hence ‚Äústatistical‚Äù machine learning).\nSurvey a breadth of modern ML tools and algorithms that fall into the workflow below. Part of the cognitive load will be:\n\nkeeping all the tools in place (what are they and when to use them)\nunderstanding the connections between the tools\nadapting (not memorizing) code to implement each tool\na new topic almost every day\n\nWe‚Äôll focus on concepts and applications over mathematical theory. (Come chat with me in office hours if you‚Äôre interested in learning more about the theory!)",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#course-structure",
    "href": "activities/L01-introductions.html#course-structure",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Course Structure",
    "text": "Course Structure",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#before-class",
    "href": "activities/L01-introductions.html#before-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Before Class",
    "text": "Before Class\nIn order to dedicate our class time to hands-on learning, you will prepare for class by watching short videos, reading from our textbook, and completing short quizzes (checkpoints) to assess your initial understanding of concepts. You can reattempt each checkpoint question multiple times, with a small penalty for incorrect responses.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#during-class",
    "href": "activities/L01-introductions.html#during-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "During Class",
    "text": "During Class\nDuring class time, you will engage with each other in exercises and discussions that build upon the pre-class work. Please bring your laptop to class every day. Consistent attendance and active participation in these activities is expected of all students and, most importantly, will be crucial for your learning!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#after-class",
    "href": "activities/L01-introductions.html#after-class",
    "title": "Introduction to Statistical Machine Learning",
    "section": "After Class",
    "text": "After Class\nAfter class, you will be expected to finish any remaining exercises from the class activity and review/organize your notes. For each unit, you will also complete homework assignments designed to help you practice and synthesize material and provide an opportunity to receive feedback to further guide your learning.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#types-of-ml-tasks",
    "href": "activities/L01-introductions.html#types-of-ml-tasks",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Types of ML Tasks",
    "text": "Types of ML Tasks\n\nStatistical machine learning tools can be classified as follows:\n\nsupervised or unsupervised\nwithin supervised learning: regression vs classification\nwithin unsupervised learning: clustering vs dimension reduction\n\nKnowing which of these scenarios your research question falls into is an important first step in identifying which tool to use!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#supervised-learning",
    "href": "activities/L01-introductions.html#supervised-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nWe want to model the relationship between some output variable1 \\(y\\) and input variables2 \\(x = (x_1, x_2,..., x_p)\\):\n\\[\n\\begin{split}\ny\n& = f(x) + \\varepsilon \\\\\n& = \\text{(trend in the relationship) } + \\text{ (residual deviation from the trend)} \\\\\n\\end{split}\n\\]\nTypes of supervised learning tasks:\n\nregression: \\(y\\) is quantitative\nexample:\n\\(y\\) = number of dental caries (cavities)\n\\(x\\) = (genetic information at millions of markers, sex, age, age\\(^2\\), etc)\nproject details\nclassification: \\(y\\) is categorical\nexample:\n\\(y\\) = whether a patient experienced adverse surgery outcomes after undergoing an upper endoscopy (yes, no)\n\\(x\\) = (administration of sedation [anesthesia professional, nurse], age, medical comorbidities [eg sleep apnea], etc.)\nproject details",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#unsupervised-learning",
    "href": "activities/L01-introductions.html#unsupervised-learning",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\nWe have some input variables \\(x = (x_1, x_2,..., x_p)\\) but there‚Äôs no output variable \\(y\\). Thus the goal is to use \\(x\\) to understand and/or modify the structure of our data.\nTypes of unsupervised learning tasks:\n\n\n\n\nclustering: Identify and examine groups or clusters of data points that are similar with respect to their \\(x_i\\) values.\nexample:\n\\(x\\) = (genetic data)\nproject details (led by a Mac alum!)\ndimension reduction: Turn the original set of \\(p\\) input variables, which are potentially correlated, into a smaller set of \\(k &lt; p\\) variables which still preserve the majority of information in the originals.\nexample:\n\\(x\\) = (genetic data)\nproject details\n\n\n\n\n\n\nSupplemental Figure 2A from Barragan et al (2023) [link] uses both clustering and dimension reduction!",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#instructions",
    "href": "activities/L01-introductions.html#instructions",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Instructions",
    "text": "Instructions\n\nDiscuss the following scenarios as a group, talking through your ideas, questions, and reasoning as you go.\nWrite down your answers, and any insights or questions that come up while working, in your notebook or simply type in here and render your own work!\nI‚Äôll move around to groups to check in on your progress and see what questions you have.\nYou can check your answers by clicking the drop-down ‚ÄúSolutions‚Äù button.",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#questions",
    "href": "activities/L01-introductions.html#questions",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Questions",
    "text": "Questions\nIndicate whether each scenario below represents a regression, classification, or clustering task.\n\nHow is the number of people that rent bikes on a given day in Washington, D.C. (\\(y\\)) explained by the temperature (\\(x_1\\)) and whether or not it‚Äôs a weekend (\\(x_2\\))?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nregression. there‚Äôs a quantitative output variable \\(y\\).\n\n\n\nGiven the observed bill length (\\(x_1\\)) and bill depth (\\(x_2\\)) on a set of penguins, how many different penguin species might there be?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nclustering. there‚Äôs no output variable \\(y\\).\n\n\n\nHow can we determine whether somebody has a certain infection (\\(y\\)) based on two different blood sample measurements, Measure A (\\(x_1\\)) and Measure B (\\(x_2\\))?\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nclassification. there‚Äôs a categorical output variable \\(y\\).\n\n\n\nMachine learn about past students! Scenario A.\nThe following data were collected from past STAT 253 students and were analyzed using a machine learning algorithm. The questions were about their major (STAT/DS and Other), Activity (readng, streaming), walk time to MAC, Photo rating, class year, ). In your groups: (1) brainstorm what research question is being investigated; (2) determine whether this is a regression, classification, or clustering task; and (3) summarize what the output tells you about the students.\n\n\n\n\nSolution\n\n\npredict someone‚Äôs major based on ‚Äòother‚Äô survey responses\nclassification (\\(y\\) = major is categorical)\n(will vary by semester ‚Äì what do you learn about the majors represented in this class and the variables that are useful for predicting it?)\n\n\n\n\nMachine learn about past students! Scenario B.\nSame directions as for Scenario A: (1) brainstorm what research question is being investigated; (2) determine whether this is a regression, classification, or clustering task; and (3) summarize what the output tells you about the students.\n\n\n\n\nSolution\n\n\npredict walk time to Mac based on photo rating and class year\nregression (\\(y\\) = time to mac is quantitative)\n(answers will vary by semester ‚Äì what do you learn about the relationships between these variables?)\n\n\n\n\nUse Spotify users‚Äô previous listening behavior to identify groups of similar users.\n\n\n\nSolution\n\nclustering\n\n \n\nPredict workers‚Äô wages by their years of experience.\n\n\n\n\nSolution\n\nregression (\\(y\\) = wages)\n\n\n\nPredict workers‚Äô wages by their college major.\n\n\n\n\nSolution\n\nregression (\\(y\\) = wages)\n\n\n\nUse a customer‚Äôs age to predict whether they‚Äôve seen the Barbie movie.\n\n\n\n\nSolution\n\nclassification (\\(y\\) = whether or not watched the film)\n\n\n\nLook for similarities among genetic samples taken from a group of patients.\n\n\n\n\nSolution\n\nclustering (no outcome \\(y\\))",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#whats-next",
    "href": "activities/L01-introductions.html#whats-next",
    "title": "Introduction to Statistical Machine Learning",
    "section": "What‚Äôs next?",
    "text": "What‚Äôs next?\nWhat to work on after class today:\n\ncomplete the pre-class tasks for next class on Friday (videos/reading/checkpoint)- note that no class on Wednesday!\n\nreview the checkpoint instructions & policies on Moodle before you start!\n\nstart HW0 (I will post it soon)\n\ndue Friday (at 11:59 pm)\nreview the Stat 155 Review resources as needed\n\ncomplete the recommended R and RStudio Setup steps\ncarefully review the course logistics (in the course website)",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L01-introductions.html#footnotes",
    "href": "activities/L01-introductions.html#footnotes",
    "title": "Introduction to Statistical Machine Learning",
    "section": "Footnotes",
    "text": "Footnotes\n\n\notherwise known as outcome, response, dependent variable‚Ü©Ô∏é\notherwise known as predictors, features, independent variables‚Ü©Ô∏é",
    "crumbs": [
      "Introduction to Statistical Machine Learning"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html",
    "href": "activities/L03-Overfitting.html",
    "title": "Overfitting",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#directions",
    "href": "activities/L03-Overfitting.html#directions",
    "title": "Overfitting",
    "section": "Directions",
    "text": "Directions\nLet‚Äôs build and evaluate a predicted model of an adult‚Äôs height (\\(y\\)) using some predictors \\(x_i\\) (e.g., age, weight, etc.).\n\nIntroduce yourself in whatever way you feel appropriate and check in with each other as human beings\nCome up with a team name\nWork through the steps below as a group\n\nEach group will be given a different sample of 40 adults\nStart by predicting height (in) using hip circumference (cm)\nEvaluate the model on your sample.\n\nBe prepared to share your answers to:\n\nHow good is your simple model?\nWhat would happen if we added more predictors?",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions",
    "href": "activities/L03-Overfitting.html#questions",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\n\nGoal\n\nLet‚Äôs build and evaluate a predictive model of an adult‚Äôs height (\\(y\\)) using some predictors \\(x_i\\) (eg: age, height, etc).\nSince \\(y\\) is quantitative this is a regression task.\nThere are countless possible models of \\(y\\) vs \\(x\\). We‚Äôll utilize a linear regression model:\n\n\\[y = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p + \\varepsilon\\]\n\nAnd after building this model, we‚Äôll evaluate it.\n\n\n\nData: Each group will be given a different sample of 40 adults.\n\n# Load packages needed for this analysis\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nUsing the following starter code, fill in the blank in the URL with the appropriate number depending on your group number.\n\nGroup 1: 50\nGroup 2: 143\n\nREMINDER: Do not edit the starter code directly. Instead, copy-paste the code into an empty code chunk below. Then, make edits (eg fill in blanks) in that second code chunk.\n\n# Load data\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat___.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\nCheck out a density plot of your outcome:\n\n# Plot data\nggplot(humans, aes(x = ___)) + \n  geom____()\n\n\n\nModel building: Build a linear regression model of height (in) by hip circumference (cm).\n\n# STEP 1: model specification\nlm_spec &lt;- ___() %&gt;% \n  set_mode(___) %&gt;% \n  set_engine(___)\n\n\n# STEP 2: model estimation\nmodel_1 &lt;- ___ %&gt;% \n  ___(height ~ hip, data = humans)\n\n\n# Check out the coefficients\n# Do all groups have the same coefficients? Should they?\n\n\n\nModel evaluation: How good is our model?\n\n# Calculate the R^2 for model_1\n\n\n# Use your model to predict height for your subjects\n# Just print the first 6 results\nmodel_1 %&gt;% \n  ___(new_data = ___) %&gt;% \n  head()\n\n\n# Calculate the MAE, i.e. typical prediction error, for your model\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  ___(truth = ___, estimate = ___)\n\n\n\nReflection\nIn addition to hip circumference, suppose we incorporated more predictors into our model of height. What would happen to \\(R^2\\)? To the MAE?",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#directions-1",
    "href": "activities/L03-Overfitting.html#directions-1",
    "title": "Overfitting",
    "section": "Directions",
    "text": "Directions\n\nTake 5 minutes to complete exercises 1 and 2 (choosing one of three models).\nWe‚Äôll pause for a few minutes to discuss each group‚Äôs answers to these exercises.\nThen, and only then, you can finish exercises 3 - 5.\n\nREMINDERS:\n\nBe kind to yourself/each other. You will make mistakes!\nCollaborate:\n\nactively contribute to discussion (don‚Äôt work on your own)\nactively include all group members in discussion\ncreate a space where others feel comfortable making mistakes and sharing their ideas\nstay in sync",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions-1",
    "href": "activities/L03-Overfitting.html#questions-1",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\n\nSelect a model\n\nConsider 3 different models of height, estimated below. As a group, use your data to choose which is the best predictive model of height. Calculate the MAE for this model.\n\n# height vs hip\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_1 %&gt;% \n  tidy()\n## Error: object 'model_1' not found\n\n# height vs hip & weight\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_2 %&gt;% \n  tidy()\n## Error: object 'model_2' not found\n\n# height vs a lot of predictors (AND some interaction terms)\nmodel_3 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat * abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n## Error: object 'lm_spec' not found\n\nmodel_3 %&gt;% \n  tidy()\n## Error: object 'model_3' not found\n\n\n# Calculate the MAE for your model\n___ %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## Error in parse(text = input): &lt;text&gt;:2:2: unexpected input\n## 1: # Calculate the MAE for your model\n## 2: __\n##     ^\n\n\n\nüõë WAIT. Don‚Äôt keep going.\n\n\n\n\n\n\n\nDon‚Äôt peek\nWhat do you know?! 40 new people just walked into the doctor‚Äôs office and the doctor wants to predict their height:\n\n# Import the new data\nnew_patients &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat182.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\n\n\n\n\nIntuition\nConsider using your models to predict height for these 40 new subjects. On average, do you think these predictions will be better or worse than for your original patients? Why?\n\n\n\n\n\nHow well does your models do in the real world?\nUse your model to predict height for the new patients and calculate the typical prediction error (MAE). Record this in the Google sheet. (MAE: NEW PATIENTS)\n\n\n___ %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## Error in parse(text = input): &lt;text&gt;:1:2: unexpected input\n## 1: __\n##      ^\n\n\n\n\n\nReflection\nIn summary, which model seems best? What‚Äôs the central theme here?\n\n\nIn general, models tend to perform worse on new data than on the data on which they were built/trained. In this particular dataset, Model 2 looks best on new data, and Model 3 performs horribly. Model 3 is overfit to the training data. This is more likely to happen with an overly complicated model.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#overfitting",
    "href": "activities/L03-Overfitting.html#overfitting",
    "title": "Overfitting",
    "section": "Overfitting",
    "text": "Overfitting\nWhen we add more and more predictors into a model, it can become overfit to the noise in our sample data:\n\nour model loses the broader trend / big picture\nthus does not generalize to new data\nthus results in bad predictions and a bad understanding of the relationship among the new data points\n\n\n\nPreventing overfitting: training and testing\n\nIn-sample metrics, i.e.¬†measures of how well the model performs on the same sample data that we used to build it, tend to be overly optimistic and lead to overfitting.\nInstead, we should build and evaluate, or train and test, our model using different data.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#r-code",
    "href": "activities/L03-Overfitting.html#r-code",
    "title": "Overfitting",
    "section": "R Code",
    "text": "R Code\n\n\n\n\n\n\nNote\n\n\n\nThis section is for future reference. It is a summary of code you‚Äôll learn below for creating and applying training and testing data. You don‚Äôt need to (and in fact should not) run the code in this section‚Äîjust use this as example code for future reference.\n\n\nSuppose we wish to build and evaluate a linear regression model of y vs x1 and x2 using our sample_data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nSplit the sample data into training and test sets\n\n# Set the random number seed\nset.seed(___)\n\n# Split the sample_data\n# \"prop\" is the proportion of data assigned to the training set\n# it must be some number between 0 and 1\ndata_split &lt;- initial_split(sample_data, strata = y, prop = ___)\n\n# Get the training data from the split\ndata_train &lt;- data_split %&gt;% \n  training()\n\n# Get the testing data from the split\ndata_test &lt;- data_split %&gt;% \n  testing()\n\nBuild a training model\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\nmodel_train &lt;- lm_spec %&gt;% \n  fit(y ~ x1 + x2, data = data_train)\n\nUse the training model to make predictions for the test data\n\n# Make predictions\nmodel_train %&gt;% \n  augment(new_data = data_test)\n\nEvaluate the training model using the test data\n\n# Calculate the test MAE\nmodel_train %&gt;% \n  augment(new_data = data_test) %&gt;% \n  mae(truth = y, estimate = .pred)",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#questions-2",
    "href": "activities/L03-Overfitting.html#questions-2",
    "title": "Overfitting",
    "section": "Questions",
    "text": "Questions\nThe following exercises are inspired by Chapter 5.3.1 of ISLR.\n\n# Load packages\n# NOTE: You might first need to install the ISLR package\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ISLR) # install the package ISLR if you haven't already\n\n# Load data\ndata(Auto)\n\n# Select three variables from Auto data\n# Save as a data frame called \"cars\"\ncars &lt;- Auto %&gt;% \n  dplyr::select(mpg, horsepower, year)\nhead(cars)\n##   mpg horsepower year\n## 1  18        130   70\n## 2  15        165   70\n## 3  18        150   70\n## 4  16        150   70\n## 5  17        140   70\n## 6  15        198   70\ndim(cars)\n## [1] 392   3\n\n\n\nLet‚Äôs use the cars data to compare three linear regression models of fuel efficiency in miles per gallon (mpg) by engine power (horsepower):\n\n# Raw data\ncars_plot &lt;- ggplot(cars, aes(x = horsepower, y = mpg)) + \n  geom_point()\ncars_plot\n\n\n\n\n\n\n\n\n\n# model 1: 1 predictor (y = b0 + b1 x)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# model 2: 2 predictors (y = b0 + b1 x + b2 x^2)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 2))\n\n\n\n\n\n\n\n\n\n# model 3: 19 predictors (y = b0 + b1 x + b2 x^2 + ... + b19 x^19)\ncars_plot + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 19))\n\n\n\n\n\n\n\n\n\n\nGoal\nLet‚Äôs evaluate and compare these models by training and testing them using different data.\n\n\n\n155 review: set.seed()\n\nRun the two chunks below multiple times each. Afterward, summarize what set.seed() does and why it‚Äôs important to being able to reproduce a random sample.\n\nsample_n(cars, 2)\n##      mpg horsepower year\n## 224 15.5        145   77\n## 326 44.3         48   80\n\n\nset.seed(253)\nsample_n(cars, 2)\n##      mpg horsepower year\n## 224 15.5        145   77\n## 61  20.0         90   72\n\n¬†\n\nTraining and test sets\n\nLet‚Äôs randomly split our original 392 sample cars into two separate pieces: select 80% of the cars to train (build) the model and the other 20% to test (evaluate) the model.\n\n# Set the random number seed\nset.seed(8)\n    \n# Split the cars data into 80% / 20%\n# Ensure that the sub-samples are similar with respect to mpg\ncars_split &lt;- initial_split(cars, strata = mpg, prop = 0.8)\n\n\n# Check it out\n# What do these numbers mean?\ncars_split\n## &lt;Training/Testing/Total&gt;\n## &lt;312/80/392&gt;\n\n\n# Get the training data from the split\ncars_train &lt;- cars_split %&gt;% \n  training()\n    \n# Get the testing data from the split\ncars_test &lt;- cars_split %&gt;% \n  testing()\n\n\n# The original data has 392 cars\nnrow(cars)\n## [1] 392\n    \n# How many cars are in cars_train?\nnrow(cars_train)\n## [1] 312\n\n# How many cars are in cars_test?\nnrow(cars_test)\n## [1] 80\n\n\n\n\nReflect on the above code\n\n\nWhy do we want the training and testing data to be similar with respect to mpg (strata = mpg)? What if they weren‚Äôt?\n\n\nSuppose, for example, the training cars all had higher mpg than the test cars. Then the training model likely would not perform well on the test cars, thus we‚Äôd get an overly pessimistic measure of model quality.\n\n\nWhy did we need all this new code instead of just using the first 80% of cars in the sample for training and the last 20% for testing?\n\n\nIf the cars are ordered in some way (eg: from biggest to smallest) then our training and testing samples would have systematically different properties.\n\n\n\n\nBuild the training model\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- ___ %&gt;% \n  ___(mpg ~ poly(horsepower, 19), data = ___)\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- lm_spec %&gt;% \n  fit(mpg ~ poly(horsepower, 19), data = cars_train)\n\n\n\n\nEvaluate the training model\n\n\n# How well does the TRAINING model predict the TRAINING data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = ___) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n\n\n# How well does the training model predict the training data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_train) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        2.99\n\n\n# How well does the TRAINING model predict the TEST data?\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = ___) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n\n\n\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_test) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        6.59\n\n\n\n\nPunchline\n\nThe table below summarizes your results for train_model_19 as well as the other two models of interest. (You should confirm the other two model results outside of class!)\n\n\n\nModel\nTraining MAE\nTesting MAE\n\n\n\n\nmpg ~ horsepower\n3.78\n4.00\n\n\nmpg ~ poly(horsepower, 2)\n3.20\n3.49\n\n\nmpg ~ poly(horsepower, 19)\n2.99\n6.59\n\n\n\nLet us discuss following and reflect on why each answer makes sense:\n\nWithin each model, how do the training errors compare to the testing errors? (This isn‚Äôt always the case, but is common.)\n\n\nthe training errors are smaller\n\n\nWhat about the training and test errors for the third model suggest that it is overfit to our sample data?\n\n\nthe test MAE is much larger than the training MAE\n\n\nWhich model seems the best with respect to the training errors?\n\n\nthe 19th order polynomial\n\n\nWhich model is the best with respect to the testing errors?\n\n\nthe quadratic\n\n\nWhich model would you choose?\n\n\nthe quadratic\n\n\n\n\nFinal reflection\n\n\nThe training / testing procedure provided a more honest evaluation and comparison of our model predictions. How might we improve upon this procedure? What problems can you anticipate in splitting our data into 80% / 20%?\nSummarize the key themes from today in your own words.\n\n\n\n\nSTAT 155 REVIEW: data drill\n\n\nConstruct and interpret a plot of mpg vs horsepower and year.\nCalculate the average mpg.\nCalculate the average mpg for each year. HINT: group_by()\nPlot the average mpg by year.\n\n\n\n\nCode for the curious (optional)\n\nI wrote a function calculate_MAE() to automate the calculations in the table. If you‚Äôre curious, pick through this code!\n\n# Write function to calculate MAEs\ncalculate_MAE &lt;- function(poly_order){\n  # Construct a training model\n  model &lt;- lm_spec %&gt;% \n    fit(mpg ~ poly(horsepower, poly_order), cars_train)\n  \n  # Calculate the training MAE\n  train_it &lt;- model %&gt;% \n    augment(new_data = cars_train) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Calculate the testing MAE\n  test_it &lt;- model %&gt;% \n    augment(new_data = cars_test) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Return the results\n  return(data.frame(train_MAE = train_it$.estimate, test_MAE = test_it$.estimate))\n}\n    \n# Calculate training and testing MSEs\ncalculate_MAE(poly_order = 1)\n##   train_MAE test_MAE\n## 1  3.779331 4.004333\ncalculate_MAE(poly_order = 2)\n##   train_MAE test_MAE\n## 1  3.199882 3.487022\ncalculate_MAE(poly_order = 19)\n##   train_MAE test_MAE\n## 1  2.989305 6.592341\n\n# For those of you interested in trying all orders...\n\nresults &lt;- purrr::map_df(1:19,calculate_MAE) %&gt;% \n  mutate(order = 1:19) %&gt;%\n  pivot_longer(cols=1:2,names_to='Metric',values_to = 'MAE') \n\nresults %&gt;%\n  ggplot(aes(x = order, y = MAE, color = Metric)) + \n  geom_line() + \n  geom_point(data = results %&gt;% filter(Metric == 'test_MAE') %&gt;% slice_min(MAE)) + \n  geom_point(data = results %&gt;% filter(Metric == 'train_MAE') %&gt;% slice_min(MAE))",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#small-group-discussion-1",
    "href": "activities/L03-Overfitting.html#small-group-discussion-1",
    "title": "Overfitting",
    "section": "Small Group Discussion",
    "text": "Small Group Discussion\nData\n\n\nSolution\n\nEach group will have slightly different plots because they have different samples of data.\nThroughout the solutions I‚Äôll use one of the datasets as an example:\n\nhumans &lt;- read.csv(\"https://Mac-Stat.github.io/data/bodyfat50.csv\") %&gt;% \n  filter(ankle &lt; 30) %&gt;% \n  rename(body_fat = fatSiri)\n\nggplot(humans, aes(x = height)) + \n  geom_density()\n\n\n\n\n\n\n\n\n\n\nModel building\n\n\nSolution\n\nEach group will have slightly different coefficients because they have different samples of data.\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode('regression') %&gt;% \n  set_engine('lm')\n\n# STEP 2: model estimation\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\n\n# Check out the coefficients\nmodel_1  %&gt;% \n  tidy()\n## # A tibble: 2 √ó 5\n##   term        estimate std.error statistic      p.value\n##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n## 1 (Intercept)   52.5      7.68        6.84 0.0000000460\n## 2 hip            0.179    0.0778      2.30 0.0272\n\n\n\nModel evaluation\n\n\nSolution\n\nAgain, each group will have slightly different answers here because they have different samples of data.\n\n# Calculate the R^2 for model_1\nmodel_1 %&gt;%\n  glance()\n## # A tibble: 1 √ó 12\n##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1     0.125         0.101  2.26      5.29  0.0272     1  -86.1  178.  183.\n## # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n# Use your model to predict height for your subjects\n# Just print the first 6 results\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  head()\n## # A tibble: 6 √ó 21\n##   .pred .resid fatBrozek body_fat density   age weight height adiposity\n##   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n## 1  70.3  -1.09      24.7     25.4    1.04    43   177    69.2      26  \n## 2  70.8  -1.52      22       22.5    1.05    38   187.   69.2      27.5\n## 3  70.2  -1.19       9.4      8.8    1.08    29   161.   69        23.8\n## 4  68.9   4.58       7.1      6.3    1.08    49   153.   73.5      19.9\n## 5  69.3   2.91       9.9      9.4    1.08    23   160.   72.2      21.6\n## 6  70.2  -2.48      22.7     23.3    1.05    52   167    67.8      25.6\n## # ‚Ñπ 12 more variables: fatFreeWeight &lt;dbl&gt;, neck &lt;dbl&gt;, chest &lt;dbl&gt;,\n## #   abdomen &lt;dbl&gt;, hip &lt;dbl&gt;, thigh &lt;dbl&gt;, knee &lt;dbl&gt;, ankle &lt;dbl&gt;,\n## #   biceps &lt;dbl&gt;, forearm &lt;dbl&gt;, wrist &lt;dbl&gt;, hipin &lt;dbl&gt;\n\n# Calculate the MAE, i.e. typical prediction error, for your model\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.88\n\n\n\nReflection\n\n\nSolution\n\n\\(R^2\\) would increase and MAE would decrease.\n\n\nBONUS\n\n\nSolution\n\nReview your notes from last class and stop by office hours to discuss!",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#exercises-part-1-1",
    "href": "activities/L03-Overfitting.html#exercises-part-1-1",
    "title": "Overfitting",
    "section": "Exercises (Part 1)",
    "text": "Exercises (Part 1)\n\nSelect a model\n\n\n\nSolution\n\nWill vary by group. MAE is calculated here for each model.\nREMINDER: Throughout the solutions I‚Äôm using one of the datasets as an example: bodyfat50.csv.\n\n# Build the models\nmodel_1 &lt;- lm_spec %&gt;% \n  fit(height ~ hip, data = humans)\nmodel_2 &lt;- lm_spec %&gt;% \n  fit(height ~ hip + weight, data = humans)\nmodel_3 &lt;- lm_spec %&gt;% \n  fit(height ~ chest * age * weight * body_fat * abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, data = humans)\n\n# Evaluate the models\nmodel_1 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.88\nmodel_2 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.67\nmodel_3 %&gt;% \n  augment(new_data = humans) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard    1.53e-10\n\n\n\n\nShare your results.\n\n\n\nSolution\n\nDone! (Model 3 had the best MAE for this dataset.)\n\n\n\nIntuition.\n\n\n\nSolution\n\nAnswers will vary.\n\n\n\nHow well does your model do in the real world?\n\n\n\nSolution\n\n\n# Predict height (assume, for example, I choose model_1)\nmodel_1 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  head()\n## # A tibble: 6 √ó 21\n##   .pred .resid fatBrozek body_fat density   age weight height adiposity\n##   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n## 1  71.5 -1.96       27.1     28      1.04    62   201.   69.5      29.3\n## 2  70.4 -0.141      20.9     21.3    1.05    42   163    70.2      23.3\n## 3  69.7 -0.497      26.1     27      1.04    72   168    69.2      24.7\n## 4  69.1 -1.39        4.1      3      1.09    35   152.   67.8      23.4\n## 5  68.5 -2.99        1.9      0.7    1.1     35   126.   65.5      20.6\n## 6  71.9 -1.91       31       32.3    1.03    57   206.   70        29.5\n## # ‚Ñπ 12 more variables: fatFreeWeight &lt;dbl&gt;, neck &lt;dbl&gt;, chest &lt;dbl&gt;,\n## #   abdomen &lt;dbl&gt;, hip &lt;dbl&gt;, thigh &lt;dbl&gt;, knee &lt;dbl&gt;, ankle &lt;dbl&gt;,\n## #   biceps &lt;dbl&gt;, forearm &lt;dbl&gt;, wrist &lt;dbl&gt;, hipin &lt;dbl&gt;\n\n\n# Calculate the MAE for model_1\nmodel_1 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.73\n\n# Calculate the MAE for model_2\nmodel_2 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        1.68\n\n# Calculate the MAE for model_3\nmodel_3 %&gt;% \n  augment(new_data = new_patients) %&gt;% \n  mae(truth = height, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        105.\n\n\n\n\nReflection\n\n\n\nSolution\n\nA few takeaways:\n\nIn general, models tend to perform worse on new data than on the data on which they were built/trained.\nIn this particular dataset, Model 2 looks best on new data, and Model 3 performs horribly.\nModel 3 is overfit to the training data. This is more likely to happen with an overly complicated model.",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L03-Overfitting.html#exercises-part-2-1",
    "href": "activities/L03-Overfitting.html#exercises-part-2-1",
    "title": "Overfitting",
    "section": "Exercises (Part 2)",
    "text": "Exercises (Part 2)\n\n155 review: set.seed()\n\n\n\nSolution\n\nset.seed() is used to create the same ‚Äúrandom numbers‚Äù each time a random function is called.\nNote that is if you want to get exactly the same random result, set.seed() needs to be run right before the call to random function, every time.\nIt is important so that you can reproduce the same random sample every time you knit your work.\nThere might be different results across computers/platforms as they might be using different pseudo-random number generators. The most important thing is for your code to be consistent.\n\n\n\nTraining and test sets\n\n\n\nSolution\n\n\n# Set the random number seed\nset.seed(8)\n\n# Split the cars data into 80% / 20%\n# Ensure that the sub-samples are similar with respect to mpg\ncars_split &lt;- initial_split(cars, strata = mpg, prop = 0.8)\n\n# Check it out\ncars_split\n## &lt;Training/Testing/Total&gt;\n## &lt;312/80/392&gt;\n\n# Get the training data from the split\ncars_train &lt;- cars_split %&gt;% \n  training()\n\n# Get the testing data from the split\ncars_test &lt;- cars_split %&gt;% \n  testing()\n\n# The original data has 392 cars\nnrow(cars)\n## [1] 392\n\n# How many cars are in cars_train?\nnrow(cars_train)\n## [1] 312\n\n# How many cars are in cars_test?\nnrow(cars_test)\n## [1] 80\n\n\n\n\nReflect on the above code\n\n\n\nSolution\n\n\nSuppose, for example, the training cars all had higher mpg than the test cars. Then the training model likely would not perform well on the test cars, thus we‚Äôd get an overly pessimistic measure of model quality.\nIf the cars are ordered in some way (eg: from biggest to smallest) then our training and testing samples would have systematically different properties.\n\n\n\n\nBuild the training model\n\n\n\nSolution\n\n\n# STEP 1: model specification\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# STEP 2: model estimation using the training data\n# Construct the 19th order polynomial model using the TRAINING data\nmodel_19_train &lt;- lm_spec %&gt;% \n  fit(mpg ~ poly(horsepower, 19), data = cars_train)\n\n\n\n\nEvaluate the training model\n\n\n\nSolution\n\n\n# How well does the training model predict the training data?\n# Calculate the training (in-sample) MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_train) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        2.99\n\n# How well does the training model predict the test data?\n# Calculate the test MAE\nmodel_19_train %&gt;% \n  augment(new_data = cars_test) %&gt;% \n  mae(truth = mpg, estimate = .pred)\n## # A tibble: 1 √ó 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 mae     standard        6.59\n\n\n\n\nPunchline\n\n\n\nSolution\n\n\nthe training errors are smaller\n\nthe test MAE is much larger than the training MAE\nthe 19th order polynomial\n\nthe quadratic\n\nthe quadratic\n\nCode for the curious\nI wrote a function calculate_MAE() to automate the calculations in the table. If you‚Äôre curious, pick through this code!\n\n# Write function to calculate MAEs\ncalculate_MAE &lt;- function(poly_order){\n  # Construct a training model\n  model &lt;- lm_spec %&gt;% \n    fit(mpg ~ poly(horsepower, poly_order), cars_train)\n  \n  # Calculate the training MAE\n  train_it &lt;- model %&gt;% \n    augment(new_data = cars_train) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Calculate the testing MAE\n  test_it &lt;- model %&gt;% \n    augment(new_data = cars_test) %&gt;% \n    mae(truth = mpg, estimate = .pred)\n      \n  # Return the results\n  return(data.frame(train_MAE = train_it$.estimate, test_MAE = test_it$.estimate))\n}\n    \n# Calculate training and testing MSEs\ncalculate_MAE(poly_order = 1)\n##   train_MAE test_MAE\n## 1  3.779331 4.004333\ncalculate_MAE(poly_order = 2)\n##   train_MAE test_MAE\n## 1  3.199882 3.487022\ncalculate_MAE(poly_order = 19)\n##   train_MAE test_MAE\n## 1  2.989305 6.592341\n\n\n# For those of you interested in trying all orders...\n\nresults &lt;- purrr::map_df(1:19,calculate_MAE) %&gt;% \n  mutate(order = 1:19) %&gt;%\n  pivot_longer(cols=1:2,names_to='Metric',values_to = 'MAE') \n\nresults %&gt;%\n  ggplot(aes(x = order, y = MAE, color = Metric)) + \n  geom_line() + \n  geom_point(data = results %&gt;% filter(Metric == 'test_MAE') %&gt;% slice_min(MAE)) + \n  geom_point(data = results %&gt;% filter(Metric == 'train_MAE') %&gt;% slice_min(MAE))\n\n\n\n\n\n\n\n\n\n\n\nFinal reflection\n\n\n\nSolution\n\nThis will be discussed in the next video!\n \n\n\n\nSTAT 155 REVIEW: data drill\n\n\n\nSolution\n\n\n# a. One of many options\nggplot(cars, aes(x = horsepower, y = mpg, color = year)) + \n  geom_point()\n\n\n\n\n\n\n\n\n# b\ncars %&gt;% \n  summarize(mean(mpg))\n##   mean(mpg)\n## 1  23.44592\n\n# c\ncars %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_mpg = mean(mpg))\n## # A tibble: 13 √ó 2\n##     year mean_mpg\n##    &lt;dbl&gt;    &lt;dbl&gt;\n##  1    70     17.7\n##  2    71     21.1\n##  3    72     18.7\n##  4    73     17.1\n##  5    74     22.8\n##  6    75     20.3\n##  7    76     21.6\n##  8    77     23.4\n##  9    78     24.1\n## 10    79     25.1\n## 11    80     33.8\n## 12    81     30.2\n## 13    82     32\n\n# d\ncars %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_mpg = mean(mpg)) %&gt;% \n  ggplot(aes(y = mean_mpg, x = year)) + \n  geom_point()",
    "crumbs": [
      "Overfitting"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html",
    "href": "activities/L05-model-selection.html",
    "title": "Model Selection",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#context",
    "href": "activities/L05-model-selection.html#context",
    "title": "Model Selection",
    "section": "Context",
    "text": "Context\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\ntask = regression\n\\(y\\) is quantitative\nmodel = linear regression\nWe‚Äôll assume that the relationship between \\(y\\) and (\\(x_1, x_2, ..., x_p\\)) can be represented by\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\varepsilon\\]",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#inferential-v.-predictive-models",
    "href": "activities/L05-model-selection.html#inferential-v.-predictive-models",
    "title": "Model Selection",
    "section": "Inferential v. Predictive Models",
    "text": "Inferential v. Predictive Models\nIn model building, the decision of which predictors to use depends upon our goal.\nInferential models\n\nGoal: Explore & test hypotheses about a specific relationship.\nPredictors: Defined by the goal.\nExample: An economist wants to understand how salaries (\\(y\\)) vary by age (\\(x_1\\)) while controlling for education level (\\(x_2\\)).\n\n\n\nPredictive models\n\n\nGoal: Produce the ‚Äúbest‚Äù possible predictions of \\(y\\).\nPredictors: Any combination of predictors that help us meet this goal.\nExample: A mapping app wants to provide users with quality estimates of arrival time (\\(y\\)) utilizing any useful predictors (eg: time of day, distance, route, speed limit, weather, day of week, traffic radar‚Ä¶)",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#model-selection-goals",
    "href": "activities/L05-model-selection.html#model-selection-goals",
    "title": "Model Selection",
    "section": "Model Selection Goals",
    "text": "Model Selection Goals\nModel selection algorithms can help us build a predictive model of \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\nThere are 3 general approaches to this task:\n\n\nVariable selection (today)\nIdentify a subset of predictors to use in our model of \\(y\\).\nShrinkage / regularization (next class)\nShrink / regularize the coefficients of all predictors toward or to 0.\nDimension reduction (later in the semester)\nCombine the predictors into a smaller set of new predictors.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#instructions",
    "href": "activities/L05-model-selection.html#instructions",
    "title": "Model Selection",
    "section": "Instructions",
    "text": "Instructions\nAs a group, you‚Äôll design a variable selection algorithm to pick which predictors to use in a predictive model of height. Specifically, you will:\n\ncome up with one algorithm (5 mins)\n\nNOTE: This will NOT be perfect! Our goals are to:\n\nHave fun and work together!\nTap into your intuition for key questions and challenges in variable selection.\nDeepen your understanding of ‚Äúalgorithms‚Äù and ‚Äútuning parameters‚Äù by designing and communicating your own.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#questions",
    "href": "activities/L05-model-selection.html#questions",
    "title": "Model Selection",
    "section": "Questions",
    "text": "Questions\nLet‚Äôs build a predictive model of height in inches using one or more of 12 possible predictors. Other than age and weight, these are circumferences measured in cm.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Load data\nhumans &lt;- read.csv(\"https://mac-stat.github.io/data/bodyfat1.csv\")\nnames(humans)\n##  [1] \"age\"     \"weight\"  \"neck\"    \"chest\"   \"abdomen\" \"hip\"     \"thigh\"  \n##  [8] \"knee\"    \"ankle\"   \"biceps\"  \"forearm\" \"wrist\"   \"height\"\n\n\n\nA heat map displays correlations for each pair of variables in our dataset. Not only is height correlated with multiple predictors, the predictors are correlated with one another (mulicollinear)! We don‚Äôt need all of them in our model.\n\n\nCode\n# Get the correlation matrix\nlibrary(reshape2)\ncor_matrix &lt;- cor(humans)\ncor_matrix[lower.tri(cor_matrix)] &lt;- NA\ncor_matrix &lt;- cor_matrix %&gt;% \n  melt() %&gt;% \n  na.omit() %&gt;% \n  rename(correlation = value)\n\n# Visualize the correlation for each pair of variables\nggplot(cor_matrix, aes(x = Var1, y = Var2, fill = correlation)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(\n    low = \"blue\", high = \"red\", mid = \"white\", \n    midpoint = 0, limit = c(-1,1)) +\n  labs(x = \"\", y = \"\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\nDesign your own algorithm (5 minutes)\n- Do not use any materials from outside this class. - Document your algorithm in words (not code). - Your algorithm must: - be clear to other humans - be clear to a machine (cannot utilize context) - lead to a single model that uses 0-12 of our predictors - define and provide directions for selecting any tuning parameters",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-1-best-subset-selection",
    "href": "activities/L05-model-selection.html#algorithm-1-best-subset-selection",
    "title": "Model Selection",
    "section": "Algorithm 1: Best Subset Selection",
    "text": "Algorithm 1: Best Subset Selection\n\n\nBuild all \\(2^p\\) possible models that use any combination of the available predictors \\((x_1, x_2,..., x_p)\\).\n\nIdentify the best model with respect to some chosen metric (eg: CV MAE) and context.\n\n\nSuppose we used this algorithm for our height model with 12 possible predictors: what‚Äôs the main drawback?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-2-backward-stepwise-selection",
    "href": "activities/L05-model-selection.html#algorithm-2-backward-stepwise-selection",
    "title": "Model Selection",
    "section": "Algorithm 2: Backward Stepwise Selection",
    "text": "Algorithm 2: Backward Stepwise Selection\n\n\nBuild a model with all \\(p\\) possible predictors, \\((x_1, x_2,..., x_p)\\).\n\nRepeat the following until only 1 predictor remains in the model:\n\nRemove the 1 predictor with the biggest p-value.\nBuild a model with the remaining predictors.\n\n\nYou now have \\(p\\) competing models: one with all \\(p\\) predictors, one with \\(p-1\\) predictors, ‚Ä¶, and one with 1 predictor. Identify the ‚Äúbest‚Äù model with respect to some metric (eg: CV MAE) and context.\n\n\n\nLet‚Äôs try out the first few steps!\n\n# Load packages and data\nlibrary(tidyverse)\nlibrary(tidymodels)\nhumans &lt;- read.csv(\"https://mac-stat.github.io/data/bodyfat1.csv\")\n\n\n# STEP 1: model specifications\nlm_spec &lt;- linear_reg() %&gt;% \n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n\n# STEP 2: model estimate (using all 12 predictors to start)\n# Pick apart this code and make it easier to identify the least \"significant\" predictor!!!\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist, \n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\n# 11 predictors (tweak the code)\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\n# 10 predictors (tweak the code)\nlm_spec %&gt;% \n  fit(height ~ age + weight + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4))\n\n\nBelow is the complete model sequence along with 10-fold CV MAE for each model (using set.seed(253)).\n\n\n\npred\nCV MAE\npredictor list\n\n\n\n\n12\n5.728\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee, neck, biceps\n\n\n11\n5.523\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee, neck\n\n\n10\n5.413\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist, knee\n\n\n9\n5.368\nweight, hip, forearm, thigh, chest, abdomen, age, ankle, wrist\n\n\n8\n5.047\nweight, hip, forearm, thigh, chest, abdomen, age, ankle\n\n\n7\n5.013\nweight, hip, forearm, thigh, chest, abdomen, age\n\n\n6\n4.684\nweight, hip, forearm, thigh, chest, abdomen\n\n\n5\n4.460\nweight, hip, forearm, thigh, chest\n\n\n4\n4.386\nweight, hip, forearm, thigh\n\n\n3\n4.091\nweight, hip, forearm\n\n\n2\n3.733\nweight, hip\n\n\n1\n3.658\nweight\n\n\n\n\n\nDISCUSS at your tables: In Groups\n\n(Review) Interpret the CV MAE for the model of height by weight alone.\nIs this algorithm more or less computationally expensive than the best subset algorithm?\nThe predictors neck and wrist, in that order, are the most strongly correlated with height. Where do these appear in the backward sequence and what does this mean?\n\n\ncor(humans)[,'height'] %&gt;% \n  sort()\n##       thigh         hip         age     abdomen        knee       chest \n## -0.11301249 -0.10648937 -0.05853538 -0.02173587  0.02345904  0.05838830 \n##      biceps       ankle      weight     forearm       wrist        neck \n##  0.07441696  0.07920867  0.11228791  0.16968040  0.28967468  0.29147610 \n##      height \n##  1.00000000\n\n\nWe deleted predictors one at a time. Why is this better than deleting a collection of multiple predictors at the same time (eg: kicking out all predictors with p-value &gt; 0.1)?\n\n\n\n\n\nWe have to pick just 1 of the 12 models as our final model. That is, we have to pick a value for our tuning parameter, the number of predictors.\nIt helps to plot the CV MAE for each model in the sequence.\nHere‚Äôs what we saw above:\n\n\nCode\ndata.frame(\n    predictors = c(12:1), \n    mae = c(5.728, 5.523, 5.413, 5.368, 5.047, 5.013, 4.684, 4.460, 4.386, 4.091, 3.733, 3.658)) %&gt;% \n  ggplot(aes(x = predictors, y = mae)) + \n    geom_point() + \n    geom_line() + \n    scale_x_continuous(breaks = c(1:12))\n\n\n\n\n\n\n\n\n\nDISCUSS at your tables: In Groups\n\nWhich model do you pick?!?\nIn the odd ‚ÄúGoldilocks‚Äù fairy tale, a kid comes upon a bear den ‚Äì the first bear‚Äôs bed is too hard, the second bear‚Äôs is too soft, and the third bear‚Äôs is just right. The second plot, below, illustrates a goldilocks problem in tuning the number of predictors in our backward stepwise model. Explain.\n\n\n\nWhen the number of predictors is too small, the MAE increases because the model is too‚Ä¶.\nWhen the number of predictors is too large, the MAE increases because the model is too‚Ä¶.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#algorithm-3-forward-stepwise-selection",
    "href": "activities/L05-model-selection.html#algorithm-3-forward-stepwise-selection",
    "title": "Model Selection",
    "section": "Algorithm 3: Forward Stepwise Selection",
    "text": "Algorithm 3: Forward Stepwise Selection\nDISCUSS at your tables: In Groups\n\nHow do you think this works?\nIs it more or less computationally expensive than backward stepwise?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#machine-learning-vs-human-learning",
    "href": "activities/L05-model-selection.html#machine-learning-vs-human-learning",
    "title": "Model Selection",
    "section": "Machine Learning vs Human Learning",
    "text": "Machine Learning vs Human Learning\nWhen tuning or finalizing a model building algorithm, we (humans!) have our own choices to make. For one, we need to decide what we prefer:\n\na model with the lowest prediction errors; or\na more parsimonious model: one with slightly higher prediction errors but fewer predictors\n\nIn deciding, here are some human considerations:\n\ngoal: How will the model be used? Should it be easy for humans to interpret and apply?\ncost: How many resources (time, money, computer memory, etc) do the model and data needed require?\nimpact: What are the consequences of a bad prediction?\n\n\n\nFor each scenario below, which model would you pick: (1) the model with the lowest prediction errors; or (2) a parsimonious model with slightly worse predictions?\n\nGoogle asks us to re-build their search algorithm.\nA small non-profit hires us to help them build a predictive model of the donation dollars they‚Äôll receive throughout the year.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#warning",
    "href": "activities/L05-model-selection.html#warning",
    "title": "Model Selection",
    "section": "WARNING",
    "text": "WARNING\nVariable selection algorithms are a nice, intuitive place to start our discussion of model selection techniques.\nBUT we will not use them.\nThey are frowned upon in the broader ML community, so much so that tidymodels doesn‚Äôt even implement them! Why?\n\nBest subset selection is computationally expensive.\n\nStepwise selection methods (forward and backward):\n\nAre greedy ‚Äì they make locally optimal decisions, thus often missing the globally optimal model\nOverestimate the significance of included predictors, thus shouldn‚Äôt be used for inference\n\nThis Stack Exchange discussion shows the results of a simulation study that helps illustrate this phenomenon.\n\nCan produce odd combinations of predictors\n\nForward: a new predictor may render previously included predictors non-significant)\nBackward: sensible predictors can be kicked out early (like the neck and wrist issue in our height model in Example 3)",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#instructions-1",
    "href": "activities/L05-model-selection.html#instructions-1",
    "title": "Model Selection",
    "section": "Instructions",
    "text": "Instructions\n\nGoal: become familiar with new code structures (recipes and workflows)\nAsk me questions as I move around the room.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#questions-1",
    "href": "activities/L05-model-selection.html#questions-1",
    "title": "Model Selection",
    "section": "Questions",
    "text": "Questions\nThe video for today introduced the concepts of recipes and workflows in the tidymodels framework. These concepts will become important to our new modeling algorithms. Though they aren‚Äôt necessary to linear regression models, let‚Äôs explore them in this familiar setting.\nRun through the following discussion and code one step at a time. Take note of the general process, concepts, and questions you have.\n\n\nSTEP 1: model specification\nThis specifies the structure or general modeling algorithm we plan to use.\nIt does not specify anything about the variables of interest or our data.\n\nlm_spec &lt;- linear_reg() %&gt;%\n  set_mode(\"regression\") %&gt;% \n  set_engine(\"lm\")\n\n# Check it out\nlm_spec\n\n\n\nSTEP 2: recipe specification\nJust as a cooking recipe specifies the ingredients and how to prepare them, a tidymodels recipe specifies:\n\nthe variables in our relationship of interest (the ingredients)\nhow to pre-process or wrangle these variables (how to prepare the ingredients)\nthe data we‚Äôll use to explore these variables (where to find the ingredients)\n\nIt does not specify anything about the model structure we‚Äôll use to explore this relationship.\n\n# A simple recipe with NO pre-processing\ndata_recipe &lt;- recipe(height ~ wrist + ankle, data = humans)\n\n# Check it out\ndata_recipe # Not shpowing output in Bill's RStudio!\nhead(data_recipe) # Check the third output!\n\n\n\nSTEP 3: workflow creation (model + recipe)\nThis specifies the general workflow of our modeling process, including our model structure and our variable recipe.\n\nmodel_workflow &lt;- workflow() %&gt;%\n  add_recipe(data_recipe) %&gt;%\n  add_model(lm_spec)\n\n# Check it out\nmodel_workflow # 0 Recipe Steps- No pre-processing steps\n\n\n\nSTEP 4: Model estimation\nThis step estimates or fits our model of interest using our entire sample data.\nThe model (lm_spec) and variable details (here just height ~ wrist + ankle) are specified in the workflow, so we do not need to give that information again!\n\nmy_model &lt;- model_workflow %&gt;% \n  fit(data = humans)\n\n# Check it out\nmy_model\n\n\n\nSTEPS 5: Model evaluation\nTo get in-sample metrics, use my_model like normal.\n\n# example: calculate in-sample R^2\nmy_model %&gt;% \n  glance()\n\n# example: calculate in-sample MAE\nmy_model %&gt;%\n  augment(new_data = humans) %&gt;% # notice what data we're plugging in here!\n  mae(truth = height, estimate = .pred)\n\nTo get CV metrics, pass the workflow to fit_resamples along with information about how to randomly create folds.\n\n# conduct 10-fold CV, calculate R^2 on each test fold\nset.seed(253) # review: what is this line doing? why do we need it? \nmy_model_cv &lt;- model_workflow %&gt;% \n  fit_resamples(resamples = vfold_cv(humans, v = 10), # \"v\" is our \"k\" \n                metrics = metric_set(rsq)) # replace rsq with the metric of your choice!\n\n# Check it out\nmy_model_cv\n\nThen, proceed as usual‚Ä¶\n\n# get a summary of the CV metrics across all folds\nmy_model_cv %&gt;%\n  collect_metrics()\n## Error: object 'my_model_cv' not found\n\n# get the metrics for each fold\nmy_model_cv %&gt;%\n  unnest(.metrics)\n## Error: object 'my_model_cv' not found",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#collaborative-learning",
    "href": "activities/L05-model-selection.html#collaborative-learning",
    "title": "Model Selection",
    "section": "Collaborative Learning",
    "text": "Collaborative Learning\nTake 5 minutes to free-write in response to the following prompts, reflecting upon your strengths and areas for growth with respect to collaboration.\nIn Unit 1:\n\nHow actively did you contribute to group discussions?\nHow actively did you include ALL other group members in discussion?\nIn what ways did you (or did you not) help create a space where others feel comfortable making mistakes & sharing their ideas?\n\nMore generally:\n\nWhat has/hasn‚Äôt worked well for you when it comes to working on in-class exercises in small groups (in this class or others)?\nWhat would you like to try, or avoid, in this next unit?",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#exercises-part-1-1",
    "href": "activities/L05-model-selection.html#exercises-part-1-1",
    "title": "Model Selection",
    "section": "Exercises: Part 1",
    "text": "Exercises: Part 1\nDesign your own algorithm.\n\n\nSolution\n\nThere is no ‚Äúcorrect‚Äù answer to this question ‚Äî we just want to see what you can come up with! With that said, a ‚Äúgood‚Äù algorithm should:\n\nbe clear to other humans\nbe clear to a machine (eg cannot utilize context)\nlead to a single model that uses 0‚Äì12 of our predictors\ndefine and provide directions for selecting any tuning parameters",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#notes-discussion-variable-selection-1",
    "href": "activities/L05-model-selection.html#notes-discussion-variable-selection-1",
    "title": "Model Selection",
    "section": "Notes & Discussion: Variable Selection",
    "text": "Notes & Discussion: Variable Selection\nBest Subset Selection Drawback\n\n\nSolution\n\nIt‚Äôs computationally expensive. For our humans example, we‚Äôd need to build 4096 models:\n\n2^12\n## [1] 4096\n\n\n\nBackward Stepwise Selection Implementation\n\n\nSolution\n\n\n# All 12 predictors\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + biceps + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;%  # use tidy to get p-values for each coefficient\n  filter(term != \"(Intercept)\") %&gt;% # exclude the intercept\n  mutate(p.value = round(p.value, 4)) %&gt;% # round the p-values for easier viewing\n  arrange(desc(p.value)) # added this line to arrange from largest to smallest p-value\n## # A tibble: 12 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 biceps   -0.0808     0.746    -0.108  0.915 \n##  2 neck      0.139      1.17      0.119  0.906 \n##  3 knee      0.151      0.941     0.160  0.874 \n##  4 wrist     0.836      2.32      0.361  0.721 \n##  5 ankle    -0.888      1.28     -0.693  0.494 \n##  6 abdomen   0.283      0.354     0.798  0.432 \n##  7 age      -0.112      0.132    -0.847  0.405 \n##  8 chest    -0.459      0.473    -0.971  0.340 \n##  9 forearm   2.25       1.80      1.25   0.223 \n## 10 weight    0.379      0.213     1.78   0.0864\n## 11 hip      -0.921      0.510    -1.81   0.0822\n## 12 thigh    -1.24       0.646    -1.92   0.066\n\n\n# 11 predictors (got rid of biceps)\nlm_spec %&gt;% \n  fit(height ~ age + weight + neck + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4)) %&gt;% \n  arrange(desc(p.value))\n## # A tibble: 11 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 neck       0.161     1.14      0.142  0.888 \n##  2 knee       0.180     0.886     0.203  0.841 \n##  3 wrist      0.907     2.18      0.416  0.681 \n##  4 ankle     -0.878     1.26     -0.699  0.490 \n##  5 abdomen    0.281     0.348     0.809  0.425 \n##  6 age       -0.111     0.130    -0.858  0.398 \n##  7 chest     -0.453     0.461    -0.982  0.334 \n##  8 forearm    2.17      1.62      1.34   0.192 \n##  9 hip       -0.902     0.470    -1.92   0.0652\n## 10 weight     0.369     0.190     1.94   0.0623\n## 11 thigh     -1.26      0.602    -2.09   0.0454\n\n\n# 10 predictors (got rid of neck)\nlm_spec %&gt;% \n  fit(height ~ age + weight  + chest + abdomen + hip + thigh + knee + ankle + forearm + wrist,\n      data = humans) %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% \n  mutate(p.value = round(p.value, 4)) %&gt;% \n  arrange(desc(p.value))\n## # A tibble: 10 √ó 5\n##    term    estimate std.error statistic p.value\n##    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 knee       0.166     0.866     0.191  0.850 \n##  2 wrist      0.985     2.07      0.475  0.639 \n##  3 ankle     -0.884     1.23     -0.716  0.480 \n##  4 age       -0.111     0.127    -0.869  0.392 \n##  5 abdomen    0.298     0.322     0.924  0.363 \n##  6 chest     -0.460     0.451    -1.02   0.316 \n##  7 forearm    2.29      1.37      1.66   0.107 \n##  8 weight     0.377     0.179     2.11   0.0435\n##  9 thigh     -1.26      0.591    -2.14   0.0409\n## 10 hip       -0.931     0.416    -2.24   0.0331\n\nEtc.\n\n\nBackward Stepwise Selection Step-by-Step Results\n\n\nSolution\n\nIf you‚Äôre curious, here‚Äôs some code to implement all steps of the backward stepwise selection algorithm:\n\n\nCode\n# setup\npredictors &lt;- c(\"age\", \"weight\", \"neck\", \"chest\", \"abdomen\", \"hip\", \"thigh\", \"knee\", \"ankle\", \"biceps\", \"forearm\", \"wrist\")\np &lt;- length(predictors)\nkick_out &lt;- rep(0, p)\ncvs &lt;- rep(0, p)\n\n# loop through predictors\nfor(i in 1:12){\n  # fit model\n  my_model &lt;- lm_spec %&gt;% \n    fit(as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))), \n        data = humans) %&gt;% \n    tidy() %&gt;% \n    filter(term != \"(Intercept)\") %&gt;% \n    arrange(desc(p.value))\n  \n  # use 10-fold CV to get MAE for model\n  set.seed(253)\n  cv_process &lt;- lm_spec %&gt;% \n      fit_resamples(\n        as.formula(paste(\"height ~ \", paste(predictors, collapse = \"+\"))),\n        resamples = vfold_cv(humans, v = 10), \n        metrics = metric_set(mae)\n      ) %&gt;% \n      collect_metrics()\n  \n  # get name of worst variable (biggest p-value)\n  worst &lt;- as.data.frame(my_model)[1,1]\n  kick_out[i] &lt;- worst\n  \n  # get rid of worst variable from predictor list\n  predictors &lt;- predictors[predictors != worst]\n  \n  # save CV MAE for this model\n  cvs[i] &lt;- as.data.frame(cv_process)$mean\n}\n\nkick_out\n##  [1] \"biceps\"  \"neck\"    \"knee\"    \"wrist\"   \"ankle\"   \"age\"     \"abdomen\"\n##  [8] \"chest\"   \"thigh\"   \"forearm\" \"hip\"     \"weight\"\ncvs\n##  [1] 5.727898 5.522730 5.413292 5.368143 5.047014 5.013322 4.684182 4.460353\n##  [9] 4.385650 4.090791 3.733412 3.658251\n\n\n\nUsing a linear model with only weight to predict height, our prediction error would be on average 3.58 inches off from the truth on new data. In other words, we estimate that this model can predict a new person‚Äôs height within, on average, 3.58 inches.\nLess. We only have to build 12 models.\nBoth neck and wrist are kicked out early! The 1-predictor model produced by this algorithm isn‚Äôt necessarily the best 1-predictor model (same for any number of predictors). Backward stepwise selection is a greedy algorithm!\nThe value of the coefficient (and thus the p-value) is dependent on the other variables in the model as we are accounting for or conditioning on them.\n\n\n\nBackward Stepwise Selection Final Model\n\n\nSolution\n\n\nBased on our data, I think the model with 1 predictor seems pretty reasonable! It‚Äôs simple and has the smallest CV MAE. If you‚Äôre worried that model is too simple, the model with 2 predictors also has a similarly small MAE.\nIf I were looking at the other MAE plot, though, I might pick a model with 1 (the simplest), 2 (still simple, but better MAE than 1 predictor), or 5 predictors (the model with the best CV MAE).\nToo few predictors: model is too simple. Too many predictors: model is too overfit.\n\n\n\nForward Stepwise Selection\n\n\nSolution\n\n\nStart with 0 predictors. Fit all possible models with 1 predictor. Add the predictor with the smallest p-value. To this model, add a second predictor with the smallest p-value. Continue until all predictors are in the model. (More details in ISLR Section 6.1.2.)\nMore. For 12 predictors, we‚Äôd have to build 12 models in step 1, 11 models in step 2, etc. Thus 12 + 11 + ‚Ä¶ + 1 = 78 models total.\n\n\n\nMachine Learning vs Human Learning\n\n\nSolution\n\n\n1\n2",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L05-model-selection.html#exercises-part-2-1",
    "href": "activities/L05-model-selection.html#exercises-part-2-1",
    "title": "Model Selection",
    "section": "Exercises: Part 2",
    "text": "Exercises: Part 2\nNo solutions for this part.",
    "crumbs": [
      "Model Selection"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html",
    "href": "activities/L07-nonparametric.html",
    "title": "Non-Parametric Models",
    "section": "",
    "text": "You can download the .qmd file for this activity here and open in R-studio. The rendered version is posted in the course website (Activities tab). I often experiment with the class activities (and see it in live!) and make updates, but I always post the final version before class starts. To be sure you have the most up-to-date copy, please download it once you‚Äôve settled in before class begins.",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#context",
    "href": "activities/L07-nonparametric.html#context",
    "title": "Non-Parametric Models",
    "section": "Context",
    "text": "Context\n\n\nworld = supervised learning\nWe want to model some output variable \\(y\\) using a set of potential predictors (\\(x_1, x_2, ..., x_p\\)).\ntask = regression\n\\(y\\) is quantitative\nmodel = nonparametric regression???",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#goal",
    "href": "activities/L07-nonparametric.html#goal",
    "title": "Non-Parametric Models",
    "section": "Goal",
    "text": "Goal\nJust as in Unit 2, Unit 3 will focus on model building, but a different aspect:\n\nUnit 2: how do we handle / select predictors for our predictive model of \\(y\\)?\nUnit 3: how do we handle situations in which linear regression models are too ‚Äúrigid‚Äù to capture the relationship of \\(y\\) vs \\(x\\)?",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#genai",
    "href": "activities/L07-nonparametric.html#genai",
    "title": "Non-Parametric Models",
    "section": "GenAI",
    "text": "GenAI\n\nFor most homework assignments, it is okay to use GenAI as a resource. However‚Ä¶\nI strongly prefer that you use existing course materials first! Why?\n\nThis ensures we are all using the same terminology and coding syntax (which I have very intentionally selected).\nIt saves resources (GenAI has a large environmental impact!). You should be able to answer all HW questions using resources I‚Äôve already provided.\nHomework is designed to give you opportunities to practice and synthesize key course concepts. Doing the synthesizing yourself (by reviewing course materials, making connections between concepts, etc.) is an important part of learning the material!\n\nFor code, specifically, it is more important to me that you understand what code is doing rather than being able to write it yourself. It‚Äôs easy to use ChatGPT for the latter without ever figuring out the former!\n\nFYI: Quizzes will include questions about code we have seen in class. You‚Äôll need to recognize and explain what it is doing (and why).",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#feedback",
    "href": "activities/L07-nonparametric.html#feedback",
    "title": "Non-Parametric Models",
    "section": "Feedback:",
    "text": "Feedback:\n\nYou will receive individual feedback on (almost all) questions and an overall score of PASS / ATTEMPT / UNABLE TO ASSESS\nYou will access this feedback via email\nIf your overall score is PASS this means:\n\nyou demonstrated effort on all (or almost all) questions\nmost of your answers were correct or almost correct\nalthough you have PASSed the assignment, there likely is still room for improvement! make sure you review your feedback for all questions (even those marked as correct) and stop by office hours with any questions\n\nThere will be opportunities to revise your answers to some homework questions incorporated into the learning reflections at the end of each major topic.\n\ntake note AFTER THE CLASS of which questions/topics need revision!",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#motivating-example",
    "href": "activities/L07-nonparametric.html#motivating-example",
    "title": "Non-Parametric Models",
    "section": "Motivating Example",
    "text": "Motivating Example\nLet‚Äôs build a predictive model of blood glucose level in mg/dl by time in hours (\\(x\\)) since eating a high carbohydrate meal.\nConsider 3 linear regression models of \\(y\\), none of which appear to be very good:\n\\[\\begin{array}{ll}\n\\text{linear:} &  y = f(x) + \\varepsilon = \\beta_0 + \\beta_1 x + \\varepsilon \\\\\n\\text{quadratic:} & y = f(x) + \\varepsilon = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\varepsilon \\\\\n\\text{6th order polynomial:} & y = f(x) + \\varepsilon = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\beta_4 x^4 + \\beta_5 x^5 +  \\beta_6 x^6 + \\varepsilon \\\\\n\\end{array}\\]\n\n## # A tibble: 14 √ó 2\n##    glucose   time\n##      &lt;dbl&gt;  &lt;dbl&gt;\n##  1    3.49 -0.167\n##  2    3.46  0    \n##  3    4.84  0.333\n##  4    6.24  0.667\n##  5    6.84  1    \n##  6    5.55  1.33 \n##  7    4.29  1.67 \n##  8    3.97  2    \n##  9    4.05  2.5  \n## 10    3.99  3    \n## 11    3.54  3.5  \n## 12    3.46  4    \n## 13    3.54  4.5  \n## 14    3.62  5\n\n\n\n\n\n\n\n\n\nParametric vs Nonparametric\nThese parametric linear regression models assume (incorrectly) that we can represent glucose over time by the following formula for \\(f(x)\\) that depends upon parameters \\(\\beta_i\\):\n\\[y = f(x) + \\varepsilon = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_p x_p + \\varepsilon\\]\nNonparametric models do NOT assume a parametric form for the relationship between \\(y\\) and \\(x\\), \\(f(x)\\). Thus they are more flexible.",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-1-intuition",
    "href": "activities/L07-nonparametric.html#part-1-intuition",
    "title": "Non-Parametric Models",
    "section": "Part 1: Intuition",
    "text": "Part 1: Intuition\nIn Part 1, your task is to come up with a nonparametric algorithm to estimate \\(f(\\text{time})\\) in the equation \\[\\text{glucose} = f(\\text{time}) + \\epsilon\\]\n\n\n\nMake some nonparametric predictions\nWorking as a group, thinking nonparametrically, and utilizing the plot and data in the handout, predict glucose level after:\n\n1.5 hours\n4.25 hours\n\\(x\\) hours (i.e.¬†what‚Äôs your general prediction process at any time point \\(x\\)?)\n\n\n\n\n\nBuild a nonparametric algorithm\nWorking as a group:\n\nTranslate your prediction process into a formal algorithm, i.e.¬†step-by-step procedure or recipe, to predict glucose at any time point \\(x\\). THINK:\n\nDoes this depend upon any tuning parameters? For example, did your prediction process use any assumed ‚Äúthresholds‚Äù or quantities?\nIf so, represent this tuning parameter as ‚Äút‚Äù and write your algorithm using t (not a tuned value for t).\n\nOn the separate page provided, one person should summarize this algorithm and report the predictions you got using this algorithm.\n\n\n\n\n\nTest your algorithm\nExchange algorithms with another group.\n\nIs the other group‚Äôs algorithm similar to yours?\nUse their algorithm to predict glucose after 1.5 hours and 4.25 hours. Do your calculations match theirs? If not, what was unclear about their algorithm that led to the discrepancy?\n\n\n\n\n\nBuilding an algorithm as a class\n\nOn your sheet, sketch a predictive model of glucose by time that a ‚Äúgood‚Äù algorithm would produce.\nIn general, how would such an algorithm work? What would be its tuning parameter?",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-2-distance",
    "href": "activities/L07-nonparametric.html#part-2-distance",
    "title": "Non-Parametric Models",
    "section": "Part 2: Distance",
    "text": "Part 2: Distance\nCentral to nonparametric modeling is the concept of using data points within some local window or neighborhood.\nDefining a local window or neighborhood relies on the concept of distance.\nWith only one predictor, this was straightforward in our glucose example: the closest neighbors at time \\(x\\) are the data points observed at the closest time points.\n\nGOAL\nExplore the idea of distance when we have more predictors, and the data-preprocessing steps we have to take in order to implement this idea in practice.\n\n\n\nTwo measures of distance\nConsider data on 2 predictors for 2 students:\n\n\nstudent 1: 8 hours sleep Monday (\\(a_1\\)), 9 hours sleep Tuesday (\\(b_1\\))\nstudent 2: 7 hours sleep Monday (\\(a_2\\)), 11 hours sleep Tuesday (\\(b_2\\))\n\n\nCalculate the Manhattan distance between the 2 students.\n\n\\[|a_1 - a_2| + |b_1 - b_2|\\]\n\n# a\nabs(8 - 7) + abs(9 - 11)\n## [1] 3\n\n\n\n\n\n\n\n\n\n\n\nCalculate the Euclidean distance between the 2 students:\n\n\\[\\sqrt{(a_1 - a_2)^2 + (b_1 - b_2)^2}\\]\n\n# b\nsqrt((8 - 7)^2 + (9 - 11)^2)     \n## [1] 2.236068\n\n\n\n\n\n\n\n\n\n\nNOTE: We‚Äôll typically use Euclidean distance in our algorithms. But for the purposes of this activity, use Manhattan distance (just since it‚Äôs easier to calculate and gets at the same ideas).\n\n\n\nWho are my neighbors?\nConsider two more possible predictors of some student outcome variable \\(y\\):\n\n\n\\(x_1\\) = number of days old\n\\(x_2\\) = major division (humanities, fine arts, social science, or natural science)\n\nCalculate how many days old you are:\n\n# Record dates in year-month-day format\ntoday &lt;- today()\nbday  &lt;- as.Date(\"????-??-??\")\n    \n# Calculate difference\ndifftime(today, bday, units = \"days\")\n\nThen for each scenario, identify which of your group members is your nearest neighbor, as defined by Manhattan distance:\n\nUsing only \\(x_1\\).\nUsing only \\(x_2\\). And how are you measuring the distance between students‚Äô major divisions (categories not quantities)?!\nUsing both \\(x_1\\) and \\(x_2\\)\n\n\n\n\nMeasuring distance: 2 quantitative predictors\nConsider 2 more measures on another 3 students:\n\n\n\n\n\nDays Old\nDistance from Campus\n\n\n\n\nstudent 1\n7300 days\n0.1 hour\n\n\nstudent 2\n7304 days\n0.1 hour\n\n\nstudent 3\n7300 days\n3.1 hours\n\n\n\n\n\nContextually, not mathematically, do you think student 1 is more similar to student 2 or student 3?\nCalculate the mathematical Manhattan distance between: (1) students 1 and 2; and (2) students 1 and 3.\nDo your contextual and mathematical assessments match? If not, what led to this discrepancy?\n\n\n\n\nMeasuring distance: quantitative & categorical predictors\nLet‚Äôs repeat for another 3 students:\n\n\n\n\n\nMajor\nDays Old\n\n\n\n\nstudent 1\nSTAT\n7300 days\n\n\nstudent 2\nSTAT\n7302 days\n\n\nstudent 3\nGEOG\n7300 days\n\n\n\n\n\nContextually, do you think student 1 is more similar to student 2 or student 3?\nMathematically, calculate the Manhattan distance between: (1) students 1 and 2; and (2) students 1 and 3. NOTE: The distance between 2 different majors is 1.\nDo your contextual and mathematical assessments match? If not, what led to this discrepancy?",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-3-pre-processing-predictors",
    "href": "activities/L07-nonparametric.html#part-3-pre-processing-predictors",
    "title": "Non-Parametric Models",
    "section": "Part 3: Pre-processing predictors",
    "text": "Part 3: Pre-processing predictors\nIn nonparametric modeling, we don‚Äôt want our definitions of ‚Äúlocal windows‚Äù or ‚Äúneighbors‚Äù to be skewed by the scales and structures of our predictors.\nIt‚Äôs therefore important to create variable recipes which pre-process our predictors before feeding them into a nonparametric algorithm.\nLet‚Äôs explore this idea using the bikes data to model rides by temp, season, and breakdowns:\n\n# Load some packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Load the bikes data and do a little data cleaning\nset.seed(253)\nbikes &lt;- read.csv(\"https://mac-stat.github.io/data/bike_share.csv\") %&gt;% \n  rename(rides = riders_registered, temp = temp_feel) %&gt;% \n  mutate(temp = round(temp)) %&gt;% \n  mutate(breakdowns = sample(c(rep(0, 728), rep(1, 3)), 731, replace = FALSE)) %&gt;% \n  select(temp, season, breakdowns, rides)\nhead(bikes)\n##   temp season breakdowns rides\n## 1   65 winter          0   654\n## 2   64 winter          0   670\n## 3   49 winter          0  1229\n## 4   51 winter          0  1454\n## 5   53 winter          0  1518\n## 6   53 winter          0  1518\n\n\n\n\nStandardizing quantitative predictors\nLet‚Äôs standardize or normalize the 2 quantitative predictors, temp and breakdowns, to the same scale: centered at 0 with a standard deviation of 1. Run and reflect upon each chunk below:\n\n\n# Recipe with 1 preprocessing step\nrecipe_1 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_normalize(all_numeric_predictors())\n    \n# Check it out\nrecipe_1\n\n\n# Check out the first 3 rows of the pre-processed data\n# (Don't worry about the code. Normally we won't do this step.)\nrecipe_1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  head(3)\n## # A tibble: 3 √ó 4\n##     temp season breakdowns rides\n##    &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n## 1 -0.660 winter    -0.0642   654\n## 2 -0.728 winter    -0.0642   670\n## 3 -1.75  winter    -0.0642  1229\n\n\n# Compare to first 3 rows of original data\nbikes %&gt;% \n  head(3)\n##   temp season breakdowns rides\n## 1   65 winter          0   654\n## 2   64 winter          0   670\n## 3   49 winter          0  1229\n\nFollow-up questions & comments\n\nTake note of how the pre-processed data compares to the original. Confirm this standardized value ‚Äúby hand‚Äù using the mean and standard deviation in temp:\n\n\nbikes %&gt;% \n    summarize(mean(temp), sd(temp))\n    \n# Standardized temp: (observed - mean) / sd\n(___ - ___) / ___\n\n\nThe first day had a temp of 65 degrees and a standardized temp of -0.66, i.e.¬†65 degrees is 0.66 standard deviations below average.\n\n\n\n\nCreating ‚Äúdummy‚Äù variables for categorical predictors\nConsider the categorical season predictor: fall, winter, spring, summer. Since we can‚Äôt plug words into a mathematical formula, ML algorithms convert categorical predictors into ‚Äúdummy variables‚Äù, also known as indicator variables. (This is unfortunately the technical term, not something I‚Äôm making up.) Run and reflect upon each chunk below:\n\n\n# Recipe with 1 preprocessing step\nrecipe_2 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_dummy(all_nominal_predictors())\n\n\n# Check out 3 specific rows of the pre-processed data\n# (Don't worry about the code.)\nrecipe_2 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##    temp breakdowns rides season_spring season_summer season_winter\n##   &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1    53          0   674             0             0             1\n## 2    70          0   674             1             0             0\n## 3    68          0   655             0             0             0\n\n\n# Compare to the same 3 rows in the original data\nbikes %&gt;% \n  filter(rides %in% c(655, 674))\n##   temp season breakdowns rides\n## 1   53 winter          0   674\n## 2   70 spring          0   674\n## 3   68   fall          0   655\n\nFollow-up questions & comments\n\n3 of the 4 seasons show up in the pre-processed data as ‚Äúdummy variables‚Äù with 0/1 outcomes. Which season does not appear? This ‚Äúreference‚Äù category is also the one that wouldn‚Äôt appear in a table of model coefficients.\nHow is a winter day represented by the 3 dummy variables?\nHow is a fall day represented by the 3 dummy variables?\n\n\n\n\nCombining pre-processing steps\nWe can also do multiple pre-processing steps! In some cases, order matters. Compare the results of normalizing before creating dummy variables and vice versa:\n\n\n# step_normalize() before step_dummy()\nrecipe(rides ~ ., data = bikes) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##     temp breakdowns rides season_spring season_summer season_winter\n##    &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -1.48     -0.0642   674             0             0             1\n## 2 -0.320    -0.0642   674             1             0             0\n## 3 -0.456    -0.0642   655             0             0             0\n\n\n# step_dummy() before step_normalize()\nrecipe(rides ~ ., data = bikes) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##     temp breakdowns rides season_spring season_summer season_winter\n##    &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -1.48     -0.0642   674        -0.580        -0.588         1.74 \n## 2 -0.320    -0.0642   674         1.72         -0.588        -0.573\n## 3 -0.456    -0.0642   655        -0.580        -0.588        -0.573\n\nFollow-up questions / comments\n\nHow did the order of our 2 pre-processing steps impact the outcome?\nThe standardized dummy variables lose some contextual meaning. But, in general, negative values correspond to 0s (not that category), positive values correspond to 1s (in that category), and the further a value is from zero, the less common that category is. We‚Äôll observe in the future how this is advantageous when defining ‚Äúneighbors‚Äù.\n\n\n\n\n\n\nPAUSE\nThough our current focus is on nonparametric modeling, the concepts of standardizing and dummy variables are also important in parametric modeling.\n\n\n\nalgorithm\npre-processing step\nnecessary?\ndone automatically behind the R code?\n\n\n\n\nleast squares\nstandardizing\nno\nno (because it‚Äôs not necessary!)\n\n\n\ndummy variables\nyes\nyes\n\n\nLASSO\nstandardizing\nyes\nyes\n\n\n\ndummy variables\nyes\nno (we have to pre-process)\n\n\n\n\n\n\n\n\n\nLess common: Removing variables with ‚Äúnear-zero variance‚Äù\nNotice that on almost every day in our sample, there were 0 bike station breakdowns. Thus there is near-zero variability (nzv) in the breakdowns predictor:\n\n\nbikes %&gt;% \n  count(breakdowns)\n##   breakdowns   n\n## 1          0 728\n## 2          1   3\n\nThis extreme predictor could bias our model results ‚Äì the rare days with 1 breakdown might seem more important than they are, thus have undue influence. To this end, we can use step_nzv():\n\n# Recipe with 3 preprocessing steps\nrecipe_3 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors())\n\n\n# Check out the first 3 rows of the pre-processed data\n# (Don't worry about the code.)\nrecipe_3 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  head(3)\n## # A tibble: 3 √ó 5\n##     temp rides season_spring season_summer season_winter\n##    &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -0.660   654        -0.580        -0.588          1.74\n## 2 -0.728   670        -0.580        -0.588          1.74\n## 3 -1.75   1229        -0.580        -0.588          1.74\n\n\n# Compare to this to the first 3 rows in the original data\nbikes %&gt;% \n  head(3)\n##   temp season breakdowns rides\n## 1   65 winter          0   654\n## 2   64 winter          0   670\n## 3   49 winter          0  1229\n\nFollow-up questions\n\nWhat did step_nzv() do?!\nWe could move step_nzv() to the last step in our recipe. But what advantage is there to putting it first?\n\n\n\n\nThere‚Äôs lots more!\n\nThe 3 pre-processing steps above are among the most common. Many others exist and can be handy in specific situations. Run the code below to get a list of possibilities:\n\nls(\"package:recipes\")[startsWith(ls(\"package:recipes\"), \"step_\")]\n##  [1] \"step_arrange\"            \"step_bagimpute\"         \n##  [3] \"step_bin2factor\"         \"step_BoxCox\"            \n##  [5] \"step_bs\"                 \"step_center\"            \n##  [7] \"step_classdist\"          \"step_classdist_shrunken\"\n##  [9] \"step_corr\"               \"step_count\"             \n## [11] \"step_cut\"                \"step_date\"              \n## [13] \"step_depth\"              \"step_discretize\"        \n## [15] \"step_dummy\"              \"step_dummy_extract\"     \n## [17] \"step_dummy_multi_choice\" \"step_factor2string\"     \n## [19] \"step_filter\"             \"step_filter_missing\"    \n## [21] \"step_geodist\"            \"step_harmonic\"          \n## [23] \"step_holiday\"            \"step_hyperbolic\"        \n## [25] \"step_ica\"                \"step_impute_bag\"        \n## [27] \"step_impute_knn\"         \"step_impute_linear\"     \n## [29] \"step_impute_lower\"       \"step_impute_mean\"       \n## [31] \"step_impute_median\"      \"step_impute_mode\"       \n## [33] \"step_impute_roll\"        \"step_indicate_na\"       \n## [35] \"step_integer\"            \"step_interact\"          \n## [37] \"step_intercept\"          \"step_inverse\"           \n## [39] \"step_invlogit\"           \"step_isomap\"            \n## [41] \"step_knnimpute\"          \"step_kpca\"              \n## [43] \"step_kpca_poly\"          \"step_kpca_rbf\"          \n## [45] \"step_lag\"                \"step_lincomb\"           \n## [47] \"step_log\"                \"step_logit\"             \n## [49] \"step_lowerimpute\"        \"step_meanimpute\"        \n## [51] \"step_medianimpute\"       \"step_modeimpute\"        \n## [53] \"step_mutate\"             \"step_mutate_at\"         \n## [55] \"step_naomit\"             \"step_nnmf\"              \n## [57] \"step_nnmf_sparse\"        \"step_normalize\"         \n## [59] \"step_novel\"              \"step_ns\"                \n## [61] \"step_num2factor\"         \"step_nzv\"               \n## [63] \"step_ordinalscore\"       \"step_other\"             \n## [65] \"step_pca\"                \"step_percentile\"        \n## [67] \"step_pls\"                \"step_poly\"              \n## [69] \"step_poly_bernstein\"     \"step_profile\"           \n## [71] \"step_range\"              \"step_ratio\"             \n## [73] \"step_regex\"              \"step_relevel\"           \n## [75] \"step_relu\"               \"step_rename\"            \n## [77] \"step_rename_at\"          \"step_rm\"                \n## [79] \"step_rollimpute\"         \"step_sample\"            \n## [81] \"step_scale\"              \"step_select\"            \n## [83] \"step_shuffle\"            \"step_slice\"             \n## [85] \"step_spatialsign\"        \"step_spline_b\"          \n## [87] \"step_spline_convex\"      \"step_spline_monotone\"   \n## [89] \"step_spline_natural\"     \"step_spline_nonnegative\"\n## [91] \"step_sqrt\"               \"step_string2factor\"     \n## [93] \"step_time\"               \"step_unknown\"           \n## [95] \"step_unorder\"            \"step_window\"            \n## [97] \"step_YeoJohnson\"         \"step_zv\"",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-4-additional-exercises",
    "href": "activities/L07-nonparametric.html#part-4-additional-exercises",
    "title": "Non-Parametric Models",
    "section": "Part 4: Additional Exercises",
    "text": "Part 4: Additional Exercises\nIf you complete the above exercises in class, you should try the remaining exercises.\nOtherwise, you do not need to loop back ‚Äì these concepts will be covered in the videos for the next class.\n\n\n\nKNN\n\nNow that we have a sense of some themes (defining ‚Äúlocal‚Äù) and details (measuring ‚Äúdistance‚Äù) in nonparametric modeling, let‚Äôs explore a common nonparametric algorithm: K Nearest Neighbors (KNN). Let‚Äôs start with your intuition for how the KNN works, simply based on its name. On your paper, sketch what you anticipate the following models of the 14 glucose measurements to look like:\n\n\\(K = 1\\) nearest neighbors model\n\n\\(K = 14\\) nearest neighbors model\n\nNOTE: You might start by making predictions at each observed time point (eg: 0, 15 min, 30 min,‚Ä¶). Then think about what the predictions would be for times in between these observations (eg: 5 min).\n\n\n\n\n\n\n\n\n\n\n\n\nThinking like a machine learner\n\nUpon what tuning parameter does KNN depend?\nWhat‚Äôs the smallest value this tuning parameter can take? The biggest?\nSelecting a ‚Äúgood‚Äù tuning parameter is a goldilocks challenge:\n\nWhat happens when the tuning parameter is too small?\n\nToo big?",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-1-intuition-1",
    "href": "activities/L07-nonparametric.html#part-1-intuition-1",
    "title": "Non-Parametric Models",
    "section": "Part 1: Intuition",
    "text": "Part 1: Intuition\n\nMake some nonparametric predictions\n\n\n\nSolution\n\nWill vary by group.\n\n\n\nBuild a nonparametric algorithm\n\n\n\nSolution\n\nWill vary by group.\n\n\n\nTest your algorithm\n\n\n\nSolution\n\nWill vary by group.\n\n\n\n\n\nBuilding an algorithm as a class\n\n\n\nSolution\n\n\nsmooth curve that follows the general trend\ntuning parameter = size of the windows or neighborhoods. in general, we‚Äôll fit ‚Äúmodels‚Äù within smaller windows",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-2-distance-1",
    "href": "activities/L07-nonparametric.html#part-2-distance-1",
    "title": "Non-Parametric Models",
    "section": "Part 2: Distance",
    "text": "Part 2: Distance\n\nTwo measures of distance\n\n\n\nSolution\n\n\n# a\nabs(8 - 7) + abs(9 - 11)\n## [1] 3\n\n# b\nsqrt((8 - 7)^2 + (9 - 11)^2)\n## [1] 2.236068\n\n\n\n\nWho are my neighbors?\n\n\n\nSolution\n\nWill vary by group.\n\n\n\nMeasuring distance: 2 quantitative predictors\n\n\n\n\nSolution\n\n\nMy opinion: student 2. Being 4 days apart is more ‚Äúsimilar‚Äù than 2 students that live 3 hours apart.\nstudents 1 and 2: \\(|7300 - 7304| + |0.1 - 0.1| = 4\\), students 1 and 3: \\(|7300 - 7300| + |0.1 - 3.1| = 3\\)\nstudent 3. nope. the variables are on different scales.\n\n\n\n\nMeasuring distance: quantitative & categorical predictors\n\n\n\n\nSolution\n\n\nMy opinion: student 2. Being 2 days apart is more ‚Äúsimilar‚Äù than different majors.\nstudents 1 and 2: \\(|1 - 1| + |7300 - 7302| = 2\\), students 1 and 3: \\(|1 - 0| + |7300 - 7300| = 1\\)\nnope. the variables are on different scales.",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-3-pre-processing-predictors-1",
    "href": "activities/L07-nonparametric.html#part-3-pre-processing-predictors-1",
    "title": "Non-Parametric Models",
    "section": "Part 3: Pre-processing predictors",
    "text": "Part 3: Pre-processing predictors\n\n\nCode\n# Load some packages\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n# Load the bikes data and do a little data cleaning\nset.seed(253)\nbikes &lt;- read.csv(\"https://mac-stat.github.io/data/bike_share.csv\") %&gt;% \n  rename(rides = riders_registered, temp = temp_feel) %&gt;% \n  mutate(temp = round(temp)) %&gt;% \n  mutate(breakdowns = sample(c(rep(0, 728), rep(1, 3)), 731, replace = FALSE)) %&gt;% \n  select(temp, season, breakdowns, rides)\n\n\n\n\n\nStandardizing quantitative predictors\n\n\n\nSolution\n\n\n# Recipe with 1 preprocessing step\nrecipe_1 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_normalize(all_numeric_predictors())\n\n# Check it out\nrecipe_1\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome:   1\n## predictor: 3\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Centering and scaling for: all_numeric_predictors()\n\n\n# Check out the first 3 rows of the pre-processed data\n# (Don't worry about the code. Normally we won't do this step.)\nrecipe_1 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  head(3)\n## # A tibble: 3 √ó 4\n##     temp season breakdowns rides\n##    &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n## 1 -0.660 winter    -0.0642   654\n## 2 -0.728 winter    -0.0642   670\n## 3 -1.75  winter    -0.0642  1229\n\n\n# Compare to first 3 rows of original data\nbikes %&gt;% \n  head(3)\n##   temp season breakdowns rides\n## 1   65 winter          0   654\n## 2   64 winter          0   670\n## 3   49 winter          0  1229\n\nFollow-up questions\n\nThe numeric predictors, but not rides, were standardized.\nSee below.\n\n\nbikes %&gt;% \n  summarize(mean(temp), sd(temp))\n##   mean(temp) sd(temp)\n## 1   74.69083 14.67838\n        \n(65 - 74.69083) / 14.67838\n## [1] -0.6602111\n\n\n\n\nCreating ‚Äúdummy‚Äù variables for categorical predictors\n\n\n\nSolution\n\n\n# Recipe with 1 preprocessing step\nrecipe_2 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_dummy(all_nominal_predictors())\n\n# Check it out\nrecipe_2\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome:   1\n## predictor: 3\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Dummy variables from: all_nominal_predictors()\n\n\n# Check out 3 specific rows of the pre-processed data\n# (Don't worry about the code.)\nrecipe_2 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##    temp breakdowns rides season_spring season_summer season_winter\n##   &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1    53          0   674             0             0             1\n## 2    70          0   674             1             0             0\n## 3    68          0   655             0             0             0\n\n\n# Compare to the same 3 rows in the original data\nbikes %&gt;% \n  filter(rides %in% c(655, 674))\n##   temp season breakdowns rides\n## 1   53 winter          0   674\n## 2   70 spring          0   674\n## 3   68   fall          0   655\n\nFollow-up questions\n\nfall\n0 for spring and summer, 1 for winter\n0 for spring, summer, and winter\n\n\n\n\nCombining pre-processing steps\n\n\n\nSolution\n\n\n# step_normalize() before step_dummy()\nrecipe(rides ~ ., data = bikes) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##     temp breakdowns rides season_spring season_summer season_winter\n##    &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -1.48     -0.0642   674             0             0             1\n## 2 -0.320    -0.0642   674             1             0             0\n## 3 -0.456    -0.0642   655             0             0             0\n\n\n# step_dummy() before step_normalize()\nrecipe(rides ~ ., data = bikes) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  filter(rides %in% c(655, 674))\n## # A tibble: 3 √ó 6\n##     temp breakdowns rides season_spring season_summer season_winter\n##    &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -1.48     -0.0642   674        -0.580        -0.588         1.74 \n## 2 -0.320    -0.0642   674         1.72         -0.588        -0.573\n## 3 -0.456    -0.0642   655        -0.580        -0.588        -0.573\n\nFollow-up questions / comments\n\nwhen dummies are created second, they remain as 0s and 1s. when dummies are created first, these 0s and 1s are standardized\n\n\n\n\nLess common: Removing variables with ‚Äúnear-zero variance‚Äù\n\n\n\nSolution\n\n\n# notice the near-zero variability in the breakdowns predictor\nbikes %&gt;% \n  count(breakdowns)\n##   breakdowns   n\n## 1          0 728\n## 2          1   3\n\n\n# Recipe with 3 preprocessing steps\nrecipe_3 &lt;- recipe(rides ~ ., data = bikes) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;% \n  step_normalize(all_numeric_predictors())\n\n# Check out the first 3 rows of the pre-processed data\n# (Don't worry about the code.)\nrecipe_3 %&gt;% \n  prep() %&gt;% \n  bake(new_data = bikes) %&gt;% \n  head(3)\n## # A tibble: 3 √ó 5\n##     temp rides season_spring season_summer season_winter\n##    &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n## 1 -0.660   654        -0.580        -0.588          1.74\n## 2 -0.728   670        -0.580        -0.588          1.74\n## 3 -1.75   1229        -0.580        -0.588          1.74\n\n\n# Compare to this to the first 3 rows in the original data\nbikes %&gt;% \n  head(3)\n##   temp season breakdowns rides\n## 1   65 winter          0   654\n## 2   64 winter          0   670\n## 3   49 winter          0  1229\n\nFollow-up questions\n\nit removed breakdowns from the data set.\nmore computationally efficient. don‚Äôt spend extra energy on pre-processing breakdowns since we don‚Äôt even want to keep it.\n\n\n\n\nThere‚Äôs lots more!\n\n\n\nSolution\n\n\nls(\"package:recipes\")[startsWith(ls(\"package:recipes\"), \"step_\")]\n##  [1] \"step_arrange\"            \"step_bagimpute\"         \n##  [3] \"step_bin2factor\"         \"step_BoxCox\"            \n##  [5] \"step_bs\"                 \"step_center\"            \n##  [7] \"step_classdist\"          \"step_classdist_shrunken\"\n##  [9] \"step_corr\"               \"step_count\"             \n## [11] \"step_cut\"                \"step_date\"              \n## [13] \"step_depth\"              \"step_discretize\"        \n## [15] \"step_dummy\"              \"step_dummy_extract\"     \n## [17] \"step_dummy_multi_choice\" \"step_factor2string\"     \n## [19] \"step_filter\"             \"step_filter_missing\"    \n## [21] \"step_geodist\"            \"step_harmonic\"          \n## [23] \"step_holiday\"            \"step_hyperbolic\"        \n## [25] \"step_ica\"                \"step_impute_bag\"        \n## [27] \"step_impute_knn\"         \"step_impute_linear\"     \n## [29] \"step_impute_lower\"       \"step_impute_mean\"       \n## [31] \"step_impute_median\"      \"step_impute_mode\"       \n## [33] \"step_impute_roll\"        \"step_indicate_na\"       \n## [35] \"step_integer\"            \"step_interact\"          \n## [37] \"step_intercept\"          \"step_inverse\"           \n## [39] \"step_invlogit\"           \"step_isomap\"            \n## [41] \"step_knnimpute\"          \"step_kpca\"              \n## [43] \"step_kpca_poly\"          \"step_kpca_rbf\"          \n## [45] \"step_lag\"                \"step_lincomb\"           \n## [47] \"step_log\"                \"step_logit\"             \n## [49] \"step_lowerimpute\"        \"step_meanimpute\"        \n## [51] \"step_medianimpute\"       \"step_modeimpute\"        \n## [53] \"step_mutate\"             \"step_mutate_at\"         \n## [55] \"step_naomit\"             \"step_nnmf\"              \n## [57] \"step_nnmf_sparse\"        \"step_normalize\"         \n## [59] \"step_novel\"              \"step_ns\"                \n## [61] \"step_num2factor\"         \"step_nzv\"               \n## [63] \"step_ordinalscore\"       \"step_other\"             \n## [65] \"step_pca\"                \"step_percentile\"        \n## [67] \"step_pls\"                \"step_poly\"              \n## [69] \"step_poly_bernstein\"     \"step_profile\"           \n## [71] \"step_range\"              \"step_ratio\"             \n## [73] \"step_regex\"              \"step_relevel\"           \n## [75] \"step_relu\"               \"step_rename\"            \n## [77] \"step_rename_at\"          \"step_rm\"                \n## [79] \"step_rollimpute\"         \"step_sample\"            \n## [81] \"step_scale\"              \"step_select\"            \n## [83] \"step_shuffle\"            \"step_slice\"             \n## [85] \"step_spatialsign\"        \"step_spline_b\"          \n## [87] \"step_spline_convex\"      \"step_spline_monotone\"   \n## [89] \"step_spline_natural\"     \"step_spline_nonnegative\"\n## [91] \"step_sqrt\"               \"step_string2factor\"     \n## [93] \"step_time\"               \"step_unknown\"           \n## [95] \"step_unorder\"            \"step_window\"            \n## [97] \"step_YeoJohnson\"         \"step_zv\"",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#part-4-optional",
    "href": "activities/L07-nonparametric.html#part-4-optional",
    "title": "Non-Parametric Models",
    "section": "Part 4: Optional",
    "text": "Part 4: Optional\n\nKNN\n\n\n\nSolution\n\nWill vary by group.\n\n\n\nThinking like a machine learner\n\n\n\nSolution\n\n\nnumber of neighbors ‚ÄúK‚Äù\n1, 2, ‚Ä¶., n (sample size)\nWhen K is too small, our model is too flexible / overfit. When K is too big, our model is too rigid / simple.",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#main-points-from-today",
    "href": "activities/L07-nonparametric.html#main-points-from-today",
    "title": "Non-Parametric Models",
    "section": "Main Points from Today",
    "text": "Main Points from Today\n\nIf the relationship between \\(x\\) and \\(y\\) is not a straight line or a polynomial (such as quadratic), we might need nonparametric methods.\n\nOne needs to consider the scale of variables when calculating distance between observations with more than one predictor.\nPre-processing steps invoke important assumptions that impact your models and predictions.",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "activities/L07-nonparametric.html#after-class",
    "href": "activities/L07-nonparametric.html#after-class",
    "title": "Non-Parametric Models",
    "section": "After Class",
    "text": "After Class\n\nFinish the exercises (at least through Part 3), check the solutions, organize your notes, and come to office hours with questions!\nBefore our next class:\n\nComplete CP6\nInstall the kknn and shiny packages",
    "crumbs": [
      "Non-Parametric Models"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Homework Assignment",
    "section": "",
    "text": "‚Ä¶due at 11:59 pm Central on Moodle!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 253: Statistical Machine Learning",
    "section": "",
    "text": "STAT 253: Statistical Machine Learning\nMacalester College, Spring 2026\nStatistics is not just about theories & numbers ‚Äî it‚Äôs about making sense of the world.\n\n\n\n\n\n\nüìñ A Thought from H. G. Wells\n\n\n\n\n‚ÄúStatistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.‚Äù\n\n\n\nWelcome to the world of Statistics! In this course, you‚Äôll learn how to analyze data, test research hypotheses, and make predictions in ways that matter.\nInstructor: Md Mutasim Billah  Class meeting times:\n\nSection 03: M/W/F 02:20-03:20pm, THTR 213\n\nOffice hours:\n\nLocation: My office (OLRI 234) and over Zoom\nTimes: M/W: 12:00pm - 12:30pm (in-person), T/TR: 2pm - 3pm (Over zoom, password: 123456)\nBy Appointment: I‚Äôm also happy to meet one-on-one if my normal drop-in/virtual hours don‚Äôt work for you. Shoot me an email and we can arrange it over zoom, password: 123456.\nEmail Response Time: I do my best to reply to emails promptly during weekdays. Please note that messages sent after 3:00 pm or on weekends may take longer to receive a response.\n\n\nSTAT 253 Preceptor Office Hours: There is a link to a Google Calendar containing all preceptor office hours available at the top of the course Moodle page!\nData and R Support: In addition to our course preceptors, there is support on campus for working with data and R / RStudio. See https://www.macalester.edu/mscs/data-support for more information.\n\nThis course website will be updated throughout the semester with new activities, assignments, and announcements, so please bookmark this page if you are enrolled in the course!\nIf you find any typos, bugs, dead links, or have other questions, please email mbillah@macalester.edu"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Please download and go through the Project Instructions in details.\nThe Rubrics for grading are here.\nParticipate in the STAT 155 Group Project Survey by Monday, October 27."
  },
  {
    "objectID": "stat155.html",
    "href": "stat155.html",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "In this course, we will build on the linear and logistic regression modeling techniques covered in STAT 155. As such, familiarity with key concepts from STAT 155 is expected. This includes, but is not necessarily limited to, the following topics:\n\ndata context: 5W‚Äôs + H (who, what, where, when, why, how)\ndata visualization in R\nlinear regression: least squares, model interpretation, prediction, model evaluation (eg residuals, \\(R^2\\))\nlogistic regression: odds, model interpretation, prediction, model evaluation (eg accuracy, sensitivity)\nbootstrapping\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are rusty on any of these concepts, please review the resources linked below!\n\n\n\n\n\n\n\n\n\n\nLet \\(y\\) be a response variable with a set of \\(k\\) explanatory variables \\(x = (x_{1}, x_{2}, ..., x_{k})\\). Then the population linear regression model is\n\\[\\begin{split}\ny & = f(x) + \\varepsilon  = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\nNOTES:\n\n\\(\\beta\\) is the Greek letter ‚Äúbeta‚Äù. \\(\\varepsilon\\) is the Greek letter ‚Äúepsilon‚Äù.\n\n‚ÄúLinear‚Äù regression is so named because it assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs. It does not mean that the relationship itself is linear!! For example, one of the predictors might be a quadratic term: \\(x_2 = x_1^2\\).\n\\(f(x) = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k}\\) captures the trend of the relationship\n\n\\(\\beta_0\\) = intercept coefficient\nthe model value when \\(x_1=x_2=\\cdots=x_k=0\\)\n\\(\\beta_i\\) = \\(x_i\\) coefficient\nhow \\(x_i\\) is related to \\(y\\) when holding constant all other \\(x_i\\)\n\n\\(\\epsilon\\) reflects deviation from the trend (the residual)\n\n\n\n\nFitting the Model\nOnce we have a population model in mind, we can ‚Äúfit the model‚Äù (i.e.¬†estimate the \\(\\beta\\) population coefficients) using sample data:\n\\[\\begin{split}\ny & =  \\hat{f}(x) + \\varepsilon \\\\\n& = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1} + \\hat{\\beta}_2 x_{2} + \\cdots + \\hat{\\beta}_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\n\n\nTo this end, collect a sample of data on \\(n\\) subjects. Use subscripts to denote the data for subject \\(i\\): \\(y_i\\) and \\(x_{ij}\\). Then the predicted response and residual (prediction error) for subject \\(i\\) are\n\nprediction \\[\\hat{y}_i = \\hat{f}(x_i) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_k x_{ik}\\]\nresidual / prediction error \\[y_i - \\hat{y}_i\\]\n\n\n\n\nLeast Squares Criterion\nEstimate (\\(\\beta_0, \\beta_1,..., \\beta_k\\)) by (\\(\\hat{\\beta}_0, \\hat{\\beta}_1,..., \\hat{\\beta}_k)\\) that minimize the sum of squared residuals: \\[\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = (y_1-\\hat{y}_1)^2 + (y_2-\\hat{y}_2)^2 + \\cdots + (y_n-\\hat{y}_n)^2\\]\n\n\n\n\n\n\nA comprehensive STAT 155 review is provided by the STAT 155 Notes created by Profs. Grinde, Heggeseth, and Myint (here) and Prof.¬†Bill‚Äôs Fall 25 STAT 155 website (skim the topics from the ‚ÄòActivities‚Äô tab as needed!) (here).",
    "crumbs": [
      "STAT 155 Resources"
    ]
  },
  {
    "objectID": "stat155.html#important-topics",
    "href": "stat155.html#important-topics",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "In this course, we will build on the linear and logistic regression modeling techniques covered in STAT 155. As such, familiarity with key concepts from STAT 155 is expected. This includes, but is not necessarily limited to, the following topics:\n\ndata context: 5W‚Äôs + H (who, what, where, when, why, how)\ndata visualization in R\nlinear regression: least squares, model interpretation, prediction, model evaluation (eg residuals, \\(R^2\\))\nlogistic regression: odds, model interpretation, prediction, model evaluation (eg accuracy, sensitivity)\nbootstrapping\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are rusty on any of these concepts, please review the resources linked below!",
    "crumbs": [
      "STAT 155 Resources"
    ]
  },
  {
    "objectID": "stat155.html#review-resources",
    "href": "stat155.html#review-resources",
    "title": "STAT 155 Resources",
    "section": "",
    "text": "Let \\(y\\) be a response variable with a set of \\(k\\) explanatory variables \\(x = (x_{1}, x_{2}, ..., x_{k})\\). Then the population linear regression model is\n\\[\\begin{split}\ny & = f(x) + \\varepsilon  = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\nNOTES:\n\n\\(\\beta\\) is the Greek letter ‚Äúbeta‚Äù. \\(\\varepsilon\\) is the Greek letter ‚Äúepsilon‚Äù.\n\n‚ÄúLinear‚Äù regression is so named because it assumes that \\(y\\) is a linear combination of the \\(x\\)‚Äôs. It does not mean that the relationship itself is linear!! For example, one of the predictors might be a quadratic term: \\(x_2 = x_1^2\\).\n\\(f(x) = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\cdots + \\beta_k x_{k}\\) captures the trend of the relationship\n\n\\(\\beta_0\\) = intercept coefficient\nthe model value when \\(x_1=x_2=\\cdots=x_k=0\\)\n\\(\\beta_i\\) = \\(x_i\\) coefficient\nhow \\(x_i\\) is related to \\(y\\) when holding constant all other \\(x_i\\)\n\n\\(\\epsilon\\) reflects deviation from the trend (the residual)\n\n\n\n\nFitting the Model\nOnce we have a population model in mind, we can ‚Äúfit the model‚Äù (i.e.¬†estimate the \\(\\beta\\) population coefficients) using sample data:\n\\[\\begin{split}\ny & =  \\hat{f}(x) + \\varepsilon \\\\\n& = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1} + \\hat{\\beta}_2 x_{2} + \\cdots + \\hat{\\beta}_k x_{k} + \\varepsilon \\\\\n\\end{split}\\]\n\n\nTo this end, collect a sample of data on \\(n\\) subjects. Use subscripts to denote the data for subject \\(i\\): \\(y_i\\) and \\(x_{ij}\\). Then the predicted response and residual (prediction error) for subject \\(i\\) are\n\nprediction \\[\\hat{y}_i = \\hat{f}(x_i) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_k x_{ik}\\]\nresidual / prediction error \\[y_i - \\hat{y}_i\\]\n\n\n\n\nLeast Squares Criterion\nEstimate (\\(\\beta_0, \\beta_1,..., \\beta_k\\)) by (\\(\\hat{\\beta}_0, \\hat{\\beta}_1,..., \\hat{\\beta}_k)\\) that minimize the sum of squared residuals: \\[\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = (y_1-\\hat{y}_1)^2 + (y_2-\\hat{y}_2)^2 + \\cdots + (y_n-\\hat{y}_n)^2\\]\n\n\n\n\n\n\nA comprehensive STAT 155 review is provided by the STAT 155 Notes created by Profs. Grinde, Heggeseth, and Myint (here) and Prof.¬†Bill‚Äôs Fall 25 STAT 155 website (skim the topics from the ‚ÄòActivities‚Äô tab as needed!) (here).",
    "crumbs": [
      "STAT 155 Resources"
    ]
  }
]